{
  "name": "02-Exploratory-Analytics",
  "uuid": "e9cfdd2c-7e7a-4d3e-b758-1e3a8d4b6aeb",
  "category": "ExploratoryAnalytics",
  "nodes": [
    {
      "id": "1",
      "name": "Read CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>InferSchema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the InferSchema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "49.0667px",
      "y": "324.067px",
      "hint": "Infer the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/MANUFACTURING/Demand-Forecasting-Electronics-Production/Raw-Data/Electronics-Demand-Forecasting.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"date\",\"product_category\",\"item\",\"sales\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Columns from CSV",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "properties",
          "value": "",
          "widget": "tab",
          "title": "Properties",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Properties Name",
          "description": "Extra options/properites available while executing in Read CSV.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Properties Value",
          "description": "Config Values for the Corresponding properites name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "3",
      "name": "Pivot By",
      "description": "Pivot Node",
      "details": "This node creates a Dataframe based on the Pivot table created out of the incoming Dataframe.<br>\n<br>\nPivot table is created by Aggregation of rows by applying the Aggregate functions on the Aggregate Columns against the Grouping and Pivot Columns selected.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif PivotBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\nPIVOT COLUMNS         :    LOCATION<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees for each combination of [DEPT] and [LOCATION] would be listed as below:<br>\n<br>\nDEPT         |    NEW JERSEY       |    NEW YORK<br>\n---------------------------------------------------<br>\nFRONT DESK   |    1                |    1<br>\nMARKETING    |    1                |    1<br>\nHR           |                     |    1<br>\nSALES        |    1                |<br>\nMAINTENANCE  |    1                |    1<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodePivotBy",
      "x": "1306px",
      "y": "322px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregate",
          "value": "",
          "widget": "tab",
          "title": "Aggregate",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "groupingCols",
          "value": "[\"date_new_month\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateCols",
          "value": "[\"sales\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateOperations",
          "value": "[\"avg\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation to use",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pivot",
          "value": "",
          "widget": "tab",
          "title": "Pivot",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pivotCol",
          "value": "product_category_item",
          "widget": "variable",
          "title": "Pivot Column",
          "description": "Pivoting Column",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "uniqueValues",
          "value": "",
          "widget": "textfield",
          "title": "UniqueValues",
          "description": "Comma separated unique values: Providing Unique values while performing pivot operation improves the performance of the operation since Spark does not have to first compute the list of distinct values of Pivot Column internally.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"date_new_month\",\"Core_Competencies_Molded_Cables\",\"Core_Competencies_RF_Cables\",\"Core_Competencies_Round_Wire_Cable_Assemblies\",\"Process_Capabilities_Automated_Wire_Processing\",\"Process_Capabilities_Metal_or_Fiber\",\"Process_Capabilities_Molding\"]",
          "widget": "schema_col_names",
          "title": "Column Names of the Table",
          "description": "Output Columns Names of the Table",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Column Types of the Table",
          "description": "Output Column Types of the Table",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Output Column Formats",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "4",
      "name": "Date Time Field Extract",
      "description": "It creates a new DataFrame by extracting Date and Time fields.",
      "details": "<h2>Date Time Field Extract Details</h2>\n<br>\nSpark functions provides hour(), minute(), second() and weekofyear() functions to extract hour, minute, second and week of the year from Timestamp column respectively along with the standard functions of year(), month() and day().<br>\nIt creates a new DataFrame by extracting the Date and Time fields.<br>\n<br>\n<h4>Input</h4>\n  * Column :- The input column is selected here and it should be of Date\\TimeStamp datatype.<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li> The values that can be extracted are YEAR,MONTH,DAY OF MONTH,HOUR,MINUTE,SECOND,WEEKOFYEAR,DAYOFWEEK and MONTHNAME</li>\n<li> The values that need to be extracted have to be set to true (by default it is false).</li>\n</ul>\n<ul>\n<li> Example:- The incoming Dataframe has a Date value as 2022-01-01 14:30:45 in YYYY-MM-DD HH:mm:ss format</li>\n</ul>",
      "examples": "If incoming Dataframe has Date value as 2022-01-01 14:30:45 in YYYY-MM-DD HH:mm:ss format then using datetimeextract node would result in followings <br>\nadded as new columns to the Dataframe:<br>\n<br>\n<ul>\n<li> YEAR : 2022 </li>\n<li> MONTH : 01</li>\n<li> DAY OF MONTH : 01 </li>\n<li> HOUR : 14</li>\n<li> MINUTE : 30</li>\n<li> SECOND : 45</li>\n<li> WEEKOFYEAR : 1</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDateTimeFieldExtract",
      "x": "400px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCol",
          "value": "date_new",
          "widget": "variable",
          "title": "Column",
          "description": "The input column name",
          "datatypes": [
            "date",
            "timestamp"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extractYear",
          "value": "true",
          "widget": "array",
          "title": "Extract Year",
          "description": "Extract Year",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extractMonth",
          "value": "true",
          "widget": "array",
          "title": "Extract Month",
          "description": "Extract Month",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extractDayOfMonth",
          "value": "false",
          "widget": "array",
          "title": "Extract Day of Month",
          "description": "Extract Day of Month",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extractHour",
          "value": "false",
          "widget": "array",
          "title": "Extract Hour",
          "description": "Extract Hour",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extractMinute",
          "value": "false",
          "widget": "array",
          "title": "Extract Minute",
          "description": "Extract Minute",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extractSecond",
          "value": "false",
          "widget": "array",
          "title": "Extract Second",
          "description": "Extract Second",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extractWeekOfYear",
          "value": "false",
          "widget": "array",
          "title": "Extract Week Of Year",
          "description": "Extract WeekOfYear",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extractDayOfWeek",
          "value": "false",
          "widget": "array",
          "title": "Extract Day Of Week",
          "description": "Extract Day Of Week",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extractDayOfYear",
          "value": "false",
          "widget": "array",
          "title": "Extract Day Of Year",
          "description": "Extract Day Of Year",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extractMonthName",
          "value": "false",
          "widget": "array",
          "title": "Extract Month Name",
          "description": "Extract Month Name",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "5",
      "name": "String To Date",
      "description": "This node converts string columns to date using the specified date/time format",
      "details": "<h2>String To Date Multi Details</h2>\n<br>\nThis node converts a string column to a date or timestamp datatype column. This node can be used to convert multiple string columns to new Date or Timestmp columns. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select the String field(s) which needs to be converted.</li>\n<li>   INPUT COLUMN FORMATS :-The format of the input column is specified here.</li>\n<li>   OUTPUT COLUMN NAMES :- Specify the output column name for the converted value. </li>\n<li>   NEW DATA TYPES :- Select the output type as either of DATE or TIMESTAMP datatype.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li>   It will convert all the specified columns into the specified  datatype.</li>\n</ul>\n<h4>Example</h4>\n<ul>\n<li>   Input : 04/13/2019</li>\n<li>   Format : MM/dd/yyyy</li>\n<li>   NEW DATA TYPES : DATE</li>\n</ul>\n<br>\n<ul>\n<li>   Input : 04/13/2019</li>\n<li>   Format : MM/dd/yyyy</li>\n<li>   NEW DATA TYPES : TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Format Examples</h2>\n<br>\n<ul>\n<li> dd-MM-yy : 31-01-12</li>\n<li> dd-MM-yyyy : 31-01-2012</li>\n<li> MM-dd-yyyy : 01-31-2012</li>\n<li> yyyy-MM-dd : 2012-01-31</li>\n<li> yyyy-MM-dd HH:mm:ss : 2012-01-31 23:59:59</li>\n<li> yyyy-MM-dd HH:mm:ss.SSS : 2012-01-31 23:59:59.999</li>\n<li> yyyy-MM-dd HH:mm:ss.SSSZ : 2012-01-31 23:59:59.999+0100</li>\n<li> EEEEE MMMMM yyyy HH:mm:ss.SSSZ : Saturday November 2012 10:45:42.720+0100</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeMultiStringToDate",
      "x": "225px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputColNames",
          "value": "[\"date\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputColFormats",
          "value": "[\"dd/MM/yyyy\"]",
          "widget": "variables_list_textfield",
          "title": "Input Column Formats",
          "description": "Input Column Formats. eg: yyyy-MM-dd yyyy-MM-dd HH:mm:ss",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"date_new\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"DATE\"]",
          "widget": "variables_list_array",
          "title": "New Data Types",
          "description": "New data types (DATE, TIMESTAMP)",
          "optionsArray": [
            "DATE",
            "TIMESTAMP"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "6",
      "name": "Concat Columns",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "575px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"date_new_year\",\"date_new_month\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "year_month",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "-",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "7",
      "name": "Concat Columns",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "750px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"product_category\",\"item\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "product_category_item",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "_",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "9",
      "name": "Sort By",
      "iconImage": "fa fa-tumblr-square",
      "description": "It sorts the incoming DataFrame on the fields specified.",
      "details": "This node sorts the incoming DataFrame based on the values present in columns specified.<br>\n<br>\nMultiple columns can be selected for sorting data. Data can be sorted in Ascending or Descending order.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\nIf SortBy node is configured to sort data in descending order of values present in [CUST_NAME] column then outgoing Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSortBy",
      "x": "1450px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sortByColNames",
          "value": "[\"date_new_month\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns on which to Sort By",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "ascDesc",
          "value": "[\"ASC\"]",
          "widget": "variables_list_array",
          "title": "Sorting Order",
          "description": "Whether to sort in ascending or descending order",
          "optionsArray": [
            "DESC",
            "ASC"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "11",
      "name": "Drop Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by dropping the specified columns",
      "details": "<h2>Drop Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame by dropping the selected columns.<br>\n<br>\nIt drops the selected columns from the outgoing dataframe. <br>\n<br>\nColumns that need to be dropped are to be selected in the 'Selected' list. Multiple columns can be selected in the list that needs to be dropped.<br>",
      "examples": "<h2>Drop Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe having following columns:<br>\n<br>\n<ul>\n<li> CUST_CD</li>\n<li> CUST_NAME</li>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>\n<h4>Drop Columns Node Configuration And Output</h4>\n<br>\n[DOB] and [ADDRESS] columns are selected to be dropped from the outgoing Dataframe. <br>\nOutgoing dataframe would contain only below two columns after dropping the selected columns:<br>\n<br>\n<ul>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropColumns",
      "x": "1625px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropCols",
          "value": "[\"date_new_month\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "The columns to be excluded from the output DataFrame",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "12",
      "name": "Correlation",
      "iconImage": "fa fa-tumblr-square",
      "description": "calculates the correlation between two series of data.",
      "details": "<h2>Correlation Node Details</h2>\n<br>\nCorrelation is to measure if two variables or two feature columns tend to move in together in same or opposite direction. The idea is to detect if one variable or feature column can be predicted by another variable or feature column.<br>\n<br>\nThe Correlation node uses the method of Pearson's correlation for checking correlation between two continuous variables (or feature columns)<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : A short description to summarizes what the data depicts.</li>\n<li> INPUT COLUMN FOR CORRELATION : </li>\n</ul>\n- Selected : A list of numeric columns among which the correlation is to be predicted.<br>",
      "examples": "<h2>Correlation Node Example</h2>\n<br>\nFor a given dataframe having the below schema:<br>\nCourse  | Amount | Discount| <br>\n(String)| Double | Double  |<br>\n----------------------------<br>\n<br>\nWe can select the <b>Amount</b> and <b>Discount</b> fields for which we need to find the correlation.<br>\n<br>\nThis will yield three separate output sections:<br>\n- A Correlation Table<br>\n- A Correlation Matrix &<br>\n- A sample data values of the input dataframe<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeCorrelation",
      "x": "1800px",
      "y": "326px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "Correlation Average Monthly Sales for all Product Category and Product Name",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Core_Competencies_Molded_Cables\",\"Core_Competencies_RF_Cables\",\"Core_Competencies_Round_Wire_Cable_Assemblies\",\"Process_Capabilities_Automated_Wire_Processing\",\"Process_Capabilities_Metal_or_Fiber\",\"Process_Capabilities_Molding\"]",
          "widget": "variables",
          "title": "Input Column for Correlation",
          "description": "Column Names to check correlation ",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float",
            "decimal"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "scala"
    },
    {
      "id": "14",
      "name": "Find And Replace Using Regex",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node finds and replaces text in a column with another",
      "details": "<h2>Find and Replace Details</h2>\n<br>\nThis node allows the user to find and replace patterns of text within the data. This node will only search the columns selected in the Input Columns option. <br>\nThe Find pattern must be in Regex format. This node will only find exact matches for the search pattern.<br>",
      "examples": "<h2>Find and Replace Examples</h2>\n<br>\nIncoming Dataframe has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021-01-01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019-05-04        |    11 000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018-06-07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017-02-01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020-12-21        |    78 999.00    |    BAD<br>\n<br>\n<h4>If FindAndReplaceUsingRegex node is configured to find and replace [-] character in [DATE_OF_JOINING] column with [/]</h4>\nthen outgoing Dataframe would be created as below after replacement of character:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021/01/01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019/05/04        |    11 000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018/06/07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017/02/01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020/12/21        |    78 999.00    |    BAD<br>\n<br>\n<h4>If FindAndReplaceUsingRegex node is configured to find and replace [^VERY GOOD$] string in [PERFORMANCE] column with [EXCELLENT]</h4>\nwhere [^] denotes start of string and [$] denotes end of string<br>\nthen outgoing Dataframe would be created as below after replacement of exact entry of [VERY GOOD] with [EXCELLENT] and not other entries:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021-01-01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019-05-04        |    11 000.00    |    EXCELLENT<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018-06-07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017-02-01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020-12-21        |    78 999.00    |    BAD<br>\n<br>\nNote: [VERY VERY GOOD] is not replaced as it is not an exact match.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFindAndReplaceUsingRegex",
      "x": "925px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"item\",\"product_category_item\"]",
          "widget": "variables",
          "title": "Input Columns",
          "description": "Columns on which to apply Regex",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "searchPattern",
          "value": "\\s",
          "widget": "textfield",
          "title": "Find",
          "description": "Enter Search Pattern",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replacePattern",
          "value": "_",
          "widget": "textfield",
          "title": "Replace",
          "description": "Enter replacement Value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "scala"
    },
    {
      "id": "15",
      "name": "Find And Replace Using Regex",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node finds and replaces text in a column with another",
      "details": "<h2>Find and Replace Details</h2>\n<br>\nThis node allows the user to find and replace patterns of text within the data. This node will only search the columns selected in the Input Columns option. <br>\nThe Find pattern must be in Regex format. This node will only find exact matches for the search pattern.<br>",
      "examples": "<h2>Find and Replace Examples</h2>\n<br>\nIncoming Dataframe has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021-01-01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019-05-04        |    11 000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018-06-07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017-02-01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020-12-21        |    78 999.00    |    BAD<br>\n<br>\n<h4>If FindAndReplaceUsingRegex node is configured to find and replace [-] character in [DATE_OF_JOINING] column with [/]</h4>\nthen outgoing Dataframe would be created as below after replacement of character:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021/01/01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019/05/04        |    11 000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018/06/07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017/02/01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020/12/21        |    78 999.00    |    BAD<br>\n<br>\n<h4>If FindAndReplaceUsingRegex node is configured to find and replace [^VERY GOOD$] string in [PERFORMANCE] column with [EXCELLENT]</h4>\nwhere [^] denotes start of string and [$] denotes end of string<br>\nthen outgoing Dataframe would be created as below after replacement of exact entry of [VERY GOOD] with [EXCELLENT] and not other entries:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021-01-01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019-05-04        |    11 000.00    |    EXCELLENT<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018-06-07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017-02-01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020-12-21        |    78 999.00    |    BAD<br>\n<br>\nNote: [VERY VERY GOOD] is not replaced as it is not an exact match.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFindAndReplaceUsingRegex",
      "x": "1100px",
      "y": "325px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"item\",\"product_category_item\"]",
          "widget": "variables",
          "title": "Input Columns",
          "description": "Columns on which to apply Regex",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "searchPattern",
          "value": "61.5",
          "widget": "textfield",
          "title": "Find",
          "description": "Enter Search Pattern",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replacePattern",
          "value": "61_point_5",
          "widget": "textfield",
          "title": "Replace",
          "description": "Enter replacement Value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "scala"
    },
    {
      "id": "16",
      "name": "Row Filter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "1275px",
      "y": "450px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "conditionExpr",
          "value": "product_category = \"Process Capabilities\" and item != \"\"",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "17",
      "name": "Pivot By",
      "iconImage": "fa fa-tumblr-square",
      "description": "Pivot Node",
      "details": "This node creates a Dataframe based on the Pivot table created out of the incoming Dataframe.<br>\n<br>\nPivot table is created by Aggregation of rows by applying the Aggregate functions on the Aggregate Columns against the Grouping and Pivot Columns selected.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif PivotBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\nPIVOT COLUMNS         :    LOCATION<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees for each combination of [DEPT] and [LOCATION] would be listed as below:<br>\n<br>\nDEPT         |    NEW JERSEY       |    NEW YORK<br>\n---------------------------------------------------<br>\nFRONT DESK   |    1                |    1<br>\nMARKETING    |    1                |    1<br>\nHR           |                     |    1<br>\nSALES        |    1                |<br>\nMAINTENANCE  |    1                |    1<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodePivotBy",
      "x": "1450px",
      "y": "450px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregate",
          "value": "",
          "widget": "tab",
          "title": "Aggregate",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "groupingCols",
          "value": "[\"date_new_month\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateCols",
          "value": "[\"sales\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateOperations",
          "value": "[\"avg\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation to use",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pivot",
          "value": "",
          "widget": "tab",
          "title": "Pivot",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pivotCol",
          "value": "item",
          "widget": "variable",
          "title": "Pivot Column",
          "description": "Pivoting Column",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "uniqueValues",
          "value": "",
          "widget": "textfield",
          "title": "UniqueValues",
          "description": "Comma separated unique values: Providing Unique values while performing pivot operation improves the performance of the operation since Spark does not have to first compute the list of distinct values of Pivot Column internally.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"date_new_month\",\"Automated_Wire_Processing\",\"Metal_or_Fiber\",\"Molding\"]",
          "widget": "schema_col_names",
          "title": "Column Names of the Table",
          "description": "Output Columns Names of the Table",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Column Types of the Table",
          "description": "Output Column Types of the Table",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Output Column Formats",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "18",
      "name": "Find And Replace Using Regex",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node finds and replaces text in a column with another",
      "details": "<h2>Find and Replace Details</h2>\n<br>\nThis node allows the user to find and replace patterns of text within the data. This node will only search the columns selected in the Input Columns option. <br>\nThe Find pattern must be in Regex format. This node will only find exact matches for the search pattern.<br>",
      "examples": "<h2>Find and Replace Examples</h2>\n<br>\nIncoming Dataframe has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021-01-01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019-05-04        |    11 000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018-06-07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017-02-01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020-12-21        |    78 999.00    |    BAD<br>\n<br>\n<h4>If FindAndReplaceUsingRegex node is configured to find and replace [-] character in [DATE_OF_JOINING] column with [/]</h4>\nthen outgoing Dataframe would be created as below after replacement of character:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021/01/01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019/05/04        |    11 000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018/06/07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017/02/01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020/12/21        |    78 999.00    |    BAD<br>\n<br>\n<h4>If FindAndReplaceUsingRegex node is configured to find and replace [^VERY GOOD$] string in [PERFORMANCE] column with [EXCELLENT]</h4>\nwhere [^] denotes start of string and [$] denotes end of string<br>\nthen outgoing Dataframe would be created as below after replacement of exact entry of [VERY GOOD] with [EXCELLENT] and not other entries:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021-01-01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019-05-04        |    11 000.00    |    EXCELLENT<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018-06-07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017-02-01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020-12-21        |    78 999.00    |    BAD<br>\n<br>\nNote: [VERY VERY GOOD] is not replaced as it is not an exact match.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFindAndReplaceUsingRegex",
      "x": "925px",
      "y": "450px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"item\",\"product_category_item\"]",
          "widget": "variables",
          "title": "Input Columns",
          "description": "Columns on which to apply Regex",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "searchPattern",
          "value": "\\s",
          "widget": "textfield",
          "title": "Find",
          "description": "Enter Search Pattern",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replacePattern",
          "value": "_",
          "widget": "textfield",
          "title": "Replace",
          "description": "Enter replacement Value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "scala"
    },
    {
      "id": "19",
      "name": "Find And Replace Using Regex",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node finds and replaces text in a column with another",
      "details": "<h2>Find and Replace Details</h2>\n<br>\nThis node allows the user to find and replace patterns of text within the data. This node will only search the columns selected in the Input Columns option. <br>\nThe Find pattern must be in Regex format. This node will only find exact matches for the search pattern.<br>",
      "examples": "<h2>Find and Replace Examples</h2>\n<br>\nIncoming Dataframe has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021-01-01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019-05-04        |    11 000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018-06-07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017-02-01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020-12-21        |    78 999.00    |    BAD<br>\n<br>\n<h4>If FindAndReplaceUsingRegex node is configured to find and replace [-] character in [DATE_OF_JOINING] column with [/]</h4>\nthen outgoing Dataframe would be created as below after replacement of character:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021/01/01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019/05/04        |    11 000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018/06/07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017/02/01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020/12/21        |    78 999.00    |    BAD<br>\n<br>\n<h4>If FindAndReplaceUsingRegex node is configured to find and replace [^VERY GOOD$] string in [PERFORMANCE] column with [EXCELLENT]</h4>\nwhere [^] denotes start of string and [$] denotes end of string<br>\nthen outgoing Dataframe would be created as below after replacement of exact entry of [VERY GOOD] with [EXCELLENT] and not other entries:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021-01-01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019-05-04        |    11 000.00    |    EXCELLENT<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018-06-07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017-02-01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020-12-21        |    78 999.00    |    BAD<br>\n<br>\nNote: [VERY VERY GOOD] is not replaced as it is not an exact match.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFindAndReplaceUsingRegex",
      "x": "1100px",
      "y": "450px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"item\",\"product_category_item\"]",
          "widget": "variables",
          "title": "Input Columns",
          "description": "Columns on which to apply Regex",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "searchPattern",
          "value": "61.5",
          "widget": "textfield",
          "title": "Find",
          "description": "Enter Search Pattern",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replacePattern",
          "value": "61_point_5",
          "widget": "textfield",
          "title": "Replace",
          "description": "Enter replacement Value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "scala"
    },
    {
      "id": "20",
      "name": "Drop Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by dropping the specified columns",
      "details": "<h2>Drop Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame by dropping the selected columns.<br>\n<br>\nIt drops the selected columns from the outgoing dataframe. <br>\n<br>\nColumns that need to be dropped are to be selected in the 'Selected' list. Multiple columns can be selected in the list that needs to be dropped.<br>",
      "examples": "<h2>Drop Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe having following columns:<br>\n<br>\n<ul>\n<li> CUST_CD</li>\n<li> CUST_NAME</li>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>\n<h4>Drop Columns Node Configuration And Output</h4>\n<br>\n[DOB] and [ADDRESS] columns are selected to be dropped from the outgoing Dataframe. <br>\nOutgoing dataframe would contain only below two columns after dropping the selected columns:<br>\n<br>\n<ul>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropColumns",
      "x": "1800px",
      "y": "450px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropCols",
          "value": "[\"date_new_month\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "The columns to be excluded from the output DataFrame",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "21",
      "name": "Sort By",
      "iconImage": "fa fa-tumblr-square",
      "description": "It sorts the incoming DataFrame on the fields specified.",
      "details": "This node sorts the incoming DataFrame based on the values present in columns specified.<br>\n<br>\nMultiple columns can be selected for sorting data. Data can be sorted in Ascending or Descending order.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\nIf SortBy node is configured to sort data in descending order of values present in [CUST_NAME] column then outgoing Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSortBy",
      "x": "1625px",
      "y": "450px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sortByColNames",
          "value": "[\"date_new_month\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns on which to Sort By",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "ascDesc",
          "value": "[\"ASC\"]",
          "widget": "variables_list_array",
          "title": "Sorting Order",
          "description": "Whether to sort in ascending or descending order",
          "optionsArray": [
            "DESC",
            "ASC"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "23",
      "name": "Correlation",
      "iconImage": "fa fa-tumblr-square",
      "description": "calculates the correlation between two series of data.",
      "details": "<h2>Correlation Node Details</h2>\n<br>\nCorrelation is to measure if two variables or two feature columns tend to move in together in same or opposite direction. The idea is to detect if one variable or feature column can be predicted by another variable or feature column.<br>\n<br>\nThe Correlation node uses the method of Pearson's correlation for checking correlation between two continuous variables (or feature columns)<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : A short description to summarizes what the data depicts.</li>\n<li> INPUT COLUMN FOR CORRELATION : </li>\n</ul>\n- Selected : A list of numeric columns among which the correlation is to be predicted.<br>",
      "examples": "<h2>Correlation Node Example</h2>\n<br>\nFor a given dataframe having the below schema:<br>\nCourse  | Amount | Discount| <br>\n(String)| Double | Double  |<br>\n----------------------------<br>\n<br>\nWe can select the <b>Amount</b> and <b>Discount</b> fields for which we need to find the correlation.<br>\n<br>\nThis will yield three separate output sections:<br>\n- A Correlation Table<br>\n- A Correlation Matrix &<br>\n- A sample data values of the input dataframe<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeCorrelation",
      "x": "1975px",
      "y": "450px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "Monthly Average Sales Correlation for Process Capabilities Product Category",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Automated_Wire_Processing\",\"Metal_or_Fiber\",\"Molding\"]",
          "widget": "variables",
          "title": "Input Column for Correlation",
          "description": "Column Names to check correlation ",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float",
            "decimal"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "scala"
    },
    {
      "id": "30",
      "name": "Row Filter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "1275px",
      "y": "200px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "conditionExpr",
          "value": "product_category = \"Core Competencies\" and item != \"\"",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "31",
      "name": "Pivot By",
      "iconImage": "fa fa-tumblr-square",
      "description": "Pivot Node",
      "details": "This node creates a Dataframe based on the Pivot table created out of the incoming Dataframe.<br>\n<br>\nPivot table is created by Aggregation of rows by applying the Aggregate functions on the Aggregate Columns against the Grouping and Pivot Columns selected.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif PivotBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\nPIVOT COLUMNS         :    LOCATION<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees for each combination of [DEPT] and [LOCATION] would be listed as below:<br>\n<br>\nDEPT         |    NEW JERSEY       |    NEW YORK<br>\n---------------------------------------------------<br>\nFRONT DESK   |    1                |    1<br>\nMARKETING    |    1                |    1<br>\nHR           |                     |    1<br>\nSALES        |    1                |<br>\nMAINTENANCE  |    1                |    1<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodePivotBy",
      "x": "1450px",
      "y": "200px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregate",
          "value": "",
          "widget": "tab",
          "title": "Aggregate",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "groupingCols",
          "value": "[\"date_new_month\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateCols",
          "value": "[\"sales\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateOperations",
          "value": "[\"avg\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation to use",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pivot",
          "value": "",
          "widget": "tab",
          "title": "Pivot",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pivotCol",
          "value": "item",
          "widget": "variable",
          "title": "Pivot Column",
          "description": "Pivoting Column",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "uniqueValues",
          "value": "",
          "widget": "textfield",
          "title": "UniqueValues",
          "description": "Comma separated unique values: Providing Unique values while performing pivot operation improves the performance of the operation since Spark does not have to first compute the list of distinct values of Pivot Column internally.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"date_new_month\",\"Molded_Cables\",\"RF_Cables\",\"Round_Wire_Cable_Assemblies\"]",
          "widget": "schema_col_names",
          "title": "Column Names of the Table",
          "description": "Output Columns Names of the Table",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Column Types of the Table",
          "description": "Output Column Types of the Table",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Output Column Formats",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "32",
      "name": "Drop Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by dropping the specified columns",
      "details": "<h2>Drop Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame by dropping the selected columns.<br>\n<br>\nIt drops the selected columns from the outgoing dataframe. <br>\n<br>\nColumns that need to be dropped are to be selected in the 'Selected' list. Multiple columns can be selected in the list that needs to be dropped.<br>",
      "examples": "<h2>Drop Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe having following columns:<br>\n<br>\n<ul>\n<li> CUST_CD</li>\n<li> CUST_NAME</li>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>\n<h4>Drop Columns Node Configuration And Output</h4>\n<br>\n[DOB] and [ADDRESS] columns are selected to be dropped from the outgoing Dataframe. <br>\nOutgoing dataframe would contain only below two columns after dropping the selected columns:<br>\n<br>\n<ul>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropColumns",
      "x": "1800px",
      "y": "200px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropCols",
          "value": "[\"date_new_month\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "The columns to be excluded from the output DataFrame",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "33",
      "name": "Sort By",
      "iconImage": "fa fa-tumblr-square",
      "description": "It sorts the incoming DataFrame on the fields specified.",
      "details": "This node sorts the incoming DataFrame based on the values present in columns specified.<br>\n<br>\nMultiple columns can be selected for sorting data. Data can be sorted in Ascending or Descending order.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\nIf SortBy node is configured to sort data in descending order of values present in [CUST_NAME] column then outgoing Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSortBy",
      "x": "1625px",
      "y": "200px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sortByColNames",
          "value": "[\"date_new_month\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns on which to Sort By",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "ascDesc",
          "value": "[\"ASC\"]",
          "widget": "variables_list_array",
          "title": "Sorting Order",
          "description": "Whether to sort in ascending or descending order",
          "optionsArray": [
            "DESC",
            "ASC"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "35",
      "name": "Correlation",
      "iconImage": "fa fa-tumblr-square",
      "description": "calculates the correlation between two series of data.",
      "details": "<h2>Correlation Node Details</h2>\n<br>\nCorrelation is to measure if two variables or two feature columns tend to move in together in same or opposite direction. The idea is to detect if one variable or feature column can be predicted by another variable or feature column.<br>\n<br>\nThe Correlation node uses the method of Pearson's correlation for checking correlation between two continuous variables (or feature columns)<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : A short description to summarizes what the data depicts.</li>\n<li> INPUT COLUMN FOR CORRELATION : </li>\n</ul>\n- Selected : A list of numeric columns among which the correlation is to be predicted.<br>",
      "examples": "<h2>Correlation Node Example</h2>\n<br>\nFor a given dataframe having the below schema:<br>\nCourse  | Amount | Discount| <br>\n(String)| Double | Double  |<br>\n----------------------------<br>\n<br>\nWe can select the <b>Amount</b> and <b>Discount</b> fields for which we need to find the correlation.<br>\n<br>\nThis will yield three separate output sections:<br>\n- A Correlation Table<br>\n- A Correlation Matrix &<br>\n- A sample data values of the input dataframe<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeCorrelation",
      "x": "1975px",
      "y": "200px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "Monthly Average Sales Correlation for Core Competencies Product Category",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Molded_Cables\",\"RF_Cables\",\"Round_Wire_Cable_Assemblies\"]",
          "widget": "variables",
          "title": "Input Column for Correlation",
          "description": "Column Names to check correlation ",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float",
            "decimal"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "scala"
    },
    {
      "id": "36",
      "name": "Row Filter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "1199px",
      "y": "317px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "conditionExpr",
          "value": "product_category_item != \"\"",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "1",
      "target": "5",
      "id": 1
    },
    {
      "source": "5",
      "target": "4",
      "id": 2
    },
    {
      "source": "4",
      "target": "6",
      "id": 3
    },
    {
      "source": "6",
      "target": "7",
      "id": 4
    },
    {
      "source": "3",
      "target": "9",
      "id": 5
    },
    {
      "source": "9",
      "target": "11",
      "id": 6
    },
    {
      "source": "11",
      "target": "12",
      "id": 7
    },
    {
      "source": "7",
      "target": "14",
      "id": 8
    },
    {
      "source": "14",
      "target": "15",
      "id": 9
    },
    {
      "source": "16",
      "target": "17",
      "id": 10
    },
    {
      "source": "18",
      "target": "19",
      "id": 11
    },
    {
      "source": "7",
      "target": "18",
      "id": 12
    },
    {
      "source": "21",
      "target": "20",
      "id": 13
    },
    {
      "source": "17",
      "target": "21",
      "id": 14
    },
    {
      "source": "30",
      "target": "31",
      "id": 15
    },
    {
      "source": "33",
      "target": "32",
      "id": 16
    },
    {
      "source": "31",
      "target": "33",
      "id": 17
    },
    {
      "source": "20",
      "target": "23",
      "id": 18
    },
    {
      "source": "32",
      "target": "35",
      "id": 19
    },
    {
      "source": "19",
      "target": "30",
      "id": 20
    },
    {
      "source": "19",
      "target": "16",
      "id": 21
    },
    {
      "source": "15",
      "target": "36",
      "id": 22
    },
    {
      "source": "36",
      "target": "3",
      "id": 23
    }
  ],
  "dataSetDetails": [],
  "engine": "scala"
}