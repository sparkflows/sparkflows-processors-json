{
  "name": "08-App-Prediction-Risk-Using-RF-Classifier",
  "uuid": "0d276fc1-b95c-4e5c-a3b0-219e6609dfd1",
  "category": "AnalyticalApp",
  "parameters": " --var agescore1=2 --var agefrom1=25 --var ageto1=35 --var agescore2=3 --var agefrom2=36 --var ageto2=45 --var agescore3=4 --var agefrom3=46 --var ageto3=70 --var ageweightage=1 --var goToNextTab1=true --var genderscore1=1 --var genderscore2=1 --var genderweightage=1 --var goToPreviousTab2=false --var goToNextTab2=true --var jobscore1=0 --var jobscore2=1 --var jobscore3=2 --var jobscore4=3 --var jobweightage=3 --var goToPreviousTab3=false --var goToNextTab3=true --var housingscore1=0 --var housingscore2=1 --var housingscore3=2 --var housingweightage=2 --var goToPreviousTab4=false --var goToNextTab4=true --var savingaccscore1=1 --var savingaccscore2=2 --var savingaccscore3=3 --var savingaccscore4=4 --var savingaccweightage=3 --var goToPreviousTab5=false --var goToNextTab5=true --var checkingaccscore1=1 --var checkingaccscore2=2 --var checkingaccscore3=3 --var checkingaccscore4=4 --var checkingaccweightage=3 --var goToPreviousTab6=false --var goToNextTab6=true --var creditamtscore1=1 --var creditamtfrom1=0 --var creditamtto1=250 --var creditamtscore2=3 --var creditamtfrom2=251 --var creditamtto2=1500 --var creditamtscore3=4 --var creditamtfrom3=1501 --var creditamtto3=2500 --var creditamtscore4=5 --var creditamtfrom4=2501 --var creditamtto4=4000 --var creditamtscore5=7 --var creditamtfrom5=4001 --var creditamtto5=20000 --var creditamtweightage=3 --var goToPreviousTab7=false --var goToNextTab7=true --var durationscore1=1 --var durationfrom1=0 --var durationto1=4 --var durationscore2=2 --var durationfrom2=5 --var durationto2=12 --var durationscore3=3 --var durationfrom3=13 --var durationto3=18 --var durationscore4=4 --var durationfrom4=19 --var durationto4=24 --var durationscore5=5 --var durationfrom5=25 --var durationto5=75 --var durationweightage=2 --var goToPreviousTab8=false --var goToNextTab8=true --var thresholdvalue=30 --var goToPreviousTab9=false --var destinationPath=data/BFSI/Credit-Decisioning/Incremental-Data/ --var prevStage=false --var applicantID=1,2,3 --var submit2=true",
  "nodes": [
    {
      "id": "1",
      "name": "Input Data",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>InferSchema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the InferSchema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "67.8px",
      "y": "232.8px",
      "hint": "Infer the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/BFSI/Credit-Decisioning/Incremental-Data",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"Id\",\"Age\",\"Sex\",\"Job\",\"Housing\",\"Saving_Accounts\",\"Checking_Account\",\"Credit_Amount\",\"Duration\",\"Purpose\",\"Credit_Score\",\"Credit_Score_Rating\",\"Risk\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Columns from CSV",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"DOUBLE\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "properties",
          "value": "",
          "widget": "tab",
          "title": "Properties",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Properties Name",
          "description": "Extra options/properites available while executing in Read CSV.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Properties Value",
          "description": "Config Values for the Corresponding properites name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "3",
      "name": "Drop Rows With Null",
      "description": "This node creates a new DataFrame by dropping rows containing null values",
      "details": "This node creates a new DataFrame by dropping rows containing NULL values in any of the columns.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE05       |    MARK        |               |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    TONY        |    MARKETING  |    <br>\nE04       |    MARTIN      |    MARKETING  |    45<br>\n<br>\nIncoming Dataframe has NULL values for two rows. <br>\nUsing DropRowsWithNull node would result in below outgoing Dataframe created by dropping rows having NULL values in any of the columns:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE04       |    MARTIN      |    MARKETING  |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropRowsWithNull",
      "x": "189.938px",
      "y": "476.969px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "5",
      "name": "Vector Assembler",
      "description": "Merges multiple columns into a vector column.",
      "details": "",
      "examples": "<h2> h2: VectorAssembler Node Example</h2>\n<br>\nAssume that we have a DataFrame with the columns id, hour, mobile, userFeatures, and clicked:<br>\n<br>\n id | hour | mobile | userFeatures     | clicked<br>\n----|------|--------|------------------|---------<br>\n 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0<br>\n<br>\n If we set VectorAssembler's <b>input Selected columns</b> to hour, mobile, and userFeatures and <b>output column</b> to features, after transformation we should get the following DataFrame:<br>\n<br>\n id | hour | mobile | userFeatures     | clicked | features<br>\n----|------|--------|------------------|---------|-----------------------------<br>\n 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0     | [18.0, 1.0, 0.0, 10.0, 0.5]<br>",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeVectorAssembler",
      "x": "337.969px",
      "y": "486.969px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Sex_Indexed\",\"Job\",\"Housing_Indexed\",\"CheckingAccount_Indexed\",\"Credit_Amount\",\"Duration\",\"Purpose_Indexed\",\"Age\",\"SavingAccounts_Indexed\",\"Credit_Score\"]",
          "widget": "variables",
          "title": "Input Columns",
          "description": "Input column of type - all numeric, boolean and vector",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float",
            "vectorudt"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "Vector_Data",
          "widget": "textfield",
          "title": "Output Column",
          "description": "Output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "handleInvalid",
          "value": "error",
          "widget": "array",
          "title": "Handle Invalid",
          "description": "How to handle invalid data (NULL values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output).",
          "optionsArray": [
            "error",
            "skip",
            "keep"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "12",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "54px",
      "y": "45px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "bgColor",
          "value": "blue",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "width",
          "value": "434.222222px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "height",
          "value": "87.222222px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "comment",
          "value": "<p><strong style=\"color: rgb(55, 65, 81);\">This workflow employs a previously saved Random Forest model to make predictions.</strong></p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "18",
      "name": "Standard Scaler",
      "description": "StandardScaler transforms a dataset of Vector rows, normalizing each feature to have unit standard deviation and/or zero mean.",
      "details": "<h2> Standard Scaler Node Details</h2>\n<br>\nThe Standard Scaler Node is used to normalize a dataset of Vector rows, by transforming each feature to have unit standard deviation and/or zero mean. It takes in the common parameters inputCol, outputCol, withMean, and withStd. The input column should be in the format of VectorUDT. The output column will also be in the format of VectorUDT.<br>\n<br>\nThe inputCol is the name of the feature column to be transformed. The outputCol is the name of the new column containing the transformed features. The withMean parameter, when set to true, centers the data with mean before scaling. The withStd parameter, when set to true, scales the data to unit standard deviation.<br>\n<br>\n<h4>Input Parameters</h4>\n<br>\nINPUT COLUMN : Select the required column for which Standard scaling has to be done .<br>\nOUTPUT COLUMN : The name of the output column after standard scaling.<br>\nWITH MEAN : Centers the data with mean before scaling.<br>\nWITH STANDARD DEVIATION : Scales the data to unit standard deviation.<br>",
      "examples": "<h2> Standard Scaler Node Example</h2>\n<br>\nConsider the below <b>Standard Scaler</b> output for the <b>features</b> column<br>\n<br>\nid features scaled_features<br>\n0 [1.0, 2.0, 3.0, 4.0] [-1.3416407864998738, -0.4472135954999579, 0.4472135954999579, 1.3416407864998738]<br>\n1 [-1.0, -2.0, -3.0, -4.0] [1.3416407864998738, 0.4472135954999579, -0.4472135954999579, -1.3416407864998738]<br>\nIn this example, the input column is features and the output column is scaled_features. The standard scaler scales the features to unit standard deviation by subtracting the mean of the features and then dividing by the standard deviation. The withMean parameter is set to true and withStd parameter is set to true. Here the mean of the features is (1.0+2.0+3.0+4.0)/4 = 2.5 and the standard deviation is sqrt((1^2+2^2+3^2+4^2)/4-2.5^2) = 1.2909944487358056.<br>",
      "type": "ml-estimator",
      "nodeClass": "fire.nodes.ml.NodeStandardScaler",
      "x": "484.969px",
      "y": "489.969px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCol",
          "value": "Vector_Data",
          "widget": "variable",
          "title": "Input Column",
          "description": "The input column name",
          "datatypes": [
            "vectorudt"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "Vector_Data_Scaled",
          "widget": "textfield",
          "title": "Output Column",
          "description": "The output column name",
          "datatypes": [
            "vectorudt"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "withMean",
          "value": "false",
          "widget": "array",
          "title": "With Mean",
          "description": "Centers the data with mean before scaling.",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "withStd",
          "value": "true",
          "widget": "array",
          "title": "With Standard Dev",
          "description": "Scales the data to unit standard deviation",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "19",
      "name": "Vector Assembler",
      "description": "Merges multiple columns into a vector column.",
      "details": "",
      "examples": "<h2> h2: VectorAssembler Node Example</h2>\n<br>\nAssume that we have a DataFrame with the columns id, hour, mobile, userFeatures, and clicked:<br>\n<br>\n id | hour | mobile | userFeatures     | clicked<br>\n----|------|--------|------------------|---------<br>\n 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0<br>\n<br>\n If we set VectorAssembler's <b>input Selected columns</b> to hour, mobile, and userFeatures and <b>output column</b> to features, after transformation we should get the following DataFrame:<br>\n<br>\n id | hour | mobile | userFeatures     | clicked | features<br>\n----|------|--------|------------------|---------|-----------------------------<br>\n 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0     | [18.0, 1.0, 0.0, 10.0, 0.5]<br>",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeVectorAssembler",
      "x": "461.969px",
      "y": "234.969px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Vector_Data_Scaled\"]",
          "widget": "variables",
          "title": "Input Columns",
          "description": "Input column of type - all numeric, boolean and vector",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float",
            "vectorudt"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "Vector_Features",
          "widget": "textfield",
          "title": "Output Column",
          "description": "Output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "handleInvalid",
          "value": "error",
          "widget": "array",
          "title": "Handle Invalid",
          "description": "How to handle invalid data (NULL values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output).",
          "optionsArray": [
            "error",
            "skip",
            "keep"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "21",
      "name": "String Indexer",
      "description": "StringIndexer encodes a string column of labels to a column of label indices",
      "details": "<h2> String Indexer Node Details</h2>\n<br>\nThe String Indexer node encodes a string column of labels to a column of label indices. The indices are in [0, numLabels).<br>\n<br>\nBy default, this is ordered by label frequencies so the most frequent label gets index 0. The ordering behavior is controlled by setting <b>STRING ORDER TYPE</b>. Its default value is ‘frequencyDesc’. In case of equal frequency when under frequencyDesc/Asc, the strings are further sorted alphabetically<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> HANDLE INVALID : Specifies how to handle invalid data (unseen or NULL values) in features and label column of string type. Options are 'skip' (filter out rows with invalid data), or error (throw an error).</li>\n<li> VARIABLES : Allows multiple string columns to be selected for conversion.</li>\n<li> Input Columns : Select the column which needs to be converted.</li>\n<li> Output Columns : The name of the output converted column.</li>\n<li> STRING ORDER TYPE : Specifies how to order labels of string column. (default = \"frequencyDesc\")</li>\n</ul>\n    \"frequencyDesc\": descending order by label frequency (most frequent label assigned 0)<br>\n    \"frequencyAsc\": ascending order by label frequency (least frequent label assigned 0)<br>\n    \"alphabetDesc\": descending alphabetical order<br>\n    \"alphabetAsc\": ascending alphabetical order<br>",
      "examples": "<h2> String Indexer Node Example</h2>\n<br>\nAssume that we have the following DataFrame with columns id and category:<br>\n<br>\n id | category<br>\n----|----------<br>\n 0  | a<br>\n 1  | b<br>\n 2  | c<br>\n 3  | a<br>\n 4  | a<br>\n 5  | c<br>\ncategory is a string column with three labels: \"a\", \"b\", and \"c\". Applying <b>StringIndexer</b> with <b>category</b> as the input column and <b>categoryIndex</b> as the output column, we should get the following:<br>\n<br>\n id | category | categoryIndex<br>\n----|----------|---------------<br>\n 0  | a        | 0.0<br>\n 1  | b        | 2.0<br>\n 2  | c        | 1.0<br>\n 3  | a        | 0.0<br>\n 4  | a        | 0.0<br>\n 5  | c        | 1.0<br>\n\"a\" gets index 0 because it is the most frequent, followed by \"c\" with index 1 and \"b\" with index 2.<br>",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeStringIndexer",
      "x": "192.969px",
      "y": "233.969px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "handleInvalid",
          "value": "error",
          "widget": "array",
          "title": "Handle Invalid",
          "description": "Invalid entries to be skipped or thrown error",
          "optionsArray": [
            "skip",
            "error"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Sex\",\"Housing\",\"Saving_Accounts\",\"Checking_Account\",\"Purpose\",\"Risk\"]",
          "widget": "variables_list_select",
          "title": "Input Columns",
          "description": "Input columns for encoding",
          "datatypes": [
            "string"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "[\"Sex_Indexed\",\"Housing_Indexed\",\"SavingAccounts_Indexed\",\"CheckingAccount_Indexed\",\"Purpose_Indexed\",\"Risk_Indexed\"]",
          "widget": "variables_list_textfield",
          "title": "Output Columns",
          "description": "Output columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "stringOrderType",
          "value": "frequencyDesc",
          "widget": "array",
          "title": "String Order Type",
          "description": "Param for how to order labels of string column",
          "optionsArray": [
            "frequencyDesc",
            "frequencyAsc",
            "alphabetDesc",
            "alphabetAsc"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "scala"
    },
    {
      "id": "22",
      "name": "Cast To Single Type",
      "description": "This node creates a new DataFrame by casting the specified input columns to a new data type",
      "details": "This node creates a new DataFrame by casting the specified input columns to a new data type. All the selected columns would be cast to the specified data type.<br>\n<br>\nThe boolean field Replace Existing Columns indicates whether the existing column should be replaced or a new column should be created.<br>",
      "examples": "If incoming Dataframe has following columns with below specified datatype:<br>\n<br>\n<ul>\n<li> CUST_ID : Integer</li>\n<li> CUST_NAME : String</li>\n<li> DOB : Datetime</li>\n<li> AGE : Integer</li>\n</ul>\nand [DOB] and [AGE] are selected for casting to [STRING] datatype then outgoing Dataframe would have below datatypes:<br>\n<br>\n<ul>\n<li> CUST_ID : Integer</li>\n<li> CUST_NAME : String</li>\n<li> DOB : String</li>\n<li> AGE : String</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCastColumnType",
      "x": "327px",
      "y": "232px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Credit_Amount\",\"Duration\",\"Age\",\"Job\",\"Id\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be cast to new data type",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColType",
          "value": "DOUBLE",
          "widget": "array",
          "title": "New Data Type",
          "description": "New data type for the selected columns (INTEGER, DOUBLE, STRING, LONG, SHORT)",
          "optionsArray": [
            "BOOLEAN",
            "BYTE",
            "DATE",
            "DECIMAL",
            "DOUBLE",
            "FLOAT",
            "INTEGER",
            "LONG",
            "SHORT",
            "STRING",
            "TIMESTAMP"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replaceExistingCols",
          "value": "true",
          "widget": "array",
          "title": "Replace Existing Cols?",
          "description": "Whether to replace existing columns or create new ones?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "24",
      "name": "Find And Replace Using Regex Advanced",
      "description": "This node finds and replaces text in a column containing string",
      "details": "This node finds and replaces text in a column containing string with another one.<br>\n<br>\nString can be a single character or a combination of words.<br>\n<br>\nIn this node multiple find and replace conditions can be entered for one or multiple columns in one go. <br>\n<br>\nOutgoing Dataframe would be created after processing of all conditions.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021-01-01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019-05-04        |    11 000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018-06-07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017-02-01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020-12-21        |    78 999.00    |    BAD<br>\n<br>\nif FindAndReplaceUsingRegexMultiple node is configured as below:<br>\n<br>\nINPUT COLUMNS    |   FIND    |    REPLACE \t<br>\n----------------------------------------------<br>\nDATE_OF_JOINING  |   \\-      |    \\/<br>\nSALARY           |   \\s      |    ,<br>\nPERFORMANCE      |   BAD     |    NOT SO GOOD<br>\n<br>\nthen outgoing Dataframe would be created as below<br>\nafter replacement of occurrence of [-] with [/] in [DATE_OF_JOINING] column<br>\nand  replacement of occurrence of [SPACES] with [,] in [SALARY]<br>\nand  replacement of occurrence of [BAD] with [NOT SO GOOD] in [PERFORMANCE] column:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021/01/01        |    12,000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019/05/04        |    11,000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018/06/07        |    34,000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017/02/01        |    12,500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020/12/21        |    78,999.00    |    NOT SO GOOD<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFindAndReplaceUsingRegexMultiple",
      "x": "47.5625px",
      "y": "446.594px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Risk\",\"Risk\"]",
          "widget": "variables_list_select",
          "title": "Input Columns",
          "description": "Columns on which to apply Regex",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "searchPatterns",
          "value": "[\"good\",\"bad\"]",
          "widget": "variables_list_textfield",
          "title": "Find",
          "description": "Enter Search Pattern",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replacePatterns",
          "value": "[\"Low\",\"High\"]",
          "widget": "variables_list_textfield",
          "title": "Replace",
          "description": "Enter replacement Value",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "26",
      "name": "Spark Predict",
      "description": "Predict node takes in a DataFrame and Model and makes predictions",
      "details": "Predict node takes in a DataFrame and Model and makes predictions on the data using the Model.<br>",
      "examples": "",
      "type": "ml-predict",
      "nodeClass": "fire.nodes.ml.NodePredict",
      "x": "772px",
      "y": "283px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "27",
      "name": "Binary Classification Evaluator",
      "description": "Evaluator for binary classification, which expects two input columns: rawPrediction and label.",
      "details": "Evaluator for binary classification, which expects two input columns: rawPrediction and label.<br>\n<br>\n<br>\nMore at Spark MLlib/ML docs page : <a href=\"http://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification\" target=\"_blank\">spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification</a><br>",
      "examples": "<h2>Below example is available at : <a href=\"https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification\" target=\"_blank\">spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification</a></h2>\n<br>\nimport org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS<br>\nimport org.apache.spark.mllib.evaluation.BinaryClassificationMetrics<br>\nimport org.apache.spark.mllib.regression.LabeledPoint<br>\nimport org.apache.spark.mllib.util.MLUtils<br>\n<br>\n// Load training data in LIBSVM format<br>\nval data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_binary_classification_data.txt\")<br>\n<br>\n// Split data into training (60%) and test (40%)<br>\nval Array(training, test) = data.randomSplit(Array(0.6, 0.4), seed = 11L)<br>\ntraining.cache()<br>\n<br>\n// Run training algorithm to build the model<br>\nval model = new LogisticRegressionWithLBFGS()<br>\n  .setNumClasses(2)<br>\n  .run(training)<br>\n<br>\n// Clear the prediction threshold so the model will return probabilities<br>\nmodel.clearThreshold<br>\n<br>\n// Compute raw scores on the test set<br>\nval predictionAndLabels = test.map { case LabeledPoint(label, features) =><br>\n  val prediction = model.predict(features)<br>\n  (prediction, label)<br>\n}<br>\n<br>\n// Instantiate metrics object<br>\nval metrics = new BinaryClassificationMetrics(predictionAndLabels)<br>\n<br>\n// Precision by threshold<br>\nval precision = metrics.precisionByThreshold<br>\nprecision.collect.foreach { case (t, p) =><br>\n  println(s\"Threshold: $t, Precision: $p\")<br>\n}<br>\n<br>\n// Recall by threshold<br>\nval recall = metrics.recallByThreshold<br>\nrecall.collect.foreach { case (t, r) =><br>\n  println(s\"Threshold: $t, Recall: $r\")<br>\n}<br>\n<br>\n// Precision-Recall Curve<br>\nval PRC = metrics.pr<br>\n<br>\n// F-measure<br>\nval f1Score = metrics.fMeasureByThreshold<br>\nf1Score.collect.foreach { case (t, f) =><br>\n  println(s\"Threshold: $t, F-score: $f, Beta = 1\")<br>\n}<br>\n<br>\nval beta = 0.5<br>\nval fScore = metrics.fMeasureByThreshold(beta)<br>\nfScore.collect.foreach { case (t, f) =><br>\n  println(s\"Threshold: $t, F-score: $f, Beta = 0.5\")<br>\n}<br>\n<br>\n// AUPRC<br>\nval auPRC = metrics.areaUnderPR<br>\nprintln(s\"Area under precision-recall curve = $auPRC\")<br>\n<br>\n// Compute thresholds used in ROC and PR curves<br>\nval thresholds = precision.map(_._1)<br>\n<br>\n// ROC Curve<br>\nval roc = metrics.roc<br>\n<br>\n// AUROC<br>\nval auROC = metrics.areaUnderROC<br>\nprintln(s\"Area under ROC = $auROC\")<br>",
      "type": "ml-evaluator",
      "nodeClass": "fire.nodes.ml.NodeBinaryClassificationEvaluator",
      "x": "757px",
      "y": "427px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "labelCol",
          "value": "Risk_Indexed",
          "widget": "variable",
          "title": "Label Column",
          "description": "The label column for model fitting.",
          "datatypes": [
            "double"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "predictionCol",
          "value": "prediction",
          "widget": "variable",
          "title": "Prediction Column",
          "description": "The prediction column.",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/IN-DATA/CREDIT-RISKRATING-PREDICTION/Final_Testing_Confusion_Matrix/",
          "widget": "textfield",
          "title": "Path",
          "description": "Save Confusion Matrix to Path",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "confusionMatrix",
          "value": "",
          "widget": "tab",
          "title": "Confusion Matrix",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "output_confusion_matrix_chart",
          "value": "false",
          "widget": "array",
          "title": "Output Confusion Matrix Chart",
          "description": "Whether to display Confusion Matrix Chart.",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "cmChartTitle",
          "value": "Title",
          "widget": "textfield",
          "title": "Confusion Matrix Chart Title",
          "description": "Title name to display in Confusion Matrix Chart",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "cmChartDescription",
          "value": "Visual Representation of Predicted vs. Actual Classes",
          "widget": "textfield",
          "title": "Confusion Matrix Chart Description",
          "description": "Description to display in Confusion Matrix Chart",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "confusionMatrixTargetLegend",
          "value": "Target",
          "widget": "textfield",
          "title": "Confusion Matrix Target Legend",
          "description": "Legend name to display for Target in Confusion Matrix",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "confusionMatrixPredictedLabelLegend",
          "value": "PredictedLabel",
          "widget": "textfield",
          "title": "Confusion Matrix PredictedLabel Legend",
          "description": "Legend name to display for Predicted Label in Confusion Matrix",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Description",
          "value": "",
          "widget": "tab",
          "title": "Confusion Matrix Description",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "confusionMatrixRowDescription",
          "value": "",
          "widget": "textarea_rich",
          "title": "Confusion Matrix Outcome description",
          "description": "Add the business details of the outcome of the confusion matrix rows",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "ROC Curve",
          "value": "",
          "widget": "tab",
          "title": "ROC Curve",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "output_roc_chart",
          "value": "false",
          "widget": "array",
          "title": "Output ROC Curve",
          "description": "Whether to display confusion matrix chart.",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "roc_title",
          "value": "Title",
          "widget": "textfield",
          "title": "ROC Curve Chart Title",
          "description": "Title name to display in ROC Curve Chart",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "roc_description",
          "value": "Receiver operating characteristic (ROC) curve",
          "widget": "textfield",
          "title": "ROC Curve Chart Description",
          "description": "Add Description for ROC Curve Chart",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "xlabel",
          "value": "False Positive Rate (specificity)",
          "widget": "textfield",
          "title": "X Label",
          "description": "X label",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "ylabel",
          "value": "True Positive Rate (sensitivity)",
          "widget": "textfield",
          "title": "Y Label",
          "description": "Y Label",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "scala"
    },
    {
      "id": "28",
      "name": "Spark ML Model Load",
      "details": "This node loads a previously saved Spark ML model into the workflow. This allows you to reuse trained models for scoring new data or further analysis.<br>",
      "examples": "Configuration:<br>\n<br>\nOutput Storage Level: Choose the storage level for the loaded model.<br>\nPath: Specify the path to the saved model file. You can use the \"Browse File System\" button to navigate and select the model file.<br>\nStatic Path: Set this to true if the model path is a static path.<br>\nModel Type: Specify the type of the model (e.g., KMeans, LogisticRegression, RandomForest).<br>\n<br>\nLet's say you have trained a Spark ML model for customer churn prediction and want to save it ,<br>\n<br>\nPath:data/CPG/Customer-Churn-Prediction/ModelName<br>\nStatic Path:true<br>\n<br>\nit would save the model at the given location with the model name,and can be used later.<br>",
      "type": "ml-modelload",
      "nodeClass": "fire.nodes.ml.NodeModelLoad",
      "x": "750px",
      "y": "97px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/BFSI/Credit-Decisioning/Model/",
          "widget": "textfield",
          "title": "Path",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fixedPath",
          "value": "true",
          "widget": "array",
          "title": "Static path",
          "description": "Set this to true if you have saved the model to a static path(without UUID) while training the model.",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "modelType",
          "value": "RANDOM_FOREST_CLASSIFICATION",
          "widget": "array",
          "title": "Model Type",
          "description": "Type of ML model to load",
          "optionsArray": [
            "AFT_SURVIVAL_REGRESSION",
            "ALS",
            "CHI_SQ_SELECTOR",
            "COUNT_VECTORIZER",
            "CROSS_VALIDATOR",
            "DISTRIBUTED_LDA",
            "DECISION_TREE_CLASSIFICATION",
            "DECISION_TREE_REGRESSION",
            "GBT_CLASSIFICATION",
            "GBT_REGRESSION",
            "IDF",
            "ISOTONIC_REGRESSION",
            "KMEANS",
            "LDA",
            "LINEAR_REGRESSION",
            "LOGISTIC_REGRESSION",
            "MIN_MAX_SCALER",
            "NAIVE_BAYES",
            "PCA",
            "PIPELINE",
            "RANDOM_FOREST_CLASSIFICATION",
            "RANDOM_FOREST_REGRESSION",
            "STANDARD_SCALER",
            "STRING_INDEXER",
            "STRING_INDEXER_ADVANCED",
            "ONE_HOT_ENCODER_ADVANCED",
            "MAX_ABS_SCALER",
            "ROBUST_SCALER",
            "IMPUTER",
            "ONE_HOT_ENCODER_ADVANCED",
            "NORMALIZER",
            "VECTOR_INDEXER",
            "WORD2VEC"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "scala"
    },
    {
      "id": "29",
      "name": "Graph Group By Column",
      "description": "Groups the data by the given column and plots the number of records in each group",
      "details": "<h2>Graph Group By Column Details</h2>\n<br>\nThis node represents the distribution/count of a group of data in Graphical format.<br>\n<br>\nA numeric column from the incoming dataset is selected to aggregate data into multiple groups. The count of data points in each group is plotted in the Chart.<br>\n<br>\nThe chart type used to represent data can be selected in the node.<br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   TITLE :- The title of a graph can be set here.</li>\n<li>   X LABEL :- X-axis label can be set here.</li>\n<li>   Y LABEL :- Y-axis label can be set here.</li>\n<li>   MAX VALUES TO DISPLAY :- The total number of data points can be selected here.</li>\n<li>   CHART COLORS :- The different types of color can be selected for better visualization.</li>\n<li>   GROUP BY COLUMN :- A categorical column is selected to show the counts of observations of each category.</li>\n<li>   CHART TYPE :- The desired chart can be selected from the drop-down list(Column chart, Bar Chart, Line Chart)</li>\n</ul>\n<h4> Output</h4>\n<ul>\n<li>   This node is good for comparing between each element in the categories and comparing elements across categories.</li>\n</ul>",
      "examples": "Example:<br>\n<br>\nLet's say you have a dataset of customer transactions, and you want to visualize the number of transactions for each customer category.<br>\n<br>\nConfiguration:<br>\n<br>\nGroup By Column: CustomerCategory<br>\nChart Type: Column Chart<br>\nOutput:<br>\n<br>\nThe node will generate a bar chart showing the count of transactions for each customer category. The X-axis will display the customer categories, and the Y-axis will display the number of transactions.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.graph.NodeGraphGroupByColumn",
      "x": "1089.89px",
      "y": "277.889px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "Customer Distribution by Risk Status",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "titleColor",
          "value": "#27A588",
          "widget": "textcolors",
          "title": "Title Color",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "description",
          "value": "",
          "widget": "textareafield",
          "title": "Description",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "descriptionColor",
          "value": "#6D6E70",
          "widget": "textcolors",
          "title": "Description Color",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "xlabel",
          "value": "Risk Status",
          "widget": "textfield",
          "title": "X Label",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "ylabel",
          "value": "Count",
          "widget": "textfield",
          "title": "Y Label",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "maxValuesToDisplay",
          "value": "20",
          "widget": "textfield",
          "title": "Max Values To Display",
          "description": "Maximum number of values to display in result.",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "chartColors",
          "value": "#77C8D0,#FFE3B2,#FAA19B,#A1BDFD,#B6D7D0,#FFB2C8,#FFD5BE,#C7D2FF,#83E3F4,#D1BFFF,#649BF7,#F8C9EE,#219AAD,#FFBFA3",
          "widget": "colors",
          "title": "Chart Colors",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "groupByColumn",
          "value": "prediction",
          "widget": "variable",
          "title": "Group By Column",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "graphType",
          "value": "COLUMNCHART",
          "widget": "enum",
          "title": "Chart Type",
          "optionsMap": {
            "COLUMNCHART": "Column Chart",
            "BARCHART": "Bar Chart",
            "LINECHART": "Line Chart"
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "30",
      "name": "Find And Replace Using Regex Advanced",
      "description": "This node finds and replaces text in a column containing string",
      "details": "This node finds and replaces text in a column containing string with another one.<br>\n<br>\nString can be a single character or a combination of words.<br>\n<br>\nIn this node multiple find and replace conditions can be entered for one or multiple columns in one go. <br>\n<br>\nOutgoing Dataframe would be created after processing of all conditions.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021-01-01        |    12 000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019-05-04        |    11 000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018-06-07        |    34 000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017-02-01        |    12 500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020-12-21        |    78 999.00    |    BAD<br>\n<br>\nif FindAndReplaceUsingRegexMultiple node is configured as below:<br>\n<br>\nINPUT COLUMNS    |   FIND    |    REPLACE \t<br>\n----------------------------------------------<br>\nDATE_OF_JOINING  |   \\-      |    \\/<br>\nSALARY           |   \\s      |    ,<br>\nPERFORMANCE      |   BAD     |    NOT SO GOOD<br>\n<br>\nthen outgoing Dataframe would be created as below<br>\nafter replacement of occurrence of [-] with [/] in [DATE_OF_JOINING] column<br>\nand  replacement of occurrence of [SPACES] with [,] in [SALARY]<br>\nand  replacement of occurrence of [BAD] with [NOT SO GOOD] in [PERFORMANCE] column:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE       |    DATE_OF_JOINING   |    SALARY       |    PERFORMANCE<br>\n---------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25        |    2021/01/01        |    12,000.00    |    GOOD<br>\nE02       |    JOHN        |    SALES      |    35        |    2019/05/04        |    11,000.00    |    VERY GOOD<br>\nE03       |    MARTIN      |    MARKETING  |    40        |    2018/06/07        |    34,000       |    AVERAGE<br>\nE04       |    TONY        |    MARKETING  |    45        |    2017/02/01        |    12,500.00    |    VERY VERY GOOD<br>\nE05       |    MARK        |    HR         |    25        |    2020/12/21        |    78,999.00    |    NOT SO GOOD<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFindAndReplaceUsingRegexMultiple",
      "x": "990px",
      "y": "280px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"prediction\",\"prediction\"]",
          "widget": "variables_list_select",
          "title": "Input Columns",
          "description": "Columns on which to apply Regex",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "searchPatterns",
          "value": "[\"1.0\",\"0.0\"]",
          "widget": "variables_list_textfield",
          "title": "Find",
          "description": "Enter Search Pattern",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replacePatterns",
          "value": "[\"High\",\"Low\"]",
          "widget": "variables_list_textfield",
          "title": "Replace",
          "description": "Enter replacement Value",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "31",
      "name": "Cast To Single Type",
      "description": "This node creates a new DataFrame by casting the specified input columns to a new data type",
      "details": "This node creates a new DataFrame by casting the specified input columns to a new data type. All the selected columns would be cast to the specified data type.<br>\n<br>\nThe boolean field Replace Existing Columns indicates whether the existing column should be replaced or a new column should be created.<br>",
      "examples": "If incoming Dataframe has following columns with below specified datatype:<br>\n<br>\n<ul>\n<li> CUST_ID : Integer</li>\n<li> CUST_NAME : String</li>\n<li> DOB : Datetime</li>\n<li> AGE : Integer</li>\n</ul>\nand [DOB] and [AGE] are selected for casting to [STRING] datatype then outgoing Dataframe would have below datatypes:<br>\n<br>\n<ul>\n<li> CUST_ID : Integer</li>\n<li> CUST_NAME : String</li>\n<li> DOB : String</li>\n<li> AGE : String</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCastColumnType",
      "x": "879px",
      "y": "272px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"prediction\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be cast to new data type",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColType",
          "value": "STRING",
          "widget": "array",
          "title": "New Data Type",
          "description": "New data type for the selected columns (INTEGER, DOUBLE, STRING, LONG, SHORT)",
          "optionsArray": [
            "BOOLEAN",
            "BYTE",
            "DATE",
            "DECIMAL",
            "DOUBLE",
            "FLOAT",
            "INTEGER",
            "LONG",
            "SHORT",
            "STRING",
            "TIMESTAMP"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replaceExistingCols",
          "value": "true",
          "widget": "array",
          "title": "Replace Existing Cols?",
          "description": "Whether to replace existing columns or create new ones?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "32",
      "name": "Save CSV",
      "description": "Saves the DataFrame into the specified location in CSV Format",
      "details": "This node saves incoming Dataframe into the specified location in CSV format.<br>",
      "examples": "path-folder1/folder2/filename<br>\n<br>\nthe file will be saved under the file name at the path provided<br>\nif folder is not present it will be created and save the file<br>\nif the file already exists selection in save mode determines what happens to the file,append-adds the file data to it overwrite-replaces the file altogether<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveCSV",
      "x": "1003.67px",
      "y": "493.556px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/BFSI/Credit-Decisioning/Predictive-Analysis-Input/",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the CSV files",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "34",
      "name": "Drop Columns",
      "description": "This node creates a new DataFrame by dropping the specified columns",
      "details": "<h2>Drop Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame by dropping the selected columns.<br>\n<br>\nIt drops the selected columns from the outgoing dataframe. <br>\n<br>\nColumns that need to be dropped are to be selected in the 'Selected' list. Multiple columns can be selected in the list that needs to be dropped.<br>",
      "examples": "<h2>Drop Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe having following columns:<br>\n<br>\n<ul>\n<li> CUST_CD</li>\n<li> CUST_NAME</li>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>\n<h4>Drop Columns Node Configuration And Output</h4>\n<br>\n[DOB] and [ADDRESS] columns are selected to be dropped from the outgoing Dataframe. <br>\nOutgoing dataframe would contain only below two columns after dropping the selected columns:<br>\n<br>\n<ul>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropColumns",
      "x": "885.778px",
      "y": "407.667px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropCols",
          "value": "[\"Vector_Data\",\"Vector_Data_Scaled\",\"Vector_Features\",\"rawPrediction\",\"probability\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "The columns to be excluded from the output DataFrame",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "5",
      "target": "18",
      "id": 1
    },
    {
      "source": "18",
      "target": "19",
      "id": 2
    },
    {
      "source": "3",
      "target": "21",
      "id": 3
    },
    {
      "source": "21",
      "target": "22",
      "id": 4
    },
    {
      "source": "22",
      "target": "5",
      "id": 5
    },
    {
      "source": "1",
      "target": "24",
      "id": 6
    },
    {
      "source": "24",
      "target": "3",
      "id": 7
    },
    {
      "source": "26",
      "target": "27",
      "id": 8
    },
    {
      "source": "19",
      "target": "26",
      "id": 9
    },
    {
      "source": "28",
      "target": "26",
      "id": 10
    },
    {
      "source": "26",
      "target": "31",
      "id": 11
    },
    {
      "source": "31",
      "target": "30",
      "id": 12
    },
    {
      "source": "30",
      "target": "29",
      "id": 13
    },
    {
      "source": "26",
      "target": "34",
      "id": 14
    },
    {
      "source": "34",
      "target": "32",
      "id": 15
    }
  ],
  "dataSetDetails": [],
  "engine": "scala"
}