{
  "name": "Fraud-Claim-Analysis",
  "uuid": "29d2db42-0ce6-4dc9-8e06-22cf44004455",
  "category": "GENAI",
  "description": "-",
  "parameters": " --var getStarted=true --var destinationPath=/home/sparkflows/fire-data/data/GENAI/Fraudulent-Transaction-Processing/Raw-Data/Fraud-Claim/mail_chain.pdf --var uploadFile=true --var CustomerID=C001 --var submit1=true",
  "nodes": [
    {
      "id": "32",
      "name": "Document To Text",
      "iconImage": "/images/icons/node-icon/PDF.svg",
      "description": "Extract text from Documents",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeDocumentToText",
      "x": "218px",
      "y": "143px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "filePath",
          "value": "${destinationPath}",
          "widget": "textfield",
          "title": "Directory/File Path",
          "description": "Select a Pdf/Text/Docx File or Directory",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileType",
          "value": "pdf",
          "widget": "array",
          "title": "Document Type",
          "description": "Choose a Document Type.If Empty all four types of files will be processed.",
          "optionsArray": [
            "pdf",
            "txt",
            "docx",
            "image"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "recursive",
          "value": "false",
          "widget": "array",
          "title": "Recursive",
          "description": "Recursively process the documents in the given Directory",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "imgPathCols",
          "value": "[]",
          "widget": "variables",
          "title": "Select Image Column",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "isImage",
          "value": "true",
          "widget": "array",
          "title": "Image Encoding",
          "description": "Adds a column for base64 encoded pages",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "saveImageDir",
          "value": "",
          "widget": "textfield",
          "title": "Save Images Directory Path",
          "description": "The file path to save the output",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "columns",
          "value": "",
          "widget": "tab",
          "title": "Rename Output Cols",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileNameCol",
          "value": "fileName",
          "widget": "textfield",
          "title": "File Name Column",
          "description": "Rename File Name Column. Defaults to fileName",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "contentCol",
          "value": "content",
          "widget": "textfield",
          "title": "Content Column",
          "description": "Rename Content Column. Defaults to content",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pageNumberCol",
          "value": "pageNumber",
          "widget": "textfield",
          "title": "Page Number Column",
          "description": "Rename Page Number Column. Defaults to pageNumber",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "base64ImageCol",
          "value": "base64ImageCol",
          "widget": "textfield",
          "title": "Base64 Image Column",
          "description": "Rename Image Column. Defaults to base64ImageCol",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "33",
      "name": " Multi LLM Query",
      "iconImage": "/images/icons/node-icon/Graph_group_by_column.svg",
      "description": "This node is designed to query multiple large language models (LLMs) from different providers (OpenAI, Bedrock, Gemini) using a vector database (e.g., Pinecone or FAISS) or a DataFrame. It processes user queries and returns responses by querying the selected vector database.",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeMultiLLMQuery",
      "x": "412px",
      "y": "141px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "task",
          "value": "other",
          "widget": "key_value_array",
          "title": "Select Task",
          "description": "Specify the task to perform: summary, translation, topic extraction, or other.",
          "optionsMap": {
            "summary": "Generate Summary in bullet points ",
            "translation": "Translate the following content to default language",
            "topic_extraction": "Extract key topics from the following content.",
            "other": ""
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "customPrompt",
          "value": "You are an expert to extract details from unstructurred documents. I am giving some mail chain images as well as the text written in the emails. These are nothing but some email conversation between a customer and customer executive. You need to extract the below details in respective format.\nIn the summary section put the over all chat between the customer and the customer executive\n\nCustomeId|TransactionId|SummaryOfTheConversation|TransactionLocation|TransactionAmount|Merchant|PaymentMethod|transactionDate\n\nOnly give the values.. Do not include the header. values will be in the same order",
          "widget": "textareafield",
          "title": "Prompt",
          "description": "Custom prompt to override the default instructions.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "userQueryCol",
          "value": "",
          "widget": "variable",
          "title": "User Query Column",
          "description": "Column name for user query, (if the query is in a column)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "contentCol",
          "value": "content",
          "widget": "variable",
          "title": "Content Column",
          "description": "Column name for the text content.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "llmConnection",
          "value": "azure-openai",
          "widget": "object_array",
          "title": "Select Connection",
          "description": "Select Connection",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "temperature",
          "value": "0",
          "widget": "textfield",
          "title": "Temperature",
          "description": "Temperature setting for the model (default: 0).",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "imageCol",
          "value": "base64ImageCol",
          "widget": "variable",
          "title": "Image Column",
          "description": "Column name for the base 64 image.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputMode",
          "value": "image",
          "widget": "array",
          "title": "Mode Selection",
          "description": "Select the model to use (text, image, text+image).",
          "optionsArray": [
            "text",
            "image",
            "text+image"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateMode",
          "value": "NONE",
          "widget": "enum",
          "title": "Aggregate Response",
          "optionsMap": {
            "NONE": "Do not aggregate rows",
            "ALL": "Aggregate all rows",
            "PERFILE": "Aggregate per file"
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "numPartitions",
          "value": "3",
          "widget": "textfield",
          "title": "Number of Partitions",
          "description": "Number of Partitions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileNameCol",
          "value": "fileName",
          "widget": "variable",
          "title": "File Name Column",
          "description": "Select File Name Column",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pageNumberCol",
          "value": "pageNumber",
          "widget": "variable",
          "title": "Page Number Column",
          "description": " Select Page Number column.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "34",
      "name": "Select Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "577px",
      "y": "139px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "[\"response\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "35",
      "name": "Field Splitter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node splits the string of the specified input column using the specified delimiter",
      "details": "Splits the string of the specified input column using the specified delimiter. The new column names are specified by the user.<br>\n<br>\nThe new dataframe would have the new columns added to it.<br>",
      "examples": "If a String Column stores values in [PRD_CD]:[PRD_NAME] format and incoming Dataframe has a value as CD01:DrillMachine <br>\nthen using : as Separator to split data into two Columns (Col1, Col2) would result in followings:<br>\n<br>\n<ul>\n<li> Col1 : CD01</li>\n<li> Col2 : DrillMachine</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFieldSplitter",
      "x": "726px",
      "y": "143px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCol",
          "value": "response",
          "widget": "variable",
          "title": "Input Column",
          "description": "Input column name",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "CustomeId,TransactionId,SummaryOfTheConversation,TransactionLocation,TransactionAmount,Merchant,PaymentMethod,transactionDate",
          "widget": "textarea_small",
          "title": "Output Columns",
          "description": "New column names separated by comma (eg: col1,co2,col3)",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "\\|",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to split the input column value (default: space)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "onError",
          "value": "die",
          "widget": "array",
          "title": "On Error",
          "description": "",
          "optionsArray": [
            "die",
            "ignore"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "37",
      "name": "Read CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>InferSchema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the InferSchema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "728.875px",
      "y": "381.875px",
      "hint": "Infer the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/GENAI/Fraudulent-Transaction-Processing/Raw-Data/Device_Location.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"customer_id\",\"date\",\"time\",\"location\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Columns from CSV",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"DATE\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "properties",
          "value": "",
          "widget": "tab",
          "title": "Properties",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Properties Name",
          "description": "Extra options/properites available while executing in Read CSV.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Properties Value",
          "description": "Config Values for the Corresponding properites name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "39",
      "name": "Read CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>InferSchema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the InferSchema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "784.875px",
      "y": "494.875px",
      "hint": "Infer the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/GENAI/Fraudulent-Transaction-Processing/Raw-Data/Transaction_History.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"transaction_id\",\"customer_id\",\"date\",\"amount\",\"currency\",\"type\",\"merchant_id_or_recipient_id\",\"location\",\"status\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Columns from CSV",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "properties",
          "value": "",
          "widget": "tab",
          "title": "Properties",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Properties Name",
          "description": "Extra options/properites available while executing in Read CSV.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Properties Value",
          "description": "Config Values for the Corresponding properites name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "40",
      "name": "Read CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>InferSchema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the InferSchema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "1001.88px",
      "y": "76.875px",
      "hint": "Infer the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/GENAI/Fraudulent-Transaction-Processing/Raw-Data/Customer_Details.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"customer_id\",\"name\",\"email\",\"phone\",\"address\",\"registration_date\",\"account_status\",\"risk_score\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Columns from CSV",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "properties",
          "value": "",
          "widget": "tab",
          "title": "Properties",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Properties Name",
          "description": "Extra options/properites available while executing in Read CSV.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Properties Value",
          "description": "Config Values for the Corresponding properites name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "41",
      "name": "Join Using SQL",
      "iconImage": "fa fa-stumbleupon",
      "description": "This node registers the incoming DataFrames as temporary tables and executes the SQL provided",
      "details": "<h2>Join Using SQL Details</h2>\n<br>\n<ul>\n<li> This node receives two or more input data frames and creates the corresponding temporary tables.</li>\n<li> Allows the user to write a SQL query to join these temporary tables.</li>\n<li> The resulting output dataframe contains the output of the SQL execution.</li>\n</ul>",
      "examples": "<h2>Join Using SQL Examples</h2>\n<br>\n<h4> Two-table joins</h4>\n<br>\nThe following example shows a two-table join:<br>\nSELECT order_num, lname, fname FROM tempTable1, tempTable2<br>\nWHERE tempTable1.customer_num = tempTable2.customer_num<br>\n<br>\n<h4> Multi-table joins</h4>\n<br>\nThe following multiple-table join yields the company name of the customer who ordered an item as well as its stock number and manufacturer code:<br>\nSELECT DISTINCT company, stock_num, manu_code<br>\nFROM tempTable1 c, tempTable2 o, tempTable3 i<br>\nWHERE c.customer_num = o.customer_num<br>\nAND o.order_num = i.order_num;<br>\n<br>\n<h4> LEFT OUTER joins</h4>\n<br>\nThe below table join yields data of all customers irrespective of whether or not they have placed any orders:<br>\nSELECT c.ID, c.NAME, o.AMOUNT, o.DATE<br>\nFROM tempTable1 c<br>\nLEFT OUTER JOIN tempTable2 o<br>\nON (c.ID = o.CUSTOMER_ID)<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingSQL",
      "x": "898px",
      "y": "255px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTables",
          "value": "[\"tempTable1\",\"tempTable2\"]",
          "widget": "array_of_values",
          "title": "Temp Table Names",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "select t1.*, t2.location as CustomerActualLocation from tempTable1 t1 join tempTable2 t2 on t1.transactionDate = t2.date",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"response\",\"CustomeId\",\"TransactionId\",\"SummaryOfTheConversation\",\"TransactionLocation\",\"TransactionAmount\",\"Merchant\",\"PaymentMethod\",\"transactionDate\",\"CustomerActualLocation\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "42",
      "name": "Transaction History",
      "iconImage": "fa fa-stumbleupon",
      "description": "This node registers the incoming DataFrames as temporary tables and executes the SQL provided",
      "details": "<h2>Join Using SQL Details</h2>\n<br>\n<ul>\n<li> This node receives two or more input data frames and creates the corresponding temporary tables.</li>\n<li> Allows the user to write a SQL query to join these temporary tables.</li>\n<li> The resulting output dataframe contains the output of the SQL execution.</li>\n</ul>",
      "examples": "<h2>Join Using SQL Examples</h2>\n<br>\n<h4> Two-table joins</h4>\n<br>\nThe following example shows a two-table join:<br>\nSELECT order_num, lname, fname FROM tempTable1, tempTable2<br>\nWHERE tempTable1.customer_num = tempTable2.customer_num<br>\n<br>\n<h4> Multi-table joins</h4>\n<br>\nThe following multiple-table join yields the company name of the customer who ordered an item as well as its stock number and manufacturer code:<br>\nSELECT DISTINCT company, stock_num, manu_code<br>\nFROM tempTable1 c, tempTable2 o, tempTable3 i<br>\nWHERE c.customer_num = o.customer_num<br>\nAND o.order_num = i.order_num;<br>\n<br>\n<h4> LEFT OUTER joins</h4>\n<br>\nThe below table join yields data of all customers irrespective of whether or not they have placed any orders:<br>\nSELECT c.ID, c.NAME, o.AMOUNT, o.DATE<br>\nFROM tempTable1 c<br>\nLEFT OUTER JOIN tempTable2 o<br>\nON (c.ID = o.CUSTOMER_ID)<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingSQL",
      "x": "980px",
      "y": "465px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTables",
          "value": "[\"tempTable1\",\"tempTable2\"]",
          "widget": "array_of_values",
          "title": "Temp Table Names",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "select t1.* from tempTable1 as t1 join tempTable2 as t2 on t1.customer_id= t2.CustomeId",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"transaction_id\",\"customer_id\",\"date\",\"amount\",\"currency\",\"type\",\"merchant_id_or_recipient_id\",\"location\",\"status\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "43",
      "name": "Customer Details and Device Location",
      "iconImage": "fa fa-stumbleupon",
      "description": "This node registers the incoming DataFrames as temporary tables and executes the SQL provided",
      "details": "<h2>Join Using SQL Details</h2>\n<br>\n<ul>\n<li> This node receives two or more input data frames and creates the corresponding temporary tables.</li>\n<li> Allows the user to write a SQL query to join these temporary tables.</li>\n<li> The resulting output dataframe contains the output of the SQL execution.</li>\n</ul>",
      "examples": "<h2>Join Using SQL Examples</h2>\n<br>\n<h4> Two-table joins</h4>\n<br>\nThe following example shows a two-table join:<br>\nSELECT order_num, lname, fname FROM tempTable1, tempTable2<br>\nWHERE tempTable1.customer_num = tempTable2.customer_num<br>\n<br>\n<h4> Multi-table joins</h4>\n<br>\nThe following multiple-table join yields the company name of the customer who ordered an item as well as its stock number and manufacturer code:<br>\nSELECT DISTINCT company, stock_num, manu_code<br>\nFROM tempTable1 c, tempTable2 o, tempTable3 i<br>\nWHERE c.customer_num = o.customer_num<br>\nAND o.order_num = i.order_num;<br>\n<br>\n<h4> LEFT OUTER joins</h4>\n<br>\nThe below table join yields data of all customers irrespective of whether or not they have placed any orders:<br>\nSELECT c.ID, c.NAME, o.AMOUNT, o.DATE<br>\nFROM tempTable1 c<br>\nLEFT OUTER JOIN tempTable2 o<br>\nON (c.ID = o.CUSTOMER_ID)<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingSQL",
      "x": "1120px",
      "y": "275px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTables",
          "value": "[\"tempTable1\",\"tempTable2\"]",
          "widget": "array_of_values",
          "title": "Temp Table Names",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "SELECT t1.* , t2.risk_score from tempTable1 as t1 join tempTable2 as t2 on t1.CustomeId = t2.customer_id",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"response\",\"CustomeId\",\"TransactionId\",\"SummaryOfTheConversation\",\"TransactionLocation\",\"TransactionAmount\",\"Merchant\",\"PaymentMethod\",\"transactionDate\",\"CustomerActualLocation\",\"risk_score\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "45",
      "name": "Concat Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "1244px",
      "y": "273px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"CustomeId\",\"TransactionId\",\"SummaryOfTheConversation\",\"TransactionLocation\",\"TransactionAmount\",\"Merchant\",\"PaymentMethod\",\"transactionDate\",\"CustomerActualLocation\",\"risk_score\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "CustomerAndDevice",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "|",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "46",
      "name": "Concat Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "1131px",
      "y": "414px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"transaction_id\",\"customer_id\",\"date\",\"amount\",\"currency\",\"type\",\"merchant_id_or_recipient_id\",\"location\",\"status\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "TransactionHistory",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "|",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "47",
      "name": "SQL",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "details": "<h2>SQL Details</h2>\n<br>\nSQL node receives an input data frame. It creates a temporary table on top of that data frame. It executes the provided SQL in the node on the temporary table.<br>\n<br>\nThe resulting data frame of running the SQL is passed on to the next node.<br>",
      "examples": "<h2>SQL Examples</h2>\n<br>\nBelow are some examples of SQL. <br>\n<br>\nTemporary table name used : tempTable<br>\n<br>\nThe schema of the Input Dataframe is : id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> find the average price of houses</h4>\n<br>\nselect avg(price) as avg_price from tempTable<br>\n<br>\n<br>\n<h4> find bedrooms with avg price greater than 10000</h4>\n<br>\nselect bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000<br>\n<br>\n<br>\n<h4> details of houses with bedrooms avg price greater than 10000</h4>\n<br>\nselect tempTable.* , inner_table.avg_price from<br>\n(select bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000) as inner_table<br>\nJOIN tempTable ON(inner_table.bedrooms = tempTable.bedrooms)<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "1260px",
      "y": "412px",
      "hint": "Whenever the table is changed, go to InferSchema tab and Infer the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "SELECT concat_ws('\\n', collect_list(CustomerAndDevice)) AS combined_CustomerAndDevice\r\nFROM fire_temp_table;",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"combined_CustomerAndDevice\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "48",
      "name": "SQL",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "details": "<h2>SQL Details</h2>\n<br>\nSQL node receives an input data frame. It creates a temporary table on top of that data frame. It executes the provided SQL in the node on the temporary table.<br>\n<br>\nThe resulting data frame of running the SQL is passed on to the next node.<br>",
      "examples": "<h2>SQL Examples</h2>\n<br>\nBelow are some examples of SQL. <br>\n<br>\nTemporary table name used : tempTable<br>\n<br>\nThe schema of the Input Dataframe is : id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> find the average price of houses</h4>\n<br>\nselect avg(price) as avg_price from tempTable<br>\n<br>\n<br>\n<h4> find bedrooms with avg price greater than 10000</h4>\n<br>\nselect bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000<br>\n<br>\n<br>\n<h4> details of houses with bedrooms avg price greater than 10000</h4>\n<br>\nselect tempTable.* , inner_table.avg_price from<br>\n(select bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000) as inner_table<br>\nJOIN tempTable ON(inner_table.bedrooms = tempTable.bedrooms)<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "1183px",
      "y": "561px",
      "hint": "Whenever the table is changed, go to InferSchema tab and Infer the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "SELECT concat_ws('\\n', collect_list(TransactionHistory)) AS combined_TransactionHistory\r\nFROM fire_temp_table;",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"combined_TransactionHistory\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "49",
      "name": "Join Using SQL",
      "iconImage": "fa fa-stumbleupon",
      "description": "This node registers the incoming DataFrames as temporary tables and executes the SQL provided",
      "details": "<h2>Join Using SQL Details</h2>\n<br>\n<ul>\n<li> This node receives two or more input data frames and creates the corresponding temporary tables.</li>\n<li> Allows the user to write a SQL query to join these temporary tables.</li>\n<li> The resulting output dataframe contains the output of the SQL execution.</li>\n</ul>",
      "examples": "<h2>Join Using SQL Examples</h2>\n<br>\n<h4> Two-table joins</h4>\n<br>\nThe following example shows a two-table join:<br>\nSELECT order_num, lname, fname FROM tempTable1, tempTable2<br>\nWHERE tempTable1.customer_num = tempTable2.customer_num<br>\n<br>\n<h4> Multi-table joins</h4>\n<br>\nThe following multiple-table join yields the company name of the customer who ordered an item as well as its stock number and manufacturer code:<br>\nSELECT DISTINCT company, stock_num, manu_code<br>\nFROM tempTable1 c, tempTable2 o, tempTable3 i<br>\nWHERE c.customer_num = o.customer_num<br>\nAND o.order_num = i.order_num;<br>\n<br>\n<h4> LEFT OUTER joins</h4>\n<br>\nThe below table join yields data of all customers irrespective of whether or not they have placed any orders:<br>\nSELECT c.ID, c.NAME, o.AMOUNT, o.DATE<br>\nFROM tempTable1 c<br>\nLEFT OUTER JOIN tempTable2 o<br>\nON (c.ID = o.CUSTOMER_ID)<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingSQL",
      "x": "1376px",
      "y": "519px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTables",
          "value": "[\"tempTable1\",\"tempTable2\"]",
          "widget": "array_of_values",
          "title": "Temp Table Names",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "SELECT\r\n  (SELECT combined_CustomerAndDevice FROM tempTable1) AS combined_CustomerAndDevice,\r\n  (SELECT combined_TransactionHistory FROM tempTable2) AS combined_TransactionHistory;",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"combined_CustomerAndDevice\",\"combined_TransactionHistory\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "51",
      "name": " Multi LLM Query",
      "iconImage": "/images/icons/node-icon/Graph_group_by_column.svg",
      "description": "This node is designed to query multiple large language models (LLMs) from different providers (OpenAI, Bedrock, Gemini) using a vector database (e.g., Pinecone or FAISS) or a DataFrame. It processes user queries and returns responses by querying the selected vector database.",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeMultiLLMQuery",
      "x": "1546.78px",
      "y": "417.778px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "task",
          "value": "other",
          "widget": "key_value_array",
          "title": "Select Task",
          "description": "Specify the task to perform: summary, translation, topic extraction, or other.",
          "optionsMap": {
            "summary": "Generate Summary in bullet points ",
            "translation": "Translate the following content to default language",
            "topic_extraction": "Extract key topics from the following content.",
            "other": ""
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "customPrompt",
          "value": "I am Providing a fraud claim communication details with the customer id and his actual location and transaction location. Also I am giving you his transaction history. Based on this information, You have to evaluate wheteher the transaction is really a fraud one or not.. based on his transaction history, device location on the same day and his fraud claim communication. Based on that you have to give some reason why that transaction can be a fraud. If yes.. then just suggest some recommended Action and also the follow up message. If not then provide why the transaction is not fraud, with recommendate Action\nI need the response in below format separated by Pipe symbol. No other things I need.\n\n- For reason do not just copy paste from his mail communication.. Add some more information from your analytics. You have the device location , transaction location etc. Use those things.\n- Also in the recommended action, always give suggestion. Not give any Proper resolution. You will tell the exceutive to look into some more places. That is you will give the direction what should he will see to get the result\n- The followup message will be the based on that suggestion..Also if required ask user to lodge a complain about that in police station and if it is really faulty then assure him some good things.\n- Classify if the claim is fraud or not in the Fraud column.\n\nTry to incorporate above thing in your answer.\n\nOUTPUT FORMAT\nHTML Summary Table (No markdown, no file names)\n\nReturn the following table formatted in pure HTML (no triple quotes, no markdown):\n<table border=\"1\" cellpadding=\"6\" cellspacing=\"0\" style=\"border-collapse: collapse; font-family: Arial, sans-serif; font-size: 14px;\"> <thead style=\"background-color: #f2f2f2;\"> <tr> <th>Customer ID</th> <th>Transaction ID</th> <th>Transaction Date</th> <th>Analysis and Description</th> <th>Recommended Action</th> <th>Follow Up Message</th><th>Fraud</th></tr> </thead> <tbody> </tbody> </table>",
          "widget": "textareafield",
          "title": "Prompt",
          "description": "Custom prompt to override the default instructions.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "userQueryCol",
          "value": "",
          "widget": "variable",
          "title": "User Query Column",
          "description": "Column name for user query, (if the query is in a column)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "contentCol",
          "value": "All_Data",
          "widget": "variable",
          "title": "Content Column",
          "description": "Column name for the text content.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "llmConnection",
          "value": "azure-openai",
          "widget": "object_array",
          "title": "Select Connection",
          "description": "Select Connection",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "temperature",
          "value": "0",
          "widget": "textfield",
          "title": "Temperature",
          "description": "Temperature setting for the model (default: 0).",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "imageCol",
          "value": "",
          "widget": "variable",
          "title": "Image Column",
          "description": "Column name for the base 64 image.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputMode",
          "value": "text",
          "widget": "array",
          "title": "Mode Selection",
          "description": "Select the model to use (text, image, text+image).",
          "optionsArray": [
            "text",
            "image",
            "text+image"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateMode",
          "value": "NONE",
          "widget": "enum",
          "title": "Aggregate Response",
          "optionsMap": {
            "NONE": "Do not aggregate rows",
            "ALL": "Aggregate all rows",
            "PERFILE": "Aggregate per file"
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "numPartitions",
          "value": "3",
          "widget": "textfield",
          "title": "Number of Partitions",
          "description": "Number of Partitions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileNameCol",
          "value": "",
          "widget": "variable",
          "title": "File Name Column",
          "description": "Select File Name Column",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pageNumberCol",
          "value": "",
          "widget": "variable",
          "title": "Page Number Column",
          "description": " Select Page Number column.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "53",
      "name": "Drop Duplicate Rows",
      "iconImage": "fa fa-tumblr-square",
      "description": "Drops duplicate rows from the incoming DataFrame. Specific columns can be selected to be used when comparing two rows",
      "details": "This node drops duplicate rows from the incoming DataFrame. <br>\n<br>\nSpecific columns can be selected to be used when comparing two rows.<br>\n<br>\nOne of the matching rows is included in the outgoing Dataframe.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE05       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    JOHN        |    MARKETING  |    40<br>\nE04       |    JOHN        |    MARKETING  |    45<br>\n<br>\n<h2> If DropDuplicateRows node is configured to drop duplicate rows having duplicate values in [EMP_NAME] and [DEPT] then outgoing dataframe would be created as below:</h2>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE01       |    DAVID       |    HR         |    25<br>\nE03       |    JOHN        |    MARKETING  |    40<br>\n<br>\n<h2> If DropDuplicateRows node is configured to drop duplicate rows having duplicate values in [EMP_NAME], [DEPT] and [AGE] then outgoing dataframe would be created as below:</h2>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    JOHN        |    MARKETING  |    40<br>\nE04       |    JOHN        |    MARKETING  |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropDuplicateRows",
      "x": "1199px",
      "y": "140px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "colNames",
          "value": "[\"CustomeId\",\"TransactionId\",\"SummaryOfTheConversation\",\"TransactionLocation\",\"TransactionAmount\",\"Merchant\",\"PaymentMethod\",\"transactionDate\",\"CustomerActualLocation\",\"risk_score\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be used in determining if any two rows are duplication. No columns indicate to use all the available columns.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "54",
      "name": "Drop Duplicate Rows",
      "iconImage": "fa fa-tumblr-square",
      "description": "Drops duplicate rows from the incoming DataFrame. Specific columns can be selected to be used when comparing two rows",
      "details": "This node drops duplicate rows from the incoming DataFrame. <br>\n<br>\nSpecific columns can be selected to be used when comparing two rows.<br>\n<br>\nOne of the matching rows is included in the outgoing Dataframe.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE05       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    JOHN        |    MARKETING  |    40<br>\nE04       |    JOHN        |    MARKETING  |    45<br>\n<br>\n<h2> If DropDuplicateRows node is configured to drop duplicate rows having duplicate values in [EMP_NAME] and [DEPT] then outgoing dataframe would be created as below:</h2>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE01       |    DAVID       |    HR         |    25<br>\nE03       |    JOHN        |    MARKETING  |    40<br>\n<br>\n<h2> If DropDuplicateRows node is configured to drop duplicate rows having duplicate values in [EMP_NAME], [DEPT] and [AGE] then outgoing dataframe would be created as below:</h2>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    JOHN        |    MARKETING  |    40<br>\nE04       |    JOHN        |    MARKETING  |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropDuplicateRows",
      "x": "1081px",
      "y": "521px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "colNames",
          "value": "[\"transaction_id\",\"customer_id\",\"date\",\"amount\",\"currency\",\"type\",\"merchant_id_or_recipient_id\",\"location\",\"status\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be used in determining if any two rows are duplication. No columns indicate to use all the available columns.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "55",
      "name": "Concat Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "1519px",
      "y": "548px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"combined_CustomerAndDevice\",\"combined_TransactionHistory\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "All_Data",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "----------------------------- Historical Transaction ------------------------------------",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "56",
      "name": "Output Formatter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node formats output from Columns.",
      "type": "transform",
      "nodeClass": "fire.nodes.graph.NodeOutputFormatter",
      "x": "1627px",
      "y": "290px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "column",
          "value": "response",
          "widget": "variable",
          "title": " Select Column",
          "description": "Select Column to format",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "key",
          "value": "GenAiResponse",
          "widget": "textfield",
          "title": "Key",
          "description": "Specify a key Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    }
  ],
  "edges": [
    {
      "source": "32",
      "target": "33",
      "id": 1
    },
    {
      "source": "33",
      "target": "34",
      "id": 2
    },
    {
      "source": "34",
      "target": "35",
      "id": 3
    },
    {
      "source": "35",
      "target": "41",
      "id": 4
    },
    {
      "source": "37",
      "target": "41",
      "id": 5
    },
    {
      "source": "39",
      "target": "42",
      "id": 6
    },
    {
      "source": "41",
      "target": "42",
      "id": 7
    },
    {
      "source": "41",
      "target": "43",
      "id": 8
    },
    {
      "source": "40",
      "target": "43",
      "id": 9
    },
    {
      "source": "45",
      "target": "47",
      "id": 10
    },
    {
      "source": "46",
      "target": "48",
      "id": 11
    },
    {
      "source": "47",
      "target": "49",
      "id": 12
    },
    {
      "source": "48",
      "target": "49",
      "id": 13
    },
    {
      "source": "43",
      "target": "53",
      "id": 14
    },
    {
      "source": "53",
      "target": "45",
      "id": 15
    },
    {
      "source": "42",
      "target": "54",
      "id": 16
    },
    {
      "source": "54",
      "target": "46",
      "id": 17
    },
    {
      "source": "49",
      "target": "55",
      "id": 18
    },
    {
      "source": "55",
      "target": "51",
      "id": 19
    },
    {
      "source": "51",
      "target": "56",
      "id": 20
    }
  ],
  "dataSetDetails": [],
  "engine": "pyspark"
}