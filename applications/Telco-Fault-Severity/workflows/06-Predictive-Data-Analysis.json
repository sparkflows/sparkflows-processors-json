{
  "name": "06-Predictive-Data-Analysis",
  "uuid": "f9cfc226-c598-42ce-9b12-82e07ee63b4a",
  "category": "Predictive Analytics",
  "nodes": [
    {
      "id": "1",
      "name": "Read CSV",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>Refresh Schema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the refresh schema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "388.55px",
      "y": "41.55px",
      "hint": "Refresh the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/TELCO/Telco-Fault-Severity/Volume-Bucket/Volume_Bucket.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "true",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "enforceSchema",
          "value": "true",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"volume\",\"Volume_Bucket\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptions",
          "value": "",
          "widget": "tab",
          "title": "ExtraOptions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Extra Options Keys",
          "description": "Extra options available when reading CSV files. Examples :\n comment --> # (ignore comment lines in the file)\nignoreLeadingWhiteSpace --> false (Ignores leading white spaces in string columns)\nignoreTrailingWhiteSpace --> false (Ignores trailing white spaces in string columns).\nfilterPushdown --> true (Enables filter pushdown to optimize query performance.)\nsamplingRatio --> 1.0 (Specifies the ratio of rows to sample when inferring schema.)\nignoreCorruptFiles --> false (Skips files with corrupt data instead of failing.)\nignoreMissingFiles --> false (Skips missing files instead of failing.)\npathGlobFilter --> *.csv (Filters file paths based on a specified glob pattern.)\nrecursiveFileLookup --> false (Enables recursive file lookup in directories.)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "Extra Options",
          "size": "100%"
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Extra Options Values",
          "description": "Config Values for the Corresponding keys",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "2",
      "name": "Read CSV",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>Refresh Schema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the refresh schema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "522.533px",
      "y": "15.55px",
      "hint": "Refresh the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/TELCO/Telco-Fault-Severity/Predicted-data",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "true",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "enforceSchema",
          "value": "true",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"id\",\"location\",\"fault_severity\",\"severity_type\",\"resource_type\",\"log_feature\",\"volume\",\"event_type\",\"prediction\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"STRING\",\"DOUBLE\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"STRING\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptions",
          "value": "",
          "widget": "tab",
          "title": "ExtraOptions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Extra Options Keys",
          "description": "Extra options available when reading CSV files. Examples :\n comment --> # (ignore comment lines in the file)\nignoreLeadingWhiteSpace --> false (Ignores leading white spaces in string columns)\nignoreTrailingWhiteSpace --> false (Ignores trailing white spaces in string columns).\nfilterPushdown --> true (Enables filter pushdown to optimize query performance.)\nsamplingRatio --> 1.0 (Specifies the ratio of rows to sample when inferring schema.)\nignoreCorruptFiles --> false (Skips files with corrupt data instead of failing.)\nignoreMissingFiles --> false (Skips missing files instead of failing.)\npathGlobFilter --> *.csv (Filters file paths based on a specified glob pattern.)\nrecursiveFileLookup --> false (Enables recursive file lookup in directories.)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "Extra Options",
          "size": "100%"
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Extra Options Values",
          "description": "Config Values for the Corresponding keys",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "3",
      "name": "Join On Common Column",
      "description": "This node joins the incoming dataframes using one common column between them.",
      "details": "<h2>Join On Common Column Node Details</h2>\n<br>\nThis node joins the incoming dataframes using one common column between the two dataframes. <br>\n<br>\nSelect the Common Join Column to be used in the Join.<br>\n<br>\nJoining modes supported by this node is as follows:<br>\n<ul>\n<li> inner : The joined table will have records that have matching values in both tables.</li>\n<li> outer : The joined table contains either all the records from both the tables or fills in NULL values for missing matches on either side.</li>\n<li> left_outer  : Even if there are no matches in the right table it returns all the rows from the left table.</li>\n<li> right_outer : Even if there are no matches in the left table it returns all the rows from the right table.</li>\n<li> leftsemi : This gives only those rows in the left table that have a matching row in the right table.</li>\n<li> leftanti : This join returns rows in the left table that have no matching rows in the right table.</li>\n</ul>",
      "examples": "<h2>Join On Common Column Example</h2>\n<br>\n<h4> Incoming Datasets</h4>\n<br>\n1st Incoming Dataframe table1 has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO       <br>\n-------------------------------------------<br>\nE01       |    DAVID       |    10         <br>\nE02       |    JOHN        |    20      <br>\nE03       |    MARTIN      |    30  <br>\nE04       |    TONY        |    40  <br>\n<br>\n2nd Incoming Dataframe table2 has the following rows:<br>\n<br>\nDEPT_NO    |      DEPT_NAME   |    LOC       <br>\n-------------------------------------------<br>\n10         |      HR          |    IND  <br>\n20         |      SALES       |    AUS  <br>\n30         |      MARKETING   |    UK         <br>\n50         |      RESEARCH    |    NZ      <br>\n<br>\nThe common join column is DEPT_NO<br>\n<br>\n<h4> When the Joining condition is `inner` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\nE02       |    JOHN        |    20        |      SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |      MARKETING  |    UK<br>\n<br>\n<h4> When the Joining condition `outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |    <br>\n          |                |              |   RESEARCH   |    NZ<br>\n<br>\n<h4> When the Joining condition is `left_outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |    <br>\n<br>\n<h4> When the Joining condition `right_outer` we have</h4>\n<h4> Final Output</h4>\n          <br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\n          |                |    50        |   RESEARCH   |    NZ<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingColumn",
      "x": "530.783px",
      "y": "166.783px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinCol",
          "value": "volume",
          "widget": "variable_common",
          "title": "Common Join Column",
          "description": "column on which to join",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinType",
          "value": "inner",
          "widget": "array",
          "title": "JoinType",
          "description": "type of join",
          "optionsArray": [
            "inner",
            "outer",
            "leftouter",
            "rightouter",
            "leftsemi",
            "leftanti"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"volume\",\"id\",\"location\",\"fault_severity\",\"severity_type\",\"resource_type\",\"log_feature\",\"event_type\",\"severitytype_indexed\",\"resourcetype_indexed\",\"logfeature_indexed\",\"eventtype_indexed\",\"prediction\",\"Volume_Bucket\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"INTEGER\",\"STRING\",\"DOUBLE\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "4",
      "name": "Row Filter",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "630.667px",
      "y": "55.65px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditionExpr",
          "value": "prediction==1.0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "5",
      "name": "Group By",
      "description": "Group By Node",
      "details": "<h2>Group By Details</h2>\n<br>\n<h3>Aggregation Settings</h3>\nThis node groups row values based on categorical columns selected by the user and then calculates aggregate statistics of the grouped columns. <br>\nThe Grouping Columns allows the user to select which columns to group rows by, and the Variables List allows the user to select which aggregate statistics will be generated. <br>\n<br>\n<h3>Filter Settings</h3>\nThe Filter Settings allow the user to provide additional clauses before and after the data is aggregated.<br>\nThe Where Clause allows the user to filter the data before it is aggregated, and the Having Clause allows the user to filter the data after it has been aggregated. <br>\nBoth the Where and Having Clauses are similar in use to those that exist in many forms of SQL.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif GroupBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\nSALARY               |    SUM<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees and Summation of Salary all Employees is computed for each [DEPT]:<br>\n<br>\nDEPT           |    count_emp_cd    |    sum_salary<br>\n----------------------------------------------------------<br>\nFRONT DESK     |    2               |    21000<br>\nMARKETING      |    2               |    25000<br>\nHR             |    1               |    10000<br>\nSALES          |    1               |    11000<br>\nMAINTENANCE    |    2               |    25000<br>\n<br>\nif [WHERE CLAUSE] is entered as [DEPT = 'HR'] then outgoing Dataframe would consists of data only from HR department.<br>\n<br>\nif [HAVING CLAUSE] is entered as [COUNT(*) > 1] then outgoing Dataframe would consists of data for Department where count of Employees is more than 1.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "726.883px",
      "y": "55.8833px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "groupingCols",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateCols",
          "value": "[\"prediction\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateOperations",
          "value": "[\"count\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Predicted_Fault_Count\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "6",
      "name": "Group By",
      "description": "Group By Node",
      "details": "<h2>Group By Details</h2>\n<br>\n<h3>Aggregation Settings</h3>\nThis node groups row values based on categorical columns selected by the user and then calculates aggregate statistics of the grouped columns. <br>\nThe Grouping Columns allows the user to select which columns to group rows by, and the Variables List allows the user to select which aggregate statistics will be generated. <br>\n<br>\n<h3>Filter Settings</h3>\nThe Filter Settings allow the user to provide additional clauses before and after the data is aggregated.<br>\nThe Where Clause allows the user to filter the data before it is aggregated, and the Having Clause allows the user to filter the data after it has been aggregated. <br>\nBoth the Where and Having Clauses are similar in use to those that exist in many forms of SQL.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif GroupBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\nSALARY               |    SUM<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees and Summation of Salary all Employees is computed for each [DEPT]:<br>\n<br>\nDEPT           |    count_emp_cd    |    sum_salary<br>\n----------------------------------------------------------<br>\nFRONT DESK     |    2               |    21000<br>\nMARKETING      |    2               |    25000<br>\nHR             |    1               |    10000<br>\nSALES          |    1               |    11000<br>\nMAINTENANCE    |    2               |    25000<br>\n<br>\nif [WHERE CLAUSE] is entered as [DEPT = 'HR'] then outgoing Dataframe would consists of data only from HR department.<br>\n<br>\nif [HAVING CLAUSE] is entered as [COUNT(*) > 1] then outgoing Dataframe would consists of data for Department where count of Employees is more than 1.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "616.667px",
      "y": "149.667px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "groupingCols",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateCols",
          "value": "[\"volume\",\"volume\",\"volume\",\"id\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateOperations",
          "value": "[\"min\",\"max\",\"avg\",\"count\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Min_Volume\",\"Max_Volume\",\"Avg_Volume\",\"Total_Faults\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "7",
      "name": "Join On Common Columns",
      "description": "This node joins the incoming dataframes on 1 or more columns",
      "details": "<h2>Join On Common Columns Node Details</h2>\n<br>\nThis node joins the incoming dataframes using one or more than one common column between the two dataframes. <br>\n<br>\nJoin Types supported by this node are as follows<br>\n<ul>\n<li> inner : The joined table will have records that have matching values in both tables.</li>\n<li> outer : The joined table contains either all the records from both the tables or fills in NULL values for missing matches on either side.</li>\n<li> left_outer  : Even if there are no matches in the right table it returns all the rows from the left table.</li>\n<li> right_outer : Even if there are no matches in the left table it returns all the rows from the right table.</li>\n<li> leftsemi : This gives only those rows in the left table that have a matching row in the right table.</li>\n</ul>\nThe `WHERE CLAUSE` section is used to filter any records once the two or more tables have  been joined.<br>",
      "examples": "<h2>Join On Common Columns Node Example</h2>\n<br>\n<h4> Incoming Dataframe</h4>\n<br>\n1st Incoming dataframe table1 has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO    <br>\n-------------------------------------------<br>\nE01       |    DAVID       |    10         <br>\nE02       |    JOHN        |    20      <br>\nE03       |    MARTIN      |    30  <br>\nE04       |    TONY        |    40  <br>\n<br>\n2nd Incoming dataframe table2 has the following rows:<br>\n<br>\nDEPT_NO    |      DEPT_NAME   |    LOC     |   EMP_CD <br>\n----------------------------------------------------<br>\n10         |      HR          |    IND     |   E01<br>\n20         |      SALES       |    AUS     |   E02<br>\n40         |      RESEARCH    |    NZ      |   E04<br>\n50         |      ADMIN       |    UK      |   E05<br>\n<br>\nSelected common columns for both the dataframes are following <br>\n<ul>\n<li> From table1 is DEPT_NO and EMP_CD</li>\n<li> From table2 is DEPT_NO and EMP_CD</li>\n</ul>\n<h4> When the JOIN condition is `inner` with a WHERE clause of `DEPT_NO = 10` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\n<br>\n<h4> When the JOIN condition is `inner` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\nE02       |    JOHN        |    20        |      SALES      |    AUS<br>\nE04       |    TONY        |    40        |      RESEARCH   |    NZ<br>\n<br>\n<h4> When the Joining condition `outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |              |    <br>\nE04       |    TONY        |    40        |   RESEARCH   |    NZ<br>\nE05       |                |    50        |   ADMIN      |    UK<br>\n<br>\n<h4> When the Joining condition is `left_outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |    <br>\n<br>\n<h4> When the Joining condition `right_outer` we have</h4>\n<h4> Final Output</h4>\n          <br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE04       |    MARTIN      |    30        |   RESEARCH   |    UK<br>\nE05       |                |    50        |   ADMIN      |    NZ<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingColumns",
      "x": "732.883px",
      "y": "163.883px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinCols",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables_common",
          "title": "Common Join Columns",
          "description": "Space separated list of columns on which to join",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinType",
          "value": "inner",
          "widget": "array",
          "title": "Join Type",
          "description": "Type of Join",
          "optionsArray": [
            "inner",
            "outer",
            "left_outer",
            "right_outer",
            "leftsemi"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition after join function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Volume_Bucket\",\"Min_Volume\",\"Max_Volume\",\"Avg_Volume\",\"Total_Faults\",\"Predicted_Fault_1_Count\",\"Actual_Fault_1_Count\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"LONG\",\"LONG\",\"LONG\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "8",
      "name": "Row Filter",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "551.667px",
      "y": "287.667px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditionExpr",
          "value": "fault_severity==1.0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "9",
      "name": "Group By",
      "description": "Group By Node",
      "details": "<h2>Group By Details</h2>\n<br>\n<h3>Aggregation Settings</h3>\nThis node groups row values based on categorical columns selected by the user and then calculates aggregate statistics of the grouped columns. <br>\nThe Grouping Columns allows the user to select which columns to group rows by, and the Variables List allows the user to select which aggregate statistics will be generated. <br>\n<br>\n<h3>Filter Settings</h3>\nThe Filter Settings allow the user to provide additional clauses before and after the data is aggregated.<br>\nThe Where Clause allows the user to filter the data before it is aggregated, and the Having Clause allows the user to filter the data after it has been aggregated. <br>\nBoth the Where and Having Clauses are similar in use to those that exist in many forms of SQL.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif GroupBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\nSALARY               |    SUM<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees and Summation of Salary all Employees is computed for each [DEPT]:<br>\n<br>\nDEPT           |    count_emp_cd    |    sum_salary<br>\n----------------------------------------------------------<br>\nFRONT DESK     |    2               |    21000<br>\nMARKETING      |    2               |    25000<br>\nHR             |    1               |    10000<br>\nSALES          |    1               |    11000<br>\nMAINTENANCE    |    2               |    25000<br>\n<br>\nif [WHERE CLAUSE] is entered as [DEPT = 'HR'] then outgoing Dataframe would consists of data only from HR department.<br>\n<br>\nif [HAVING CLAUSE] is entered as [COUNT(*) > 1] then outgoing Dataframe would consists of data for Department where count of Employees is more than 1.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "661.767px",
      "y": "275.783px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "groupingCols",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateCols",
          "value": "[\"fault_severity\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateOperations",
          "value": "[\"count\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Actual_Fault_Count\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "10",
      "name": "Row Filter",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "387.433px",
      "y": "147.417px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditionExpr",
          "value": "fault_severity==0.0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "11",
      "name": "Row Filter",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "163.433px",
      "y": "139.433px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditionExpr",
          "value": "prediction==1.0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "12",
      "name": "Row Filter",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "249.2px",
      "y": "198.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditionExpr",
          "value": "prediction==0.0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "13",
      "name": "Group By",
      "description": "Group By Node",
      "details": "<h2>Group By Details</h2>\n<br>\n<h3>Aggregation Settings</h3>\nThis node groups row values based on categorical columns selected by the user and then calculates aggregate statistics of the grouped columns. <br>\nThe Grouping Columns allows the user to select which columns to group rows by, and the Variables List allows the user to select which aggregate statistics will be generated. <br>\n<br>\n<h3>Filter Settings</h3>\nThe Filter Settings allow the user to provide additional clauses before and after the data is aggregated.<br>\nThe Where Clause allows the user to filter the data before it is aggregated, and the Having Clause allows the user to filter the data after it has been aggregated. <br>\nBoth the Where and Having Clauses are similar in use to those that exist in many forms of SQL.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif GroupBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\nSALARY               |    SUM<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees and Summation of Salary all Employees is computed for each [DEPT]:<br>\n<br>\nDEPT           |    count_emp_cd    |    sum_salary<br>\n----------------------------------------------------------<br>\nFRONT DESK     |    2               |    21000<br>\nMARKETING      |    2               |    25000<br>\nHR             |    1               |    10000<br>\nSALES          |    1               |    11000<br>\nMAINTENANCE    |    2               |    25000<br>\n<br>\nif [WHERE CLAUSE] is entered as [DEPT = 'HR'] then outgoing Dataframe would consists of data only from HR department.<br>\n<br>\nif [HAVING CLAUSE] is entered as [COUNT(*) > 1] then outgoing Dataframe would consists of data for Department where count of Employees is more than 1.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "168.95px",
      "y": "300.983px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "groupingCols",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateCols",
          "value": "[\"prediction\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateOperations",
          "value": "[\"count\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"TN\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "14",
      "name": "Group By",
      "description": "Group By Node",
      "details": "<h2>Group By Details</h2>\n<br>\n<h3>Aggregation Settings</h3>\nThis node groups row values based on categorical columns selected by the user and then calculates aggregate statistics of the grouped columns. <br>\nThe Grouping Columns allows the user to select which columns to group rows by, and the Variables List allows the user to select which aggregate statistics will be generated. <br>\n<br>\n<h3>Filter Settings</h3>\nThe Filter Settings allow the user to provide additional clauses before and after the data is aggregated.<br>\nThe Where Clause allows the user to filter the data before it is aggregated, and the Having Clause allows the user to filter the data after it has been aggregated. <br>\nBoth the Where and Having Clauses are similar in use to those that exist in many forms of SQL.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif GroupBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\nSALARY               |    SUM<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees and Summation of Salary all Employees is computed for each [DEPT]:<br>\n<br>\nDEPT           |    count_emp_cd    |    sum_salary<br>\n----------------------------------------------------------<br>\nFRONT DESK     |    2               |    21000<br>\nMARKETING      |    2               |    25000<br>\nHR             |    1               |    10000<br>\nSALES          |    1               |    11000<br>\nMAINTENANCE    |    2               |    25000<br>\n<br>\nif [WHERE CLAUSE] is entered as [DEPT = 'HR'] then outgoing Dataframe would consists of data only from HR department.<br>\n<br>\nif [HAVING CLAUSE] is entered as [COUNT(*) > 1] then outgoing Dataframe would consists of data for Department where count of Employees is more than 1.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "81.05px",
      "y": "298.05px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "groupingCols",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateCols",
          "value": "[\"prediction\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateOperations",
          "value": "[\"count\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"FP\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "15",
      "name": "Row Filter",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "396.433px",
      "y": "233.45px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditionExpr",
          "value": "prediction==0.0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "16",
      "name": "Row Filter",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "423.433px",
      "y": "310.45px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditionExpr",
          "value": "prediction==1.0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "17",
      "name": "Group By",
      "description": "Group By Node",
      "details": "<h2>Group By Details</h2>\n<br>\n<h3>Aggregation Settings</h3>\nThis node groups row values based on categorical columns selected by the user and then calculates aggregate statistics of the grouped columns. <br>\nThe Grouping Columns allows the user to select which columns to group rows by, and the Variables List allows the user to select which aggregate statistics will be generated. <br>\n<br>\n<h3>Filter Settings</h3>\nThe Filter Settings allow the user to provide additional clauses before and after the data is aggregated.<br>\nThe Where Clause allows the user to filter the data before it is aggregated, and the Having Clause allows the user to filter the data after it has been aggregated. <br>\nBoth the Where and Having Clauses are similar in use to those that exist in many forms of SQL.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif GroupBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\nSALARY               |    SUM<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees and Summation of Salary all Employees is computed for each [DEPT]:<br>\n<br>\nDEPT           |    count_emp_cd    |    sum_salary<br>\n----------------------------------------------------------<br>\nFRONT DESK     |    2               |    21000<br>\nMARKETING      |    2               |    25000<br>\nHR             |    1               |    10000<br>\nSALES          |    1               |    11000<br>\nMAINTENANCE    |    2               |    25000<br>\n<br>\nif [WHERE CLAUSE] is entered as [DEPT = 'HR'] then outgoing Dataframe would consists of data only from HR department.<br>\n<br>\nif [HAVING CLAUSE] is entered as [COUNT(*) > 1] then outgoing Dataframe would consists of data for Department where count of Employees is more than 1.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "333.55px",
      "y": "365.55px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "groupingCols",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateCols",
          "value": "[\"prediction\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateOperations",
          "value": "[\"count\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"TP\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "18",
      "name": "Group By",
      "description": "Group By Node",
      "details": "<h2>Group By Details</h2>\n<br>\n<h3>Aggregation Settings</h3>\nThis node groups row values based on categorical columns selected by the user and then calculates aggregate statistics of the grouped columns. <br>\nThe Grouping Columns allows the user to select which columns to group rows by, and the Variables List allows the user to select which aggregate statistics will be generated. <br>\n<br>\n<h3>Filter Settings</h3>\nThe Filter Settings allow the user to provide additional clauses before and after the data is aggregated.<br>\nThe Where Clause allows the user to filter the data before it is aggregated, and the Having Clause allows the user to filter the data after it has been aggregated. <br>\nBoth the Where and Having Clauses are similar in use to those that exist in many forms of SQL.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif GroupBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\nSALARY               |    SUM<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees and Summation of Salary all Employees is computed for each [DEPT]:<br>\n<br>\nDEPT           |    count_emp_cd    |    sum_salary<br>\n----------------------------------------------------------<br>\nFRONT DESK     |    2               |    21000<br>\nMARKETING      |    2               |    25000<br>\nHR             |    1               |    10000<br>\nSALES          |    1               |    11000<br>\nMAINTENANCE    |    2               |    25000<br>\n<br>\nif [WHERE CLAUSE] is entered as [DEPT = 'HR'] then outgoing Dataframe would consists of data only from HR department.<br>\n<br>\nif [HAVING CLAUSE] is entered as [COUNT(*) > 1] then outgoing Dataframe would consists of data for Department where count of Employees is more than 1.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "268.55px",
      "y": "291.55px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "groupingCols",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateCols",
          "value": "[\"prediction\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateOperations",
          "value": "[\"count\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"FN\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "19",
      "name": "Join On Common Columns",
      "description": "This node joins the incoming dataframes on 1 or more columns",
      "details": "<h2>Join On Common Columns Node Details</h2>\n<br>\nThis node joins the incoming dataframes using one or more than one common column between the two dataframes. <br>\n<br>\nJoin Types supported by this node are as follows<br>\n<ul>\n<li> inner : The joined table will have records that have matching values in both tables.</li>\n<li> outer : The joined table contains either all the records from both the tables or fills in NULL values for missing matches on either side.</li>\n<li> left_outer  : Even if there are no matches in the right table it returns all the rows from the left table.</li>\n<li> right_outer : Even if there are no matches in the left table it returns all the rows from the right table.</li>\n<li> leftsemi : This gives only those rows in the left table that have a matching row in the right table.</li>\n</ul>\nThe `WHERE CLAUSE` section is used to filter any records once the two or more tables have  been joined.<br>",
      "examples": "<h2>Join On Common Columns Node Example</h2>\n<br>\n<h4> Incoming Dataframe</h4>\n<br>\n1st Incoming dataframe table1 has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO    <br>\n-------------------------------------------<br>\nE01       |    DAVID       |    10         <br>\nE02       |    JOHN        |    20      <br>\nE03       |    MARTIN      |    30  <br>\nE04       |    TONY        |    40  <br>\n<br>\n2nd Incoming dataframe table2 has the following rows:<br>\n<br>\nDEPT_NO    |      DEPT_NAME   |    LOC     |   EMP_CD <br>\n----------------------------------------------------<br>\n10         |      HR          |    IND     |   E01<br>\n20         |      SALES       |    AUS     |   E02<br>\n40         |      RESEARCH    |    NZ      |   E04<br>\n50         |      ADMIN       |    UK      |   E05<br>\n<br>\nSelected common columns for both the dataframes are following <br>\n<ul>\n<li> From table1 is DEPT_NO and EMP_CD</li>\n<li> From table2 is DEPT_NO and EMP_CD</li>\n</ul>\n<h4> When the JOIN condition is `inner` with a WHERE clause of `DEPT_NO = 10` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\n<br>\n<h4> When the JOIN condition is `inner` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\nE02       |    JOHN        |    20        |      SALES      |    AUS<br>\nE04       |    TONY        |    40        |      RESEARCH   |    NZ<br>\n<br>\n<h4> When the Joining condition `outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |              |    <br>\nE04       |    TONY        |    40        |   RESEARCH   |    NZ<br>\nE05       |                |    50        |   ADMIN      |    UK<br>\n<br>\n<h4> When the Joining condition is `left_outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |    <br>\n<br>\n<h4> When the Joining condition `right_outer` we have</h4>\n<h4> Final Output</h4>\n          <br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE04       |    MARTIN      |    30        |   RESEARCH   |    UK<br>\nE05       |                |    50        |   ADMIN      |    NZ<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingColumns",
      "x": "165.783px",
      "y": "459.783px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinCols",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables_common",
          "title": "Common Join Columns",
          "description": "Space separated list of columns on which to join",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinType",
          "value": "outer",
          "widget": "array",
          "title": "Join Type",
          "description": "Type of Join",
          "optionsArray": [
            "inner",
            "outer",
            "left_outer",
            "right_outer",
            "leftsemi"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition after join function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Volume_Bucket\",\"FP\",\"TN\",\"FN\",\"TP\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"LONG\",\"LONG\",\"LONG\",\"LONG\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "22",
      "name": "Imputing With Constant",
      "description": "It imputes missing value with constant value. It fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.",
      "details": "This node imputes the missing value with constant value.<br>\n<br>\nIt fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.<br>",
      "examples": "Incoming Dataframe has following rows and [AGE] column has missing values / [NULL] for some rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |\t\t\t<br>\nCD04       |    MATT         |\t\t\t<br>\n<br>\nIf imputingwithconstatnt node is configured to Impute [AGE] with 45 then missing values in [AGE] column would be replaced with 45.<br>\nOutgoing Dataframe would result as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |    45\t\t\t<br>\nCD04       |    MATT         |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeReplaceMissingValueWithConstant",
      "x": "280.783px",
      "y": "447.783px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "colNames",
          "value": "[\"FN\",\"FP\",\"TN\",\"TP\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns to be processed for missing values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constants",
          "value": "[\"0\",\"0\",\"0\",\"0\"]",
          "widget": "variables_list_textfield",
          "title": "Constants",
          "description": "Missing value will be replaced with constant",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "23",
      "name": "Math Expression",
      "description": "Creates new columns using the specified expressions",
      "details": "<h2> Math Expression Details </h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the specified expression.<br>\n<br>\nNew columns can be computed using existing columns in the Dataframe.<br>\n<br>\nFollowing functions can be used in Expressions:<br>\n<br>\n<h4> Computations</h4>\n<ul>\n<li>\tComputation expression -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n</ul>\n<h4>Math Functions</h4>\n<ul>\n<li>\t abs :  Get the absolute value of an expression. Ex: abs(LIST_PRICE)</li>\n<li>\t pow :  Raises expr1 to the power of expr2. Ex: pow(LIST_PRICE, 2)</li>\n<li>\t cos :  Get the trigonometric cosine of an expression. Ex: cos(LIST_PRICE)</li>\n</ul>\nValid examples of Math functions - abs, acros, asin, atan, atan2, bin, cbrt, ceil, conv, cos, sosh, exp, expm1, factorial, floor, hex, hypot, log, log10, log1p, log2, pmod, pow, rint, round, shiftLeft, shiftRight, shiftRightUnsigned, signum, sin, sinh, sqrt, tan, tanh, toDegrees, toRadians, unhex (single choice)<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\nIf MathExpression node is configured to compute a new column [NET_AMT] based on expression [LIST_PRICE + TAX_AMT - DISCOUNT]<br>\nthen outgoing Dataframe would be created as below with new column added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    <br>\n------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeMathExpression",
      "x": "471.783px",
      "y": "409.783px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"Accuracy\",\"Precision\",\"Recall\"]",
          "widget": "key_array",
          "title": "Output Column",
          "description": "Output Column Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "expressions",
          "value": "[\"((TP+TN)/(TP+TN+FN+FP))*100\",\"((TP)/(TP+FP))*100\",\"((TP)/(TP+FN))*100\"]",
          "widget": "value_array",
          "title": "Math Expression",
          "description": "Define math expression.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "24",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "592.667px",
      "y": "382.667px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"Volume_Bucket\",\"Accuracy\",\"Precision\",\"Recall\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "25",
      "name": "Join On Common Columns",
      "description": "This node joins the incoming dataframes on 1 or more columns",
      "details": "<h2>Join On Common Columns Node Details</h2>\n<br>\nThis node joins the incoming dataframes using one or more than one common column between the two dataframes. <br>\n<br>\nJoin Types supported by this node are as follows<br>\n<ul>\n<li> inner : The joined table will have records that have matching values in both tables.</li>\n<li> outer : The joined table contains either all the records from both the tables or fills in NULL values for missing matches on either side.</li>\n<li> left_outer  : Even if there are no matches in the right table it returns all the rows from the left table.</li>\n<li> right_outer : Even if there are no matches in the left table it returns all the rows from the right table.</li>\n<li> leftsemi : This gives only those rows in the left table that have a matching row in the right table.</li>\n</ul>\nThe `WHERE CLAUSE` section is used to filter any records once the two or more tables have  been joined.<br>",
      "examples": "<h2>Join On Common Columns Node Example</h2>\n<br>\n<h4> Incoming Dataframe</h4>\n<br>\n1st Incoming dataframe table1 has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO    <br>\n-------------------------------------------<br>\nE01       |    DAVID       |    10         <br>\nE02       |    JOHN        |    20      <br>\nE03       |    MARTIN      |    30  <br>\nE04       |    TONY        |    40  <br>\n<br>\n2nd Incoming dataframe table2 has the following rows:<br>\n<br>\nDEPT_NO    |      DEPT_NAME   |    LOC     |   EMP_CD <br>\n----------------------------------------------------<br>\n10         |      HR          |    IND     |   E01<br>\n20         |      SALES       |    AUS     |   E02<br>\n40         |      RESEARCH    |    NZ      |   E04<br>\n50         |      ADMIN       |    UK      |   E05<br>\n<br>\nSelected common columns for both the dataframes are following <br>\n<ul>\n<li> From table1 is DEPT_NO and EMP_CD</li>\n<li> From table2 is DEPT_NO and EMP_CD</li>\n</ul>\n<h4> When the JOIN condition is `inner` with a WHERE clause of `DEPT_NO = 10` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\n<br>\n<h4> When the JOIN condition is `inner` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\nE02       |    JOHN        |    20        |      SALES      |    AUS<br>\nE04       |    TONY        |    40        |      RESEARCH   |    NZ<br>\n<br>\n<h4> When the Joining condition `outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |              |    <br>\nE04       |    TONY        |    40        |   RESEARCH   |    NZ<br>\nE05       |                |    50        |   ADMIN      |    UK<br>\n<br>\n<h4> When the Joining condition is `left_outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |    <br>\n<br>\n<h4> When the Joining condition `right_outer` we have</h4>\n<h4> Final Output</h4>\n          <br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE04       |    MARTIN      |    30        |   RESEARCH   |    UK<br>\nE05       |                |    50        |   ADMIN      |    NZ<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingColumns",
      "x": "706.783px",
      "y": "403.783px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinCols",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables_common",
          "title": "Common Join Columns",
          "description": "Space separated list of columns on which to join",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinType",
          "value": "inner",
          "widget": "array",
          "title": "Join Type",
          "description": "Type of Join",
          "optionsArray": [
            "inner",
            "outer",
            "left_outer",
            "right_outer",
            "leftsemi"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition after join function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Volume_Bucket\",\"Accuracy\",\"Precision\",\"Recall\",\"Min_Volume\",\"Max_Volume\",\"Avg_Volume\",\"Total_Faults\",\"Predicted_Fault_1_Count\",\"Actual_Fault_1_Count\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"LONG\",\"LONG\",\"LONG\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "26",
      "name": "Print N Rows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "829.883px",
      "y": "398.883px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Classification Matrix Based On Each Decile",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "27",
      "name": "Sort By",
      "description": "It sorts the incoming DataFrame on the fields specified.",
      "details": "This node sorts the incoming DataFrame based on the values present in columns specified.<br>\n<br>\nMultiple columns can be selected for sorting data. Data can be sorted in Ascending or Descending order.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\nIf SortBy node is configured to sort data in descending order of values present in [CUST_NAME] column then outgoing Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSortBy",
      "x": "810.883px",
      "y": "291.883px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textfield",
          "title": "Description",
          "description": "Description",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "sortByColNames",
          "value": "[\"Volume_Bucket\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns on which to Sort By",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "ascDesc",
          "value": "[\"ASC\"]",
          "widget": "variables_list_array",
          "title": "Sorting Order",
          "description": "Whether to sort in ascending or descending order",
          "optionsArray": [
            "DESC",
            "ASC"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "28",
      "name": "Print Rich Text",
      "description": "Displaying rich text",
      "details": "<h2>Print Rich Text Node Details</h2>\n<br>\nThis node offers a wide variety of common formatting options, such as bold, color and italics.<br>\n<br>\nThe output format also supports options to change font size, font background, text color, text highlight, create Hyperlinks and attach Images as well as create numbered or bulleted lists.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TEXT: Select the text you want to format using the format toolbar.</li>\n</ul>\n<h4> This node can be used in various ways to:</h4>\n- Add enriched comments or notes.<br>\n- Add a reference or hyperlink.<br>\n- Add images and videos.<br>",
      "examples": "<h2> Print Rich Text Node Example</h2>\n<br>\nScenario:<br>\n<br>\nLet's say you want to generate a formatted report with a mix of text, numbers, and images. You can use the Print Rich Text node to create a visually appealing and informative report.<br>\n<br>\nConfiguration:<br>\n<br>\n1. Text: Enter the text you want to print.<br>\n2. Formatting: Use the formatting options (bold, italic, underline, font size, color) to style the text.It also supports variables and parameters<br>\n<br>\nOutput:<br>\n<br>\nThe node will print the formatted text to the console or a specified output file. You can customize the formatting and content of the text to create a variety of reports.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.graph.NodePrintRichText",
      "x": "946.883px",
      "y": "386.883px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "text",
          "value": "<p><strong>Decile Based Table Analysis</strong></p><p><br></p><p>Decile Wise Actual Vs Predicted with Different Volume Range Such as Average, Minimum, Maximum Volume</p><p><br></p><ul><li>Example: - For Eighth Decile Avg Volume is 142, Minimum Volume is 128 and Maximum Volume is 154</li><li>Total Customer is 34</li><li>Actual Fault is 12, Predicted Fault is 13</li><li>Accuracy = 85%</li><li>Precision = 76%</li><li>Recall = 83%</li></ul>",
          "widget": "textarea_rich",
          "title": "Text",
          "description": "Displaying rich text",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "column",
          "value": "column",
          "widget": "variable",
          "title": "Column to pick data",
          "description": "First row from the column will be picked and displayed.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "30",
      "name": "Group By",
      "description": "Group By Node",
      "details": "<h2>Group By Details</h2>\n<br>\n<h3>Aggregation Settings</h3>\nThis node groups row values based on categorical columns selected by the user and then calculates aggregate statistics of the grouped columns. <br>\nThe Grouping Columns allows the user to select which columns to group rows by, and the Variables List allows the user to select which aggregate statistics will be generated. <br>\n<br>\n<h3>Filter Settings</h3>\nThe Filter Settings allow the user to provide additional clauses before and after the data is aggregated.<br>\nThe Where Clause allows the user to filter the data before it is aggregated, and the Having Clause allows the user to filter the data after it has been aggregated. <br>\nBoth the Where and Having Clauses are similar in use to those that exist in many forms of SQL.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif GroupBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\nSALARY               |    SUM<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees and Summation of Salary all Employees is computed for each [DEPT]:<br>\n<br>\nDEPT           |    count_emp_cd    |    sum_salary<br>\n----------------------------------------------------------<br>\nFRONT DESK     |    2               |    21000<br>\nMARKETING      |    2               |    25000<br>\nHR             |    1               |    10000<br>\nSALES          |    1               |    11000<br>\nMAINTENANCE    |    2               |    25000<br>\n<br>\nif [WHERE CLAUSE] is entered as [DEPT = 'HR'] then outgoing Dataframe would consists of data only from HR department.<br>\n<br>\nif [HAVING CLAUSE] is entered as [COUNT(*) > 1] then outgoing Dataframe would consists of data for Department where count of Employees is more than 1.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "949.1px",
      "y": "112.417px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "groupingCols",
          "value": "[\"resource_type\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateCols",
          "value": "[\"resource_type\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateOperations",
          "value": "[\"count\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Resource_Type_Count\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "31",
      "name": "Print N Rows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "828.783px",
      "y": "17.7833px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Row Values",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "32",
      "name": "Row Filter",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "831.45px",
      "y": "113.433px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditionExpr",
          "value": "prediction==1.0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "33",
      "name": "Row Filter",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "details": "<h2>Details</h2>\n<br>\nRow filter allows the user to filter out rows that do not meet a set condition. Rows that meet the condition are passed on to the next node in a new dataframe.<br>",
      "examples": "<h2>Examples of Conditional Expression</h2>\n<br>\nBelow are some examples of the Conditions Expression which can be used.<br>\n<br>\n<ul>\n<li> col1 > 5 AND col2 > 3</li>\n</ul>\n<ul>\n<li> name is not NULL</li>\n</ul>\n<ul>\n<li> name is NULL</li>\n</ul>\n<ul>\n<li> usd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100</li>\n</ul>\n<ul>\n<li> dt > '2021-09-03'  (dt column is of type date)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)</li>\n</ul>\n<ul>\n<li> datetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "946.45px",
      "y": "15.8833px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditionExpr",
          "value": "prediction==0.0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "34",
      "name": "Group By",
      "description": "Group By Node",
      "details": "<h2>Group By Details</h2>\n<br>\n<h3>Aggregation Settings</h3>\nThis node groups row values based on categorical columns selected by the user and then calculates aggregate statistics of the grouped columns. <br>\nThe Grouping Columns allows the user to select which columns to group rows by, and the Variables List allows the user to select which aggregate statistics will be generated. <br>\n<br>\n<h3>Filter Settings</h3>\nThe Filter Settings allow the user to provide additional clauses before and after the data is aggregated.<br>\nThe Where Clause allows the user to filter the data before it is aggregated, and the Having Clause allows the user to filter the data after it has been aggregated. <br>\nBoth the Where and Having Clauses are similar in use to those that exist in many forms of SQL.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif GroupBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\nSALARY               |    SUM<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees and Summation of Salary all Employees is computed for each [DEPT]:<br>\n<br>\nDEPT           |    count_emp_cd    |    sum_salary<br>\n----------------------------------------------------------<br>\nFRONT DESK     |    2               |    21000<br>\nMARKETING      |    2               |    25000<br>\nHR             |    1               |    10000<br>\nSALES          |    1               |    11000<br>\nMAINTENANCE    |    2               |    25000<br>\n<br>\nif [WHERE CLAUSE] is entered as [DEPT = 'HR'] then outgoing Dataframe would consists of data only from HR department.<br>\n<br>\nif [HAVING CLAUSE] is entered as [COUNT(*) > 1] then outgoing Dataframe would consists of data for Department where count of Employees is more than 1.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "1049.78px",
      "y": "15.7833px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "groupingCols",
          "value": "[\"resource_type\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateCols",
          "value": "[\"resource_type\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "aggregateOperations",
          "value": "[\"count\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Resource_Type_Count\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "35",
      "name": "Graph Values",
      "details": "<h2>Graph Values Details</h2>\n<br>\nThis node represents variation between data of various data series in Graphical format.<br>\n<br>\nMultiple numeric columns can be plotted along Y-Coordinate. Only one can be selected along X-Coordinate.<br>\n<br>\nVariation between dataseries is plotted as graph of the selected type such as Line-Chart, Bar-Chart or so on.<br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   TITLE :- The title of a graph can be set here.</li>\n<li>   X LABEL :- X-axis label can be set here.</li>\n<li>   Y LABEL :- Y-axis label can be set here.</li>\n<li>   MAX VALUES TO DISPLAY :- The total number of the data points can be selected here.</li>\n<li>   CHART TYPE :- The desired chart can be selected from the drop-down list(Line Chart,Side By Side Bar Chart,Pie Chart,Scatter Chart)                                                 </li>\n<li>   CHART COLORS :- The different types of color can be selected for better visualization.</li>\n<li>   IS STREAMING? :- If the graph is stream graph set the option as true else false(by default it is false). </li>\n<li>   X COLUMN :- Select the column for X-axis.</li>\n<li>   Y COLUMNS :- Select the colum for Y-axis.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li>   It will plot a graph and will represent the trends between mentioned columns.</li>\n<li>   The different types of a graph can be plotted between specified columns to check the trends.</li>\n</ul>\n<h4>Types Of Chart</h4>\n<ul>\n<li>   Line Chart</li>\n<li>   Side By Side Bar Chart</li>\n<li>   Stack Bar Chart</li>\n<li>   Pie Chart</li>\n<li>   Scatter Chart</li>\n<li>   Dual Line Chart</li>\n<li>   Area Chart</li>\n</ul>\n<h4>Example</h4>\n<ul>\n<li>   A line chart allows us to track the development of several variables at the same time.</li>\n<li>   Scatter plots are used to determine whether or not two variables have a relationship or correlation.</li>\n<li>   The main motive of a stacked bar chart is to compare numeric values between levels of a categorical variable.</li>\n</ul>",
      "examples": "Example:<br>\n<br>\nLet's say you have a dataset with sales figures for different products over time. You can configure the Graph Values node as follows:<br>\n<br>\nX Column: Date<br>\nY Columns: Sales_ProductA, Sales_ProductB<br>\nChart Type: Line Chart<br>\nThe node will generate a line chart showing the sales trends for both products over time.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.graph.NodeGraphValues",
      "x": "1043.67px",
      "y": "115.667px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Count of Predicted Severe Fault By Resource Type",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "titleColor",
          "value": "#77C27F",
          "widget": "textcolors",
          "title": "Title Color",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textareafield",
          "title": "Description",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "descriptionColor",
          "value": "#808080",
          "widget": "textcolors",
          "title": "Description Color",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "xlabel",
          "value": "X axis",
          "widget": "textfield",
          "title": "X Label",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "ylabel",
          "value": "",
          "widget": "textfield",
          "title": "Y Label",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "maxValuesToDisplay",
          "value": "20",
          "widget": "textfield",
          "title": "Max Values To Display",
          "description": "Maximum number of values to display in result.",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "graphType",
          "value": "PIE",
          "widget": "enum",
          "title": "Chart Type",
          "optionsMap": {
            "LINECHART": "Line Chart",
            "COLUMNCHART": "Side by Side Bar Chart",
            "BARCHART": "Stacked Bar Chart",
            "PIE": "Pie Chart",
            "SCATTERCHART": "Scatter Chart",
            "DUALLINECHART": "Dual Line Chart",
            "AREACHART": "Area Chart"
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "chartColors",
          "value": "#F2A993,#76D0D7,#B9ABE5,#EEC896,#DE95B0,#009cef,#86ABA1,#00AF91,#C2B8A3,#BFA2DB",
          "widget": "colors",
          "title": "Chart Colors",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "isStreaming",
          "value": "false",
          "widget": "array",
          "title": "Is Streaming?",
          "description": "Whether the Graph is a Streaming Graph or not",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "markerSize",
          "value": "12",
          "widget": "textfield",
          "title": "Marker size",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "xCol",
          "value": "resource_type",
          "widget": "variable",
          "title": "X Column",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "xSortCol",
          "value": "true",
          "widget": "array",
          "title": "Sort on X Column?",
          "description": "Whether to Sort on X column or not",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "yCols",
          "value": "[\"Resource_Type_Count\"]",
          "widget": "variables",
          "title": "Y Columns",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "ySortCol",
          "value": "",
          "widget": "variable",
          "title": "Y Sort Column",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "reNameYColumns",
          "value": "[]",
          "widget": "variables_selected",
          "title": "Rename Y Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "36",
      "name": "Graph Values",
      "details": "<h2>Graph Values Details</h2>\n<br>\nThis node represents variation between data of various data series in Graphical format.<br>\n<br>\nMultiple numeric columns can be plotted along Y-Coordinate. Only one can be selected along X-Coordinate.<br>\n<br>\nVariation between dataseries is plotted as graph of the selected type such as Line-Chart, Bar-Chart or so on.<br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   TITLE :- The title of a graph can be set here.</li>\n<li>   X LABEL :- X-axis label can be set here.</li>\n<li>   Y LABEL :- Y-axis label can be set here.</li>\n<li>   MAX VALUES TO DISPLAY :- The total number of the data points can be selected here.</li>\n<li>   CHART TYPE :- The desired chart can be selected from the drop-down list(Line Chart,Side By Side Bar Chart,Pie Chart,Scatter Chart)                                                 </li>\n<li>   CHART COLORS :- The different types of color can be selected for better visualization.</li>\n<li>   IS STREAMING? :- If the graph is stream graph set the option as true else false(by default it is false). </li>\n<li>   X COLUMN :- Select the column for X-axis.</li>\n<li>   Y COLUMNS :- Select the colum for Y-axis.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li>   It will plot a graph and will represent the trends between mentioned columns.</li>\n<li>   The different types of a graph can be plotted between specified columns to check the trends.</li>\n</ul>\n<h4>Types Of Chart</h4>\n<ul>\n<li>   Line Chart</li>\n<li>   Side By Side Bar Chart</li>\n<li>   Stack Bar Chart</li>\n<li>   Pie Chart</li>\n<li>   Scatter Chart</li>\n<li>   Dual Line Chart</li>\n<li>   Area Chart</li>\n</ul>\n<h4>Example</h4>\n<ul>\n<li>   A line chart allows us to track the development of several variables at the same time.</li>\n<li>   Scatter plots are used to determine whether or not two variables have a relationship or correlation.</li>\n<li>   The main motive of a stacked bar chart is to compare numeric values between levels of a categorical variable.</li>\n</ul>",
      "examples": "Example:<br>\n<br>\nLet's say you have a dataset with sales figures for different products over time. You can configure the Graph Values node as follows:<br>\n<br>\nX Column: Date<br>\nY Columns: Sales_ProductA, Sales_ProductB<br>\nChart Type: Line Chart<br>\nThe node will generate a line chart showing the sales trends for both products over time.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.graph.NodeGraphValues",
      "x": "1117.78px",
      "y": "93.7833px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Count of Predicted Non Severe Fault By Resource Type",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "titleColor",
          "value": "#77C27F",
          "widget": "textcolors",
          "title": "Title Color",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textareafield",
          "title": "Description",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "descriptionColor",
          "value": "#808080",
          "widget": "textcolors",
          "title": "Description Color",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "xlabel",
          "value": "X axis",
          "widget": "textfield",
          "title": "X Label",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "ylabel",
          "value": "",
          "widget": "textfield",
          "title": "Y Label",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "maxValuesToDisplay",
          "value": "20",
          "widget": "textfield",
          "title": "Max Values To Display",
          "description": "Maximum number of values to display in result.",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "graphType",
          "value": "PIE",
          "widget": "enum",
          "title": "Chart Type",
          "optionsMap": {
            "LINECHART": "Line Chart",
            "COLUMNCHART": "Side by Side Bar Chart",
            "BARCHART": "Stacked Bar Chart",
            "PIE": "Pie Chart",
            "SCATTERCHART": "Scatter Chart",
            "DUALLINECHART": "Dual Line Chart",
            "AREACHART": "Area Chart"
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "chartColors",
          "value": "#F2A993,#76D0D7,#B9ABE5,#EEC896,#DE95B0,#009cef,#86ABA1,#00AF91,#C2B8A3,#BFA2DB",
          "widget": "colors",
          "title": "Chart Colors",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "isStreaming",
          "value": "false",
          "widget": "array",
          "title": "Is Streaming?",
          "description": "Whether the Graph is a Streaming Graph or not",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "markerSize",
          "value": "12",
          "widget": "textfield",
          "title": "Marker size",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "xCol",
          "value": "resource_type",
          "widget": "variable",
          "title": "X Column",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "xSortCol",
          "value": "true",
          "widget": "array",
          "title": "Sort on X Column?",
          "description": "Whether to Sort on X column or not",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "yCols",
          "value": "[\"Resource_Type_Count\"]",
          "widget": "variables",
          "title": "Y Columns",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "ySortCol",
          "value": "",
          "widget": "variable",
          "title": "Y Sort Column",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "reNameYColumns",
          "value": "[]",
          "widget": "variables_selected",
          "title": "Rename Y Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "37",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "6px",
      "y": "20px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "bgColor",
          "value": "blue",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "width",
          "value": "364.222222px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "height",
          "value": "101.222222px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "comment",
          "value": "<p><strong>Calculate Classification Matrix</strong></p><ul><li>Create 10 Decile Bucket based on Fault Volume</li><li>For Each Decile Calculate Accuracy, Precession and Recall</li></ul><p><br></p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "38",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "802.883px",
      "y": "188.883px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "bgColor",
          "value": "gray",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "width",
          "value": "292.222222px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "height",
          "value": "82.222222px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "comment",
          "value": "<p>Calculate Min, Max, Avg, Total Faults, Total Actual Severe Faults, Total Predicted Severe Faults Based on Decile Ratio</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "39",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "378.883px",
      "y": "504.883px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "bgColor",
          "value": "gray",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "width",
          "value": "278.222222px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "height",
          "value": "67.222222px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "comment",
          "value": "<p>Calculate Accuracy Precession and Recall based on Decile Ratio</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "2",
      "target": "3",
      "id": 1
    },
    {
      "source": "1",
      "target": "3",
      "id": 2
    },
    {
      "source": "3",
      "target": "4",
      "id": 3
    },
    {
      "source": "4",
      "target": "5",
      "id": 4
    },
    {
      "source": "3",
      "target": "6",
      "id": 5
    },
    {
      "source": "6",
      "target": "7",
      "id": 6
    },
    {
      "source": "5",
      "target": "7",
      "id": 7
    },
    {
      "source": "3",
      "target": "8",
      "id": 8
    },
    {
      "source": "8",
      "target": "9",
      "id": 9
    },
    {
      "source": "9",
      "target": "7",
      "id": 10
    },
    {
      "source": "3",
      "target": "10",
      "id": 11
    },
    {
      "source": "10",
      "target": "12",
      "id": 12
    },
    {
      "source": "10",
      "target": "11",
      "id": 13
    },
    {
      "source": "12",
      "target": "13",
      "id": 14
    },
    {
      "source": "11",
      "target": "14",
      "id": 15
    },
    {
      "source": "8",
      "target": "15",
      "id": 16
    },
    {
      "source": "8",
      "target": "16",
      "id": 17
    },
    {
      "source": "16",
      "target": "17",
      "id": 18
    },
    {
      "source": "15",
      "target": "18",
      "id": 19
    },
    {
      "source": "14",
      "target": "19",
      "id": 20
    },
    {
      "source": "13",
      "target": "19",
      "id": 21
    },
    {
      "source": "18",
      "target": "19",
      "id": 22
    },
    {
      "source": "17",
      "target": "19",
      "id": 23
    },
    {
      "source": "19",
      "target": "22",
      "id": 24
    },
    {
      "source": "22",
      "target": "23",
      "id": 25
    },
    {
      "source": "23",
      "target": "24",
      "id": 26
    },
    {
      "source": "24",
      "target": "25",
      "id": 27
    },
    {
      "source": "7",
      "target": "25",
      "id": 28
    },
    {
      "source": "25",
      "target": "27",
      "id": 29
    },
    {
      "source": "27",
      "target": "26",
      "id": 30
    },
    {
      "source": "26",
      "target": "28",
      "id": 31
    },
    {
      "source": "2",
      "target": "31",
      "id": 32
    },
    {
      "source": "31",
      "target": "32",
      "id": 33
    },
    {
      "source": "31",
      "target": "33",
      "id": 34
    },
    {
      "source": "32",
      "target": "30",
      "id": 35
    },
    {
      "source": "33",
      "target": "34",
      "id": 36
    },
    {
      "source": "30",
      "target": "35",
      "id": 37
    },
    {
      "source": "34",
      "target": "36",
      "id": 38
    }
  ],
  "dataSetDetails": [],
  "engine": "scala"
}