{
  "name": "00-Data-Quality-Credir-Card-Transaction",
  "uuid": "54101af7-5a94-4f98-9c84-8f3018e44527",
  "category": "Data Quality",
  "parameters": "",
  "nodes": [
    {
      "id": "1",
      "name": "Dataset Structured",
      "iconImage": "fa fa-th-list",
      "description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset was defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",
      "details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",
      "examples": "",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "36px",
      "y": "161px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dataset",
          "value": "87dbac83-f994-4512-abb4-b5b1775d1216",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "2",
      "name": "Import Validator",
      "iconImage": "fa fa-tumblr-square",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "173.889px",
      "y": "42.8889px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Row Values",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "3",
      "name": "Null Values In Column",
      "iconImage": "fa fa-tumblr-square",
      "description": "Number of Null Values in Selected Columns.",
      "details": "This node identifies number of Null values and its percentage against the total data length in the selected columns.<br>",
      "examples": "A set of columns can be selected to display count of Null values on.<br>\n<br>\nIf NullValuesInColumn node is configured to display count of Null values in [EMP_CD], [EMP_NAME], [DEPT] and [AGE] columns from the incoming dataset<br>\n<br>\nthen outgoing Dataframe would be created as below displaying count of Null values in each column and it's percentage.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeNullValuesInColumn",
      "x": "284.778px",
      "y": "38.7639px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "inputCols",
          "value": "[\"applicant_id\",\"applicant_name\",\"age_years\",\"approval_type\",\"application_score\",\"fico_score\",\"limit_approved\",\"dod_stat\",\"state\",\"employer\",\"manual_reviewer_comments\"]",
          "widget": "variables",
          "title": "Column Names",
          "description": "Name of columns for Number of Null Values Check",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "4",
      "name": "Drop Null Rows for Applicant name and Id",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by dropping rows containing null values for selected Columns",
      "details": "This node creates a new DataFrame by dropping rows containing NULL values in selected columns.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE05       |    MARK        |               |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    TONY        |    MARKETING  |    <br>\nE04       |    MARTIN      |    MARKETING  |    45<br>\n<br>\nIncoming Dataframe has NULL values for two rows. For selected Columns DEPT and AGE,<br>\nusing DropRowsWithNull node would result in below outgoing Dataframe created by dropping rows having NULL values for selected columns:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE04       |    MARTIN      |    MARKETING  |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropRowsWithNullMultipleColumns",
      "x": "177.889px",
      "y": "155.889px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "columns_to_check",
          "value": "[\"applicant_id\",\"applicant_name\"]",
          "widget": "variables",
          "title": "Columns to Check",
          "description": "Columns to be processed for missing values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "5",
      "name": "Imputing With Mean for age, applicant score and fico score",
      "iconImage": "fa fa-tumblr-square",
      "description": "Imputing the continuous variables by mean.",
      "details": "This node imputes the missing values in the specified columns by mean of the values in the column.<br>",
      "examples": "Incoming Dataframe has following rows and [AGE] column has missing value / [NULL] for some rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |\t\t\t<br>\nCD04       |    MATT         |\t\t\t<br>\n<br>\nIf imputingwithmeanvalue node is configured to Impute [AGE] with mean value then missing values in [AGE] column would be replaced with 35 which is the mean of [AGE] column.<br>\nOutgoing Dataframe would result as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |    35\t\t\t<br>\nCD04       |    MATT         |    35<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeReplaceMissingValueWithMean",
      "x": "284.889px",
      "y": "155.889px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "inputCols",
          "value": "[\"age_years\",\"application_score\",\"fico_score\"]",
          "widget": "variables",
          "title": "Column Names",
          "description": "Columns type should be continuous",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "6",
      "name": "Imputing With Constant for approved limit, approval type, dod status, employer and state",
      "iconImage": "fa fa-tumblr-square",
      "description": "It imputes missing value with constant value. It fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.",
      "details": "This node imputes the missing value with constant value.<br>\n<br>\nIt fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.<br>",
      "examples": "Incoming Dataframe has following rows and [AGE] column has missing values / [NULL] for some rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |\t\t\t<br>\nCD04       |    MATT         |\t\t\t<br>\n<br>\nIf imputingwithconstatnt node is configured to Impute [AGE] with 45 then missing values in [AGE] column would be replaced with 45.<br>\nOutgoing Dataframe would result as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |    45\t\t\t<br>\nCD04       |    MATT         |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeReplaceMissingValueWithConstant",
      "x": "500px",
      "y": "156px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "colNames",
          "value": "[\"limit_approved\",\"approval_type\",\"dod_stat\",\"employer\",\"state\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns to be processed for missing values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constants",
          "value": "[\"2000\",\"Manual\",\"Inactive\",\"Unknown-xyz\",\"XY\"]",
          "widget": "variables_list_textfield",
          "title": "Constants",
          "description": "Missing value will be replaced with constant",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "7",
      "name": "Mapping application score and fico score to review comments",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "394px",
      "y": "158px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "manual_reviewer_comments_new",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"(application_score+fico_score)/2 < 400\",\"(application_score+fico_score)/2 > 400 and (application_score+fico_score)/2 < 550\",\" (application_score+fico_score)/2 > 550 and (application_score + fico_score)/2 < 750\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"'Poor'\",\"'Average'\",\"'Good'\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "'Very Good'",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "9",
      "name": "Validate all columns for valid range and categories",
      "iconImage": "fa fa-tumblr-square",
      "description": "Validation Multiple Node",
      "details": "<h2>Validate Fields Advanced Node Details</h2>\n<br>\nThis node creates two outgoing Dataframes based on the result of Validation Rules on the incoming Dataframe. <br>\nFirst outgoing Dataframe consists of rows that succeeds the Validation Rules and second one consists of failed rows.   <br>\n<br>\nThis node facilitates checking of multiple conditions in each rule joined by AND or OR.<br>\n<br>\nMultiple validation rules can be defined for multiple columns. Succeeded and Failed Dataframes are created by applying all the validation rules on the incoming Dataframes.<br>",
      "examples": "<h2>Validate Fields Advanced Node Examples</h2>\n<br>\nIncoming Dataframe has following rows:<br>\n<br>\nEMP_CD       |    EMP_NAME       |    DEPT       |    SALARY       |    AGE       |    DATE_OF_JOINING       |    EMAIL<br>\n------------------------------------------------------------------------------------------------------------------------------------<br>\nE01          |    ANTHONY        |    HR         |    50000        |    40        |    2020-12-12            |    anthony@hrdept.com<br>\nE02          |    LISA           |    HR         |    35000        |    35        |    2021-02-30            |    lisa@hrdept.com<br>\nE03          |    MARTIN         |    HR         |    20000        |    25        |    2020-01-01            |    martin@nodept.com<br>\nE04          |    DAVID          |    SALES      |    55000        |    40        |    2021-13-13            |    david@salesdept.com<br>\nE05          |    MARK           |    SALES      |    60000        |    27        |    2020-01-01            |    mark@salesdept.com<br>\nE06          |    JOE            |    SALES      |    40000        |    31        |    2010-01-01            |    joe@salesdept.com<br>\nE07          |    BELLA          |    HR         |    60000        |    24        |    2001-12-12            |    bella@hrdept.com<br>\n<br>\nif following Validation Rules are defined in Validation node:<br>\n<br>\nCOLUMNS       |    FUNCTION             |    VALUES       |    CONDITION    |    FUNCTION               |    VALUES<br>\n------------------------------------------------------------------------------------------------------------------------<br>\nAGE           |    VALUE_GREATER_THAN   |    30           |    AND          |    VALUE_LESS_THAN        |    41<br>\nEMP_NAME      |    LENGTH_GREATER_THAN  |    2            |    AND          |    LENGTH_LESS_THAN       |    5<br>\n<br>\nthen outgoing Dataframes would be created as below:<br>\n<br>\n<h4> Succeeded Dataframe consisting of rows that succeeded Validation Rules:</h4>\n<br>\nEMP_CD    |   EMP_NAME  |    DEPT    |  SALARY  |    AGE   |  DATE_OF_JOINING  |  EMAIL              |  validation_result | validation_result_reason<br>\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------<br>\nE02       |   LISA      |    HR      |  35000   |    35    |  2021-02-30       |  lisa@hrdept.com    |  1                 |<br>\nE06       |   JOE       |    SALES   |  40000   |    31    |  2010-01-01       |  joe@salesdept.com  |  1                 |<br>\n<br>\n<h4> Failed Dataframe consisting of rows that failed Validation Rules:</h4>\n<br>\nEMP_CD    |   EMP_NAME  |    DEPT    |  SALARY  |    AGE   |  DATE_OF_JOINING  |  EMAIL              |  validation_result | validation_result_reason<br>\n-----------------------------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |   ANTHONY   |    HR      |  50000   |    40    |  2020-12-12       |  anthony@hrdept.com |  0                 | EMP_NAME value length is not less than 5 ,<br>\nE03       |   MARTIN    |    HR      |  20000   |    25    |  2020-01-01       |  martin@nodept.com  |  0                 | AGE is not greater than 30 , EMP_NAME value length is not less than 5 ,<br>\nE04       |   DAVID     |    SALES   |  55000   |    40    |  2021-13-13       |  david@salesdept.com|  0                 | EMP_NAME value length is not less than 5 ,<br>\nE05       |   MARK      |    SALES   |  60000   |    27    |  2020-01-01       |  mark@salesdept.com |  0                 | AGE is not greater than 30 ,<br>\nE07       |   BELLA     |    HR      |  60000   |    24    |  2001-12-12       |  bella@hrdept.com   |  0                 | AGE is not greater than 30 , EMP_NAME value length is not less than 5 ,<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeValidationMultiple",
      "x": "295px",
      "y": "336px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textfield",
          "title": "Description",
          "description": "Validations being Performed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "measureValue",
          "value": "80.0",
          "widget": "textfield",
          "title": "Validation Successful if Percent Good Records >= ",
          "description": "Condition for Validation Passing",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "inputCols",
          "value": "[\"age_years\",\"application_score\",\"fico_score\",\"approval_type\",\"limit_approved\",\"dod_stat\",\"employer\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "functions1",
          "value": "[\"VALUE_LESS_THAN\",\"VALUE_GREATER_THAN\",\"VALUE_GREATER_THAN\",\"VALUE_EQUALS\",\"VALUE_GREATER_THAN\",\"VALUE_EQUALS\",\"IS_NOT_NULL\"]",
          "widget": "variables_list_array",
          "title": "Function",
          "description": "Validation Function to apply",
          "optionsArray": [
            "NONE",
            "LENGTH_LESS_THAN",
            "LENGTH_EQUALS",
            "LENGTH_GREATER_THAN",
            "VALUE_LESS_THAN",
            "VALUE_EQUALS",
            "VALUE_GREATER_THAN",
            "IS_NULL",
            "IS_NOT_NULL",
            "IS_VALID_EMAIL_ADDRESS",
            "IS_VALID_DATE_FORMAT"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values1",
          "value": "[\"75\",\"-1\",\"-1\",\"'Manual'\",\"-1\",\"'Active'\",\"\"]",
          "widget": "variables_list_textfield",
          "title": "Values",
          "description": "Values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditions1",
          "value": "[\"AND\",\"AND\",\"AND\",\"OR\",\"AND\",\"OR\",\"\"]",
          "widget": "variables_list_array",
          "title": "Condition",
          "description": "Validation Condition to apply",
          "optionsArray": [
            "NONE",
            "AND",
            "OR"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "functions2",
          "value": "[\"VALUE_GREATER_THAN\",\"LENGTH_LESS_THAN\",\"VALUE_LESS_THAN\",\"VALUE_EQUALS\",\"VALUE_LESS_THAN\",\"VALUE_EQUALS\",\"\"]",
          "widget": "variables_list_array",
          "title": "Function",
          "description": "Validation Function to apply",
          "optionsArray": [
            "NONE",
            "LENGTH_LESS_THAN",
            "LENGTH_EQUALS",
            "LENGTH_GREATER_THAN",
            "VALUE_LESS_THAN",
            "VALUE_EQUALS",
            "VALUE_GREATER_THAN",
            "IS_NULL",
            "IS_NOT_NULL",
            "IS_VALID_EMAIL_ADDRESS",
            "IS_VALID_DATE_FORMAT"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values2",
          "value": "[\"18\",\"1000\",\"1000\",\"'Auto'\",\"50000\",\"'Inactive'\",\"\"]",
          "widget": "variables_list_textfield",
          "title": "Values",
          "description": "Values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "conditions2",
          "value": "[\"\",\"\",\"\",\"OR\",\"NONE\",\"\",\"\"]",
          "widget": "variables_list_array",
          "title": "Condition",
          "description": "Validation Condition to apply",
          "optionsArray": [
            "NONE",
            "AND",
            "OR"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "functions3",
          "value": "[\"\",\"\",\"\",\"VALUE_EQUALS\",\"NONE\",\"\",\"\"]",
          "widget": "variables_list_array",
          "title": "Function",
          "description": "Validation Function to apply",
          "optionsArray": [
            "NONE",
            "LENGTH_LESS_THAN",
            "LENGTH_EQUALS",
            "LENGTH_GREATER_THAN",
            "VALUE_LESS_THAN",
            "VALUE_EQUALS",
            "VALUE_GREATER_THAN",
            "IS_NULL",
            "IS_NOT_NULL",
            "IS_VALID_EMAIL_ADDRESS",
            "IS_VALID_DATE_FORMAT"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values3",
          "value": "[\"\",\"\",\"\",\"'Conditional'\",\"\",\"\",\"\"]",
          "widget": "variables_list_textfield",
          "title": "Values",
          "description": "Values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "10",
      "name": "Distinct Values In Column",
      "iconImage": "fa fa-tumblr-square",
      "description": "",
      "details": "This node displays distinct combination of values in the selected columns. <br>\n<br>\nIf only one column is selected then it displays Distinct values present in that column. <br>\nIf more than one column is selected then it displays distinct combination of values present in the selected columns.<br>",
      "examples": "If DistinctValuesInColumn node is configured to display distinct values in [Location] and [Dept] columns from incoming dataset<br>\nthen outgoing Dataframe would be created in tabular format displaying unique combination of data between the selected columns.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDistinctValues",
      "x": "396.778px",
      "y": "39.7639px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "distinctCols",
          "value": "[\"state\"]",
          "widget": "variables",
          "title": "Column Names",
          "description": "Name of columns to get the distinct combination of values.",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "11",
      "name": "Cast age, application score and fico score to short int",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by casting the specified columns into new types",
      "details": "This node creates a new DataFrame by casting the specified columns into new types.<br>\n<br>\nOption to replace existing column or create a new column after conversion can be selected in the node.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nINV_NO    |    INV_DATE          |    INV_AMT       <br>\n----------------------------------------------------<br>\nSTRING    |    STRING            |    STRING       <br>\n----------------------------------------------------<br>\nINV001    |    2010-12-28        |    1000.0        <br>\nINV002    |    2020-10-15        |    1500.0        <br>\nINV003    |    2010-01-01        |    100.0         <br>\n<br>\nif MultiCastColumnType node is configured to perform conversions as below:<br>\n<br>\nCOLUMNS    |    NEW DATA TYPE    |    REPLACE EXISTING COLS \t<br>\n--------------------------------------------------------------<br>\nINV_DATE   |    DATE             |    false<br>\nINV_DATE   |    LONG             |    false<br>\n<br>\nthen new columns would be added in outgoing Dataframe as below after conversion:<br>\n<br>\nINV_NO    |    INV_DATE          |    INV_AMT       |    INV_DATE-new  |    INV_AMT-new       <br>\n------------------------------------------------------------------------------------------<br>\nSTRING    |    STRING            |    STRING        |    DATE          |    LONG       <br>\n------------------------------------------------------------------------------------------<br>\nINV001    |    2010-12-28        |    1000.0        |    2010-12-28    |    1000        <br>\nINV002    |    2020-10-15        |    1500.0        |    2020-10-15    |    1500        <br>\nINV003    |    2010-01-01        |    100.0         |    2010-01-01    |    100<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeMultiCastColumnType",
      "x": "649px",
      "y": "156px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "inputColNames",
          "value": "[\"age_years\",\"application_score\",\"fico_score\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"SHORT\",\"SHORT\",\"SHORT\"]",
          "widget": "variables_list_array",
          "title": "New Data Type",
          "description": "New data type(INTEGER, DOUBLE, STRING, LONG, SHORT)",
          "optionsArray": [
            "BOOLEAN",
            "BYTE",
            "DATE",
            "DECIMAL",
            "DOUBLE",
            "FLOAT",
            "INTEGER",
            "LONG",
            "SHORT",
            "STRING",
            "TIMESTAMP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "replaceExistingCols",
          "value": "[\"true\",\"true\",\"true\"]",
          "widget": "variables_list_array",
          "title": "Replace Existing Cols",
          "description": "Whether to replace existing Columns or create New Ones",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "13",
      "name": "Validate length of string type columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "Validation Node",
      "details": "<h2>Validate Fields Simple Node Details</h2>\n<br>\nThis node creates two outgoing Dataframes based on the result of Validation Rules on the incoming Dataframe. <br>\nFirst outgoing Dataframe consists of rows that succeeds the Validation Rules and second one consists of failed rows.   <br>\n<br>\nThis node facilitates checking of one condition in each rule.<br>\n<br>\nMultiple validation rules can be defined for multiple columns. Succeeded and Failed Dataframes are created by applying all the validation rules on the incoming Dataframes.<br>",
      "examples": "<h2>Validate Fields Simple Node Examples</h2>\n<br>\nIncoming Dataframe has following rows:<br>\n<br>\nEMP_CD       |    EMP_NAME       |    DEPT       |    SALARY       |    AGE       |    DATE_OF_JOINING       |    EMAIL<br>\n------------------------------------------------------------------------------------------------------------------------------------<br>\nE01          |    ANTHONY        |    HR         |    50000        |    40        |    2020-12-12            |    anthony@hrdept.com<br>\nE02          |    LISA           |    HR         |    35000        |    35        |    2021-02-30            |    lisa@hrdept.com<br>\nE03          |    MARTIN         |    HR         |    20000        |    25        |    2020-01-01            |    martin@nodept.com<br>\nE04          |    DAVID          |    SALES      |    55000        |    40        |    2021-13-13            |    david@salesdept.com<br>\nE05          |    MARK           |    SALES      |    60000        |    27        |    2020-01-01            |    mark@salesdept.com<br>\nE06          |    JOE            |    SALES      |    40000        |    31        |    2010-01-01            |    joe@salesdept.com<br>\nE07          |    BELLA          |    HR         |    60000        |    24        |    2001-12-12            |    bella@hrdept.com<br>\n<br>\nif following Validation Rules are defined in Validation node:<br>\n<br>\nCOLUMNS           |    FUNCTION                 |    VALUES \t<br>\n--------------------------------------------------------------------------<br>\nDATE_OF_JOINING   |    IS_VALID_DATE_FORMAT     |    yyyy-MM-dd<br>\nAGE               |    VALUE_LESS_THAN          |    36<br>\n<br>\nthen outgoing Dataframes would be created as below:<br>\n<br>\n<h4> Succeeded Dataframe consisting of rows that succeeded Validation Rules:</h4>\n<br>\nEMP_CD       |    EMP_NAME       |    DEPT       |    SALARY       |    AGE       |    DATE_OF_JOINING       |    EMAIL<br>\n------------------------------------------------------------------------------------------------------------------------------------<br>\nE03          |    MARTIN         |    HR         |    20000        |    25        |    2020-01-01            |    martin@nodept.com<br>\nE05          |    MARK           |    SALES      |    60000        |    27        |    2020-01-01            |    mark@salesdept.com<br>\nE06          |    JOE            |    SALES      |    40000        |    31        |    2010-01-01            |    joe@salesdept.com<br>\nE07          |    BELLA          |    HR         |    60000        |    24        |    2001-12-12            |    bella@hrdept.com<br>\n<br>\n<h4> Failed Dataframe consisting of rows that failed Validation Rules:</h4>\n<br>\nEMP_CD       |    EMP_NAME       |    DEPT       |    SALARY       |    AGE       |    DATE_OF_JOINING       |    EMAIL<br>\n------------------------------------------------------------------------------------------------------------------------------------<br>\nE01          |    ANTHONY        |    HR         |    50000        |    40        |    2020-12-12            |    anthony@hrdept.com<br>\nE02          |    LISA           |    HR         |    35000        |    35        |    2021-02-30            |    lisa@hrdept.com<br>\nE04          |    DAVID          |    SALES      |    55000        |    40        |    2021-13-13            |    david@salesdept.com<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeValidation",
      "x": "409px",
      "y": "336px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textfield",
          "title": "Description",
          "description": "Validations being Performed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "inputCols",
          "value": "[\"applicant_name\",\"approval_type\",\"dod_stat\",\"employer\",\"manual_reviewer_comments\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "functions",
          "value": "[\"VALUE_LESS_THAN\",\"LENGTH_LESS_THAN\",\"LENGTH_LESS_THAN\",\"VALUE_LESS_THAN\",\"LENGTH_LESS_THAN\"]",
          "widget": "variables_list_array",
          "title": "Function",
          "description": "Validation Function to apply",
          "optionsArray": [
            "LENGTH_LESS_THAN",
            "LENGTH_EQUALS",
            "LENGTH_GREATER_THAN",
            "VALUE_LESS_THAN",
            "VALUE_EQUALS",
            "VALUE_GREATER_THAN",
            "IS_NULL",
            "IS_NOT_NULL",
            "IS_VALID_EMAIL_ADDRESS",
            "IS_VALID_DATE_FORMAT"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"129\",\"257\",\"257\",\"65\",\"257\"]",
          "widget": "variables_list_textfield",
          "title": "Values",
          "description": "Values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "15",
      "name": "Save CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "Saves the DataFrame into the specified location in CSV Format",
      "details": "This node saves incoming Dataframe into the specified location in CSV format.<br>",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveCSV",
      "x": "874px",
      "y": "147px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "/home/sparkflows/fire-data/data/Gbank-Sample/gbankcc-credit-decisioning-validated-data",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the CSV files",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "17",
      "name": "Read CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>Refresh Schema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the refresh schema and <b>-</b> button next to the column names.<br>",
      "examples": "",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "43px",
      "y": "329px",
      "hint": "Refresh the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "/home/sparkflows/fire-data/data/Gbank-Sample/gbankcc-credit-decisioning-validated-data.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "18",
      "name": "Import Validator",
      "iconImage": "fa fa-tumblr-square",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "172px",
      "y": "321px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Row Values",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "19",
      "name": "Save Excel",
      "iconImage": "/images/icons/node-icon/excel.svg",
      "description": "Saves the DataFrame into the specified location in XLS Format",
      "details": "",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveExcel",
      "x": "843px",
      "y": "309px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "/home/sparkflows/fire-data/data/Gbank-Sample/gbankcc-credit-decisioning-validated.xlsx",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the XLS file",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dataAddress",
          "value": "sheet1",
          "widget": "textfield",
          "title": "SheetName",
          "description": "SheetName and Range: 'My Sheet'!A1",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "1",
      "target": "2",
      "id": 1
    },
    {
      "source": "2",
      "target": "3",
      "id": 2
    },
    {
      "source": "1",
      "target": "4",
      "id": 3
    },
    {
      "source": "4",
      "target": "5",
      "id": 4
    },
    {
      "source": "5",
      "target": "7",
      "id": 5
    },
    {
      "source": "7",
      "target": "6",
      "id": 6
    },
    {
      "source": "3",
      "target": "10",
      "id": 7
    },
    {
      "source": "11",
      "target": "15",
      "id": 8
    },
    {
      "source": "17",
      "target": "18",
      "id": 9
    },
    {
      "source": "11",
      "target": "19",
      "id": 10
    },
    {
      "source": "18",
      "target": "9",
      "id": 11
    },
    {
      "source": "9",
      "target": "13",
      "id": 12
    },
    {
      "source": "6",
      "target": "11",
      "id": 13
    }
  ],
  "dataSetDetails": [
    {
      "id": 265,
      "uuid": "87dbac83-f994-4512-abb4-b5b1775d1216",
      "header": true,
      "readOptions": "{\"mode\":\"PERMISSIVE\"}",
      "path": "/home/sparkflows/fire-data/data/BFSI/Credit-Card-Transaction/bank_credit_decisioning.csv",
      "delimiter": ",",
      "datasetType": "CSV",
      "datasetSchema": "{\"colNames\":[\"applicant_id\",\"applicant_name\",\"age_years\",\"approval_type\",\"application_score\",\"fico_score\",\"limit_approved\",\"dod_stat\",\"state\",\"employer\",\"manual_reviewer_comments\"],\"colTypes\":[\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"],\"colFormats\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"colMLTypes\":[\"NUMERIC\",\"TEXT\",\"NUMERIC\",\"TEXT\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"TEXT\",\"TEXT\",\"TEXT\",\"TEXT\"]}"
    }
  ],
  "engine": "scala"
}