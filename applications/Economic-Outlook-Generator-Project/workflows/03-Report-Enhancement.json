{
  "name": "03-Report-Enhancement",
  "uuid": "6587882f-70a1-449d-92fa-355e0da76eff",
  "category": "-",
  "description": "-",
  "parameters": "--var destinationPath=/home/sparkflows/fire-data/data/GENAI/Economic-Outlook-Generator-Project/Ref-Document-Repo-2025-Q1/Uploads/",
  "nodes": [
    {
      "id": "1",
      "name": "PySpark",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "details": "<h2>Pyspark Details</h2>\n<br>\nThis node receives receives an input pyspark dataframe in function called myfn.<br>\n<br>\nThe pyspark/python code processes it and returns one computed pyspark dataframe.<br>",
      "examples": "<h2>Pyspark Examples</h2>\n<br>\nInput Schema: id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> Add the house_type column</h4>\n<br>\nfrom pyspark.sql.types import StringType<br>\nfrom pyspark.sql.functions import *<br>\nfrom pyspark.sql import *<br>\nfrom fire.workflowcontext import *<br>\n<br>\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict):<br>\nhouse_type_udf = udf(lambda bedrooms: \"big house\" if int(bedrooms) >2 else \"small house\", StringType())<br>\nfiletr_df = inDF.select(\"id\", \"price\", \"lotsize\", \"bedrooms\")<br>\noutDF = filetr_df.withColumn(\"house_type\", house_type_udf(filetr_df.bedrooms))<br>\nreturn outDF<br>\n<br>\n<h4> Using pandas dataframe</h4>\n<br>\nfrom pyspark.sql.types import StringType<br>\nfrom pyspark.sql.functions import *<br>\nfrom pyspark.sql import *<br>\n<br>\nfrom fire.workflowcontext import *<br>\n<br>\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict):<br>\n# Convert the Spark DataFrame to a Pandas DataFrame<br>\npdf = inDF.select(\"*\").toPandas()<br>\n<br>\n# Display the result on the Executions page<br>\nworkflowContext.outStr(id, \"Outputting Pandas Dataframe\")<br>\n<br>\n# Display the dataframe on the Executions page<br>\nworkflowContext.outPandasDataframe(id, \"Pandas DataFrame\", pdf, 10)<br>\n<br>\n# Create a Spark DataFrame from a Pandas DataFrame<br>\ndf = spark.createDataFrame(pdf)<br>\n<br>\nreturn df<br>\n<br>\n<h4> Numpy 2d array to pandas dataframe & pandas dataframe to spark dataframe</h4>\n<br>\nfrom pyspark.sql.types import StringType<br>\nfrom pyspark.sql.functions import *<br>\nfrom pyspark.sql import *<br>\nimport numpy as np<br>\nimport pandas as pd<br>\n<br>\nfrom fire.workflowcontext import *<br>\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict):<br>\n<br>\n# Create the numpy 2d array<br>\nexample_array = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])<br>\n<br>\n# Convert to Pandas Dataframe<br>\npandas_dataframe = pd.DataFrame(example_array, columns=['a', 'b', 'c', 'd'])<br>\n<br>\n# Convert Pandas Dataframe to Spark Dataframe<br>\nspark_dataframe = spark.createDataFrame(pandas_dataframe)<br>\nreturn spark_dataframe<br>",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "246.883px",
      "y": "136.883px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import * \nfrom fire.workflowcontext import WorkflowContext \nimport os\nfrom openai import OpenAI\nclient = OpenAI(api_key=\"$openapi_key\")\nos.environ[\"OPENAI_API_KEY\"] = \"$openapi_key\"\nos.environ[\"GOOGLE_API_KEY\"] = \"$Gemini_API\"\n\nfrom fpdf import FPDF\nimport json\nimport base64\n# import openai\nimport fitz\nimport os\nfrom pdf2image import convert_from_path\nfrom langchain.document_loaders import DirectoryLoader, PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import FAISS\nimport pickle\nfrom datetime import datetime\n\nmodel = '${SelectModel}'\ndata_path = '${destinationPath}' #'${genaiHome}'+'${destinationPath}'\ndata_path =\"/\".join(data_path.split(\"/\")[:-1]) + \"/\"\noutput_dir_path = \"/\".join(data_path.split(\"/\")[:-2]) + \"/Output\"\noutput_latest_dir_path = \"/\".join(data_path.split(\"/\")[:-2]) + \"/Output-Latest\"\ntemp_image = \"/\".join(data_path.split(\"/\")[:-2]) + \"/Temp-Image\"\ndatabase_directory = \"/\".join(data_path.split(\"/\")[:-2]) + \"/Database\"\nprint(data_path)\nif not os.path.exists(output_dir_path):\n\tos.mkdir(output_dir_path)\nif not os.path.exists(temp_image):  \n\tos.mkdir(temp_image)\nif not os.path.exists(database_directory): \n  os.mkdir(database_directory)\n  \nsource_dir = output_latest_dir_path\ndest_dir = output_dir_path\ncurrent_year = datetime.now().year\n# Iterate over all files in the source directory\nfor filename in os.listdir(source_dir):\n    # Construct the full file path\n    source_file = os.path.join(source_dir, filename)\n    dest_file = os.path.join(dest_dir, filename)\n\n    # Move the file to the destination directory by renaming\n    os.rename(source_file, dest_file)\n    print(f'Moved: {source_file} -> {dest_file}')\n\nprint(\"All files have been moved successfully!\")\n\nclass PDF(FPDF):\n    def header(self):\n        self.set_font('Arial', 'B', 12)\n        self.cell(0, 10, f'Outlook {current_year}', 0, 1, 'C')\n        self.ln(10)\n        self.line(10, 20, 200, 20)  # Draw line after header\n\n    def footer(self):\n        self.set_y(-15)\n        self.set_font('Arial', 'I', 8)\n        self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')\n        self.line(10, self.get_y() - 5, 200, self.get_y() - 5)  # Draw line before footer\n\n    def render_text(self, text):\n        lines = text.split('\\n')\n        for line in lines:\n            self.multi_cell(0, 10, line)\n            self.ln(5)\n\nclass DocumentInsightGenerator():\n    def __init__(self, prompt):\n        self.images = []\n        self.base_prompt = [\n            {\n                \"role\": \"system\",\n                \"content\": \"you are a helpful assistant who's an expert at reading and creating financial documents and reports\"\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": prompt\n                    }\n                ]\n            }\n        ]\n\n    def encode_image(self, image_path):\n        with open(image_path, \"rb\") as image_file:\n            return base64.b64encode(image_file.read()).decode('utf-8')\n\n    def add_image(self, image_path):\n        encoded_image = self.encode_image(image_path)\n        self.images.append(\n            {\n                \"type\": \"image_url\",\n                \"image_url\": {\n                    \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n                }\n            }\n        )\n\n    def generate_response(self, provider=\"openai\"):\n        # if not self.images:\n        #     raise ValueError(\"No images have been added.\")\n\n        # Append images to the user's content\n        self.base_prompt[1]['content'].extend(self.images)\n        if provider == \"openai\":\n            # response = openai.ChatCompletion.create(\n            response = client.chat.completions.create(\n                model=\"gpt-4o\",\n                response_format={ \"type\": \"json_object\" },\n                messages=self.base_prompt,\n                max_tokens=4096,\n            )\n        elif provider == \"gemini\":\n            #Setting the api key\n            gemini.api_key = GOOGLE_API_KEY\n            response = gemini.ChatCompletion.create(\n                model=\"gemini-1.5-pro-exp-0801\", \n                response_format={\"type\": \"json_object\"},\n                messages=self.base_prompt,\n                max_tokens=4096,\n            )\n        else:\n            raise ValueError(\"Unsupported provider\")\n        return response\n\n    def generate_insights(self):\n        response = self.generate_response()\n        return response.choices[0].message.content\n\n\nclass MultimodalPreprocessor():\n    def __init__(self, pdf_directory = None, output_directory = None, image_info_list = None, db = None):\n        self.pdf_directory = None\n        self.output_directory = None\n        self.image_info_list = []\n        self.db = None\n\n    def ingest_into_faiss(self, **faiss_params):\n        loader = DirectoryLoader(self.pdf_directory, glob=\"**/*.pdf\", show_progress=True, loader_cls=PyPDFLoader)\n        docs = loader.load()\n\n        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1250, chunk_overlap=150, add_start_index=True)\n        splits = text_splitter.split_documents(docs)\n\n        embeddings = OpenAIEmbeddings()\n        self.db = FAISS.from_documents(splits, embeddings)\n\n        return self.db\n\n    def convert_pdfs_to_images(self):\n            if not os.path.exists(self.output_directory):\n                os.makedirs(self.output_directory)\n\n            for pdf_file in os.listdir(self.pdf_directory):\n                if pdf_file.endswith(\".pdf\"):\n                    pdf_path = os.path.join(self.pdf_directory, pdf_file)\n                    doc = fitz.open(pdf_path)\n                    for page_num in range(len(doc)):\n                        page = doc.load_page(page_num)\n                        pix = page.get_pixmap()\n                        image_filename = f\"{os.path.splitext(pdf_file)[0]}_page_{page_num + 1}.png\"\n                        image_path = os.path.join(self.output_directory, image_filename)\n                        pix.save(image_path)\n                        self.image_info_list.append([image_path, pdf_file, page_num + 1])\n\n            return self.image_info_list\n\n    def preprocess(self, directory, save_on_disk = True): ## main method 1\n        self.pdf_directory = directory\n        self.output_directory = directory + '/images'\n        print(\"Ingesting into Faiss\")\n        self.ingest_into_faiss()\n        print(\"Converting PDFs to Images\")\n        self.convert_pdfs_to_images()\n        print(\"preprocessing Done!\")\n\n        if save_on_disk == True:\n            self.save_faiss_db()\n            self.save_image_db()\n\n        print(\"db saved on disk\")\n        # return self.db, self.image_info_list\n\n    def extract_page_numbers(self, search_results):\n        pg_nos = []\n        for doc in search_results:\n            pg_nos.append([doc.metadata['source'], doc.metadata['page']])\n        return pg_nos\n\n    def search_images(self, search_list):\n        result_list = []\n\n        for search_item in search_list:\n            search_pdf, search_page = search_item\n\n            for image_info in self.image_info_list:\n                image_path, source_pdf, page_number = image_info\n\n                if os.path.basename(search_pdf) == source_pdf and search_page == page_number:\n                    result_list.append(image_path)\n                    break\n\n        return result_list\n\n    def multimodal_query(self, query, k = 7):\n        search_results = self.db.similarity_search(query, k = k)\n        pg_nos = self.extract_page_numbers(search_results)\n        result_paths = self.search_images(pg_nos)\n        return search_results, result_paths\n\n    def save_faiss_db(self):\n        self.db.save_local(database_directory +\"/faiss_index\")\n\n    def load_faiss_db(self):\n        self.db = FAISS.load_local(database_directory+\"/faiss_index\", embeddings=OpenAIEmbeddings())\n        return self.db\n\n    def save_image_db(self):\n        with open(database_directory+\"/image_info_list.json\", \"w\") as f:\n            json.dump(self.image_info_list, f)\n\n    def load_image_db(self):\n        with open(database_directory +\"/image_info_list.json\", \"r\") as f:\n            self.image_info_list = json.load(f)\n        return self.image_info_list\n\n    def format_docs(self, docs):\n        return \"\\n\\n\".join(doc.page_content+ \"source: \" + doc.metadata['source'] for doc in docs)\n\n    def load_db(self):\n        self.db = self.load_faiss_db()\n        self.image_info_list = self.load_image_db()\n        # return self.db, self.image_info_list\n        print(\"DB loaded from path\")\n\n\nclass MultimodalReportGenerator(MultimodalPreprocessor):\n    def __init__(self, pdf_directory = None, output_directory = None, image_info_list = [], db = None):\n        if db is None:\n            super().__init__(pdf_directory, output_directory, image_info_list)\n        else:\n\n            self.pdf_directory = pdf_directory\n            self.output_directory = output_directory\n            self.image_info_list = image_info_list\n            self.db = db\n\n        self.report = []\n\n    def create_base_prompt(self, context, question):\n        prompt = \"\"\"\n        Use the following pieces of context to answer the question at the end.\n        If you don't know the answer, just say that you don't know, don't try to make up an answer.\n        do not hallucinate\n\n        follow the below instructions strictly:\n        you will be given documents based on financial analysis and reports, based on the given input question you will generate a detailed report in 300 to 400 words\n\n        do not add a conclusion!!, just generate the report, if the content is too short, generate a report in as many words as possible, do not create your own information\n\n        you will also be given images of the context, which may include charts and tables. use these values to generate the report (remember facts and figures are very important for a financial report)\n\n        the generated report should be properly formatted\n\n        based on the charts and tables, you will also generate a chart for the most import figures in line with the summary generated,\n\n        return the content as a json of this format (follow this format strictly, the output has to be a json, do not include any character not supported in jsons)\n\n        {\n            report: generated_report in text format (do not use * or # in the output),\n            charts: [\n                {\n                    \"python_code\": python code. (save the chart with name as the title of the chart exactly as mentioned, do not add underscores or any other extra characters) the chart has to saved as \"\"\"+ temp_image+\"\"\"/chart name.png (this path is fixed, do not change it, only the chart name should be added appropriately), make sure the parameters are right (do not miss out on things like bar width),\n                    \"directory\": directory of the chart\n                }\n            ]\n        }\n\n        follow the instructions strictly (do not change formats, keep it consistent)\n\n        you will also include the source of the sentence you are using to generate the answer. (sources will be mentioned towards the end of sentences as citations, use only the filename as source, do not return the entire path )\"\"\" + f\"\"\"\n        {context}\n\n        Question: {question}\n\n        Helpful Answer:\"\"\"\n\n        return prompt\n\n    def get_modify_prompt(self, regenerate_charts, gen_content, question, language):\n        prompt = \"\"\"\n        Use the following pieces of context to answer the question at the end.\n        If you don't know the answer, just say that you don't know, don't try to make up an answer.\n        do not hallucinate\n\n        follow the below instructions strictly:\n        you will be given documents based on financial analysis and reports, based on the given input question you will generate a detailed report in 300 to 400 words\n\n        do not add a conclusion!!, just generate the report, if the content is too short, generate a report in as many words as possible, do not create your own information\n\n        you will also be given images of the context, which may include charts and tables. use these values to generate the report (remember facts and figures are very important for a financial report)\n\n        the generated report should be properly formatted\n\n        based on the charts and tables, you will also generate a chart for the most import figures in line with the summary generated,\n\n        using the instructions this is the text you generated earlier:\"\"\" + f\"\"\"{gen_content}\"\"\" + \"\"\"\n\n        return the content as a json of this format (follow this format strictly, the output has to be a json, do not include any character not supported in jsons)\"\"\"\n\n        if regenerate_charts == True:\n            prompt = prompt + \"\"\"\n            {\n                report: generated_report in text format (do not use * or # in the output),\n                charts: [\n                    {\n                        \"python_code\": python code. (save the chart with name as the title of the chart exactly as mentioned, do not add underscores or any other extra characters) the chart has to saved as \"\"\"+temp_image+\"\"\"/chart name.png (this path is fixed, do not change it, only the chart name should be added appropriately), make sure the parameters are right (do not miss out on things like bar width),\n                        \"directory\": directory of the chart\n                    }\n                ]\n            }\"\"\"\n        else:\n            prompt = prompt + \"\"\"\n            {\n                report: generated_report in text format (do not use * or # in the output),\n            }\"\"\"\n\n        prompt = prompt + \"\"\"\n\n        follow the instructions strictly (do not change formats, keep it consistent)\n\n        you will also include the source of the sentence you are using to generate the answer. (sources will be mentioned towards the end of sentences as citations, use only the filename as source, do not return the entire path )\"\"\" + f\"\"\"\n\n        you will have to modify the gpreviously generated text based on the new instructions given below (you will also be given some more context)\n        \n        Answer Generation Language : {language} language\n\n        Question: {question}\n\n        Helpful Answer:\"\"\"\n\n        return prompt\n\n    def format_docs(self, docs):\n        return \"\\n\\n\".join(doc.page_content+ \"source: \" + doc.metadata['source'] for doc in docs)\n\n    def get_question_prompts(self, selected_qs):\n        ## PROMPTS\n        pr1 = f\"\"\"Based on the provided documents, discuss the {current_year} economic outlook for developed and emerging markets, highlighting key variables such as economic growth, recession risks, inflation trends, and the impact of fiscal and monetary policies. Compare the economic conditions and outlook for the United States, Eurozone, and key emerging markets like China. Additionally, summarize the differing viewpoints of major investment houses regarding potential economic scenarios for {current_year}, particularly focusing on whether they anticipate a growth stagnation or a mild recession followed by recovery.\"\"\"\n\n        pr2 = f\"\"\"Based on the information provided in the following documents, generate a comprehensive summary of the monetary and fiscal policy outlook for {current_year}. Include details on the expected actions and impacts of central banks, particularly the Fed, ECB, and BoE, and provide insights on the fiscal policy landscape in the US and Eurozone. Additionally, discuss the potential challenges and scenarios that may affect these policies.\"\"\"\n\n        pr3 = f\"\"\"Using the provided excerpts from various investment outlook reports, generate a comprehensive analysis of the government bond and corporate debt markets for {current_year}. The analysis should include an overview of the expected performance of these asset classes, the factors influencing their outlook, and the preferences of different investment firms. Highlight any notable developments and regional differences, and provide insights into how potential central bank actions and economic conditions might impact these markets. Additionally, differentiate between high-quality and low-quality credit within the corporate debt market and discuss the implications for investors. Ensure to mention specific perspectives from firms such as Pictet, Fidelity, and Blackrock, particularly their views on inflation-linked bonds and the geographical allocation of investments.\"\"\"\n\n        pr4 = f\"\"\"Using the following context from various investment outlook reports, generate a comprehensive analysis on the corporate debt market. Highlight the potential impacts of interest rate cuts, the differences between issuers with higher credit ratings (Investment Grade) and those with lower ratings (High Yield), and the sustainability of debt levels given the current economic climate. Address the implications of rising default rates, the refinancing of maturing debt, and the market perception of risk versus return. Finally, compare the positioning and outlook for Investment Grade bonds versus High Yield bonds, especially in the European sector, considering potential central bank measures and economic slowdowns.\"\"\"\n\n        pr5 = f\"\"\"Based on the following excerpts from recent investment outlooks and market analyses, write a detailed summary discussing the current state and future outlook of global stock markets, emphasizing key themes such as the impact of central bank actions, sector-specific performance, and the role of technology and artificial intelligence. Also, highlight the differences in perspectives between major investment firms regarding equity and bond market dynamics, geographic diversification, and sector preferences. Be sure to include specific viewpoints from BlackRock, Goldman Sachs, Pimco, JP Morgan, Amundi, Fidelity, and other relevant firms.\"\"\"\n\n        pr6 = f\"\"\"Using the provided context, generate a comprehensive analysis on the investment outlook for emerging markets in {current_year}, highlighting key factors influencing investment decisions, regional economic performance, and geopolitical risks.\"\"\"\n\n        pr7 = f\"\"\"Based on the insights from the given documents, craft a detailed analysis discussing the anticipated impact of central bank policies on currency movements in {current_year}. Specifically, focus on the potential weakening of the US Dollar in relation to the Euro and currencies of emerging markets, highlighting key factors such as Federal Reserve and European Central Bank actions, economic growth rates, and valuation metrics. Incorporate relevant data and projections mentioned in the documents to support your analysis.\"\"\"\n\n        pr8 = f\"\"\"TOPIC HEADING: Sustainable Investments, Generate a comprehensive summary detailing the recent challenges and developments in sustainable investments and forecast the conditions and trends expected in {current_year}. The summary should cover the impacts of rising energy prices and high interest rates on sustainable investments, the legislative progress and regulatory measures supporting sustainability, the positive conditions anticipated for {current_year}, the key issues such as climate change mitigation and marine ecosystem protection, and the increasing influence of shareholders on corporate sustainability practices.\"\"\"\n\n        questions = [\n            [\"MACROECONOMIC SCENARIO\", pr1],\n            [\"FISCAL AND MONETARY POLICY\", pr2],\n            [\"GOVERNMENT BONDS AND BOND MARKET\", pr3],\n            [\"CREDIT\", pr4],\n            [\"STOCK MARKET\", pr5],\n            [\"EMERGING MARKETS\", pr6],\n            [\"FORREIGN EXCHANGE MARKET\", pr7],\n            [\"SUSTAINABLE INVESTMENTS\", pr8]\n        ]\n\n        questions = [question for question in questions if question[0] in selected_qs]\n\n        return questions\n\n    def generate_report(self, pdf_title, selected_qs):\n        questions = self.get_question_prompts(selected_qs)\n\n        for question in questions:\n            try:\n                docs1 = self.db.similarity_search(question[1], k = 7)\n                context = self.format_docs(docs1)\n                pg_nos = self.extract_page_numbers(docs1)\n\n                image_info_list = self.image_info_list\n                search_list = pg_nos\n                result_paths = self.search_images(search_list)\n\n                prompt = self.create_base_prompt(context, question[1])\n\n                generator = DocumentInsightGenerator(prompt)\n\n                for i in result_paths:\n                    generator.add_image(i)\n\n                insights = generator.generate_insights()\n\n\n                # parse insights\n                ins = insights[insights.find(\"{\"): len(insights)-insights[::-1].find(\"}\")]\n\n                try:\n                    in1 = json.loads(ins)\n                    rep = in1[\"report\"]\n                    # ch = in1[\"charts\"]\n                except:\n                    rep = ins[ins.find(\"report\"):ins.find(\"charts\")]\n\n                    rep = rep[10:-3]\n\n                ch = \"{\" + ins[ins.find(\"charts\") -1:]\n\n                # Generate and add charts\n                try:\n                    charts = json.loads(ch)\n                    chr = []\n                    for chart in charts[\"charts\"]:\n                        exec(chart[\"python_code\"])\n                        image_path = chart[\"directory\"]\n                        chr.append(image_path)\n                except Exception as e:\n                    print(f\"Error generating charts: {e}\")\n\n                self.report.append([question[0], rep, chr])\n\n            except Exception as e:\n                print(f\"Error generating report for question '{question}': {e}\")\n\n            print(\"Page complete: \" + question[0])\n\n        print(\"generated successfully!!\")\n\n        self.save_report(self.report)\n\n        return self.report\n\n    def modify_report(self, report, topic, question, language, regenerate_charts = False):\n        ## report ds --> [heading, report for heading, [list of chart locations]]\n\n        for item in report:\n            if item[0] == topic:\n                temp_rep = item\n                break\n\n        prompt = self.get_modify_prompt(regenerate_charts, temp_rep[0]+temp_rep[1], question, language)\n\n        generator = DocumentInsightGenerator(prompt)\n        insights = generator.generate_insights()\n\n        ins = insights[insights.find(\"{\"): len(insights)-insights[::-1].find(\"}\")]\n\n        try:\n            in1 = json.loads(ins)\n            rep = in1[\"report\"]\n            # ch = in1[\"charts\"]\n        except:\n            rep = ins[ins.find(\"report\"):ins.find(\"charts\")]\n\n            rep = rep[10:-3]\n\n        if regenerate_charts == True:\n            ch = \"{\" + ins[ins.find(\"charts\") -1:]\n            # Generate and add charts\n            try:\n                charts = json.loads(ch)\n                chr = []\n                for chart in charts[\"charts\"]:\n                    exec(chart[\"python_code\"])\n                    image_path = chart[\"directory\"]\n                    chr.append(image_path)\n            except Exception as e:\n                print(f\"Error generating charts: {e}\")\n\n        else:\n            chr = []\n\n        report = [topic, rep, chr]\n\n        #self.report = report\n\n        #self.save_report(report)\n\n        return report\n\n    def replace_topic(self, old_list, new_item, replace_list=True):\n        new_item_first_text = new_item[0]\n\n        for i, item in enumerate(old_list):\n            if item[0] == new_item_first_text:\n                if replace_list:\n                    old_list[i] = new_item\n                else:\n                    old_list[i][0] = new_item[0]\n                    old_list[i][1] = new_item[1]\n                return old_list\n\n        old_list.append(new_item)\n        return old_list\n\n    def remove_topic(self, old_list, topic):\n        new_list = []\n        for item in old_list:\n            if item[0] != topic:\n                new_list.append(item)\n        return new_list\n\n    def generate_pdf(self, pdf_title, selected_qs):\n        questions = self.get_question_prompts(selected_qs)\n\n        pdf = PDF()\n        pdf.add_page()\n\n        # Set title on the first page\n        pdf.set_font(\"Arial\", 'B', 24)\n        encoded_text = pdf_title.encode('latin-1', errors='replace').decode('latin-1')\n        pdf.cell(0, 30, txt=encoded_text, ln=True, align=\"C\")\n        pdf.ln(20)\n\n        pdf.set_font(\"Arial\", size=12)\n\n        for question in questions:\n            try:\n                docs1 = self.db.similarity_search(question[1], k = 7)\n                context = self.format_docs(docs1)\n                pg_nos = self.extract_page_numbers(docs1)\n\n                image_info_list = self.image_info_list\n                search_list = pg_nos\n                result_paths = self.search_images(search_list)\n\n                prompt = self.create_base_prompt(context, question[1])\n\n                generator = DocumentInsightGenerator(prompt)\n\n                for i in result_paths:\n                    generator.add_image(i)\n\n                insights = generator.generate_insights()\n\n                # parse insights\n                ins = insights[insights.find(\"{\"): len(insights)-insights[::-1].find(\"}\")]\n\n                try:\n                    in1 = json.loads(ins)\n                    rep = in1[\"report\"]\n                    # ch = in1[\"charts\"]\n                except:\n                    rep = ins[ins.find(\"report\"):ins.find(\"charts\")]\n\n                    rep = rep[10:-3]\n\n                ch = \"{\" + ins[ins.find(\"charts\") -1:]\n\n                # Render report content as markdown and then convert to plain text\n                # markdown_content = markdown(rep)\n                pdf.add_page()\n                pdf.set_font(\"Arial\", 'B', 14)\n                pdf.multi_cell(0, 10, question[0].encode('latin-1', 'replace').decode('latin-1'), align=\"L\")\n\n                pdf.set_font(\"Arial\", size=10)\n                pdf.ln(10)\n                pdf.multi_cell(0, 10, rep.encode('latin-1', 'replace').decode('latin-1'))\n\n                # Generate and add charts\n                try:\n                    charts = json.loads(ch)\n                    for chart in charts[\"charts\"]:\n                        exec(chart[\"python_code\"])\n                        image_path = chart[\"directory\"]\n                        pdf.ln(10)\n                        pdf.image(image_path, x=10, w=190)\n                except Exception as e:\n                    print(f\"Error generating charts: {e}\")\n\n            except Exception as e:\n                print(f\"Error generating report for question '{question}': {e}\")\n\n            print(\"Page complete: \" + question[0])\n\n        output_path = output_latest_dir_path + \"/\" + pdf_title + \".pdf\"\n        pdf.output(output_path)\n\n        return \"generated successfully!!\"\n\n    def generate_pdf_from_report(self, report, pdf_title, file_name):\n        pdf = PDF()\n        pdf.add_page()\n        pdf.set_font(\"Arial\", 'B', 24)\n        encoded_text = pdf_title.encode('latin-1', errors='replace').decode('latin-1')\n        pdf.cell(0, 30, txt=encoded_text, ln=True, align=\"C\")\n        pdf.ln(20)\n        pdf.set_font(\"Arial\", size=12)\n        for item in report:\n            pdf.add_page()\n            pdf.set_font(\"Arial\", 'B', 14)\n            pdf.multi_cell(0, 6, item[0].encode('latin-1', 'replace').decode('latin-1'), align=\"L\")\n            pdf.set_font(\"Arial\", size=10)\n            pdf.ln(10)\n            pdf.multi_cell(0, 6, item[1].encode('latin-1', 'replace').decode('latin-1'), align=\"L\")\n            for chart in item[2]:\n                pdf.ln(10)\n                pdf.image(chart, x=10, w=190)\n        output_path = output_latest_dir_path + \"/\" + file_name + \".pdf\"\n        pdf.output(output_path)\n        \"\"\"\n        pdf = PDF()\n        pdf.add_page()\n\n        # Title\n        pdf.set_font(\"Arial\", 'B', 24)\n        encoded_title = pdf_title.encode('latin-1', errors='replace').decode('latin-1')\n        pdf.cell(0, 30, txt=encoded_title, ln=True, align=\"C\")  # Center the title\n        pdf.ln(20)  # Add line spacing after the title\n\n        # Content\n        pdf.set_font(\"Arial\", size=12)\n        for item in report:\n            pdf.add_page()\n\n            # Heading\n            pdf.set_font(\"Arial\", 'B', 14)\n            encoded_heading = item[0].encode('latin-1', 'replace').decode('latin-1')\n            pdf.multi_cell(0, 6, encoded_heading, align=\"L\")  # Left-align the heading\n            pdf.ln(10)  # Add line spacing after the heading\n\n            # Body text\n            pdf.set_font(\"Arial\", size=10)\n            encoded_body = item[1].encode('latin-1', 'replace').decode('latin-1')\n            pdf.multi_cell(0, 6, encoded_body, align=\"L\")  # Left-align the body text\n\n            # Charts\n            for chart in item[2]:\n                pdf.ln(10)  # Add line spacing before the chart\n                pdf.image(chart, x=10, w=190)\n\n        output_path = output_latest_dir_path + \"/\" + file_name + \".pdf\"\n        pdf.output(output_path)\"\"\"\n\n        return \"generated successfully!!\"\n\n    def save_report(self, report):\n        with open(f'{database_directory}/report_ds.pkl', 'wb') as file:\n            pickle.dump(report, file)\n            print(\"report saved\")\n\n    def load_report(self):\n        with open(f'{database_directory}/report_ds.pkl', 'rb') as file:\n            report = pickle.load(file)\n            self.report = report\n            print(\"report loaded\")\n            return report\n\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n  questions = [\n    \"MACROECONOMIC SCENARIO\",\n    # \"FISCAL AND MONETARY POLICY\",\n    # \"GOVERNMENT BONDS AND BOND MARKET\",\n    # \"CREDIT\",\n    # \"STOCK MARKET\",\n    # \"EMERGING MARKETS\",\n    # \"FORREIGN EXCHANGE MARKET\",\n    # \"SUSTAINABLE INVESTMENTS\"\n    ]\n  k2 = MultimodalReportGenerator()\n  if os.path.exists(database_directory + '/report_ds.pkl'):\n      rep = k2.load_report()\n      print(\"report loaded from disk\")\n  else:\n      print(\"report not in path\")\n      try:\n          k2.load_db()\n      except:\n          k2.preprocess(data_path)\n      print(\"generating a new report\")\n      rep = k2.generate_report(f\"OUTLOOK {current_year}\", questions) # optional\n\n# modify\n  option = \"\"\"${radioOption}\"\"\"\n  new_prompt = \"\"\"${enhanceReport}\"\"\"\n  language = \"\"\"${language}\"\"\"\n  option = option.replace(\"'\",\"\")\n  print(\"-----------------------------------------------\")\n  print(option)\n  print(new_prompt)\n  new_qs_content = f\"\"\"\n  based on the context generate a new report\n\n  {new_prompt}\n  \"\"\"\n\n  rep1 = k2.modify_report(rep, option, new_qs_content,language, regenerate_charts = True) ## report_ds, topic, user_customisation, regen charts?\n\n  # either return text and chart back or generate new pdf out of it\n\n  new_rep = k2.replace_topic(rep, rep1)\n  \n  now_utc = datetime.utcnow()\n  datetime_str = now_utc.strftime(\"%Y-%m-%d_%H%M_UTC\")\n  \n  filename = f\"OUTLOOK_{current_year}_Modified_{datetime_str}\"\n\n  k2.generate_pdf_from_report(rep, f\"OUTLOOK {current_year}\", filename)\n  k2.save_report(rep)\n  raw_data = f\"OUTLOOK {current_year}\\n\"\n  for i in rep:\n    raw_data += \"\\n\".join(i[:2] if len(i)>2 else i)\n  with open(output_latest_dir_path + \"/\" + f\"OUTLOOK_MODIFIED_RAW_{datetime_str}.txt\", \"w\") as f:\n    f.write(raw_data)\n\n  return",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "2",
      "name": "Sticky Note",
      "iconImage": "fa fa-file-text",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "334.111px",
      "y": "131.111px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "bgColor",
          "value": "gray",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "width",
          "value": "300px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "height",
          "value": "110px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "comment",
          "value": "<p>Report is enhanced with selected options.</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [],
  "dataSetDetails": [],
  "engine": "pyspark"
}