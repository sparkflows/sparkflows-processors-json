{
  "name": "03-OSA-Out-Of-Stock-Phantom-Inv-And-SafetyStock-Data-Prepration",
  "uuid": "da9a3184-aaf3-458f-9e93-52274bedaf1e",
  "category": "FeatureEngineering",
  "parameters": " --var selectProduct='AutoCAD','Maya','3ds Max','Revit','Fusion 360' --var select=safetyStock --var exploreData=true",
  "nodes": [
    {
      "id": "1",
      "name": "Read CSV",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>Refresh Schema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the refresh schema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "15px",
      "y": "237px",
      "hint": "Refresh the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/CPG/CPG-On-Shelf-Availability/Prepared-Data",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"replenishment_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"on_hand_inventory_units\",\"promotion_flag\",\"replenishment_flag\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptions",
          "value": "",
          "widget": "tab",
          "title": "Extra Options",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Extra Options Keys",
          "description": "Extra options available when reading CSV files. Examples :\n comment --> # (ignore comment lines in the file)\nignoreLeadingWhiteSpace --> false (Ignores leading white spaces in string columns)\nignoreTrailingWhiteSpace --> false (Ignores trailing white spaces in string columns).\nfilterPushdown --> true (Enables filter pushdown to optimize query performance.)\nsamplingRatio --> 1.0 (Specifies the ratio of rows to sample when inferring schema.)\nignoreCorruptFiles --> false (Skips files with corrupt data instead of failing.)\nignoreMissingFiles --> false (Skips missing files instead of failing.)\npathGlobFilter --> *.csv (Filters file paths based on a specified glob pattern.)\nrecursiveFileLookup --> false (Enables recursive file lookup in directories.)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Extra Options Values",
          "description": "Config Values for the Corresponding keys",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "4",
      "name": "Read CSV",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>Refresh Schema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the refresh schema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "30px",
      "y": "478.172px",
      "hint": "Refresh the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/CPG/CPG-On-Shelf-Availability/Raw-Data/vendor_leadtime_info.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"key\",\"vendor_id\",\"sub_vendor_id\",\"store_id\",\"item_id\",\"LEAD_TIME_IN_DC\",\"LEAD_TIME_IN_TRANSIT\",\"LEAD_TIME_ON_ORDER\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptions",
          "value": "",
          "widget": "tab",
          "title": "Extra Options",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Extra Options Keys",
          "description": "Extra options available when reading CSV files. Examples :\n comment --> # (ignore comment lines in the file)\nignoreLeadingWhiteSpace --> false (Ignores leading white spaces in string columns)\nignoreTrailingWhiteSpace --> false (Ignores trailing white spaces in string columns).\nfilterPushdown --> true (Enables filter pushdown to optimize query performance.)\nsamplingRatio --> 1.0 (Specifies the ratio of rows to sample when inferring schema.)\nignoreCorruptFiles --> false (Skips files with corrupt data instead of failing.)\nignoreMissingFiles --> false (Skips missing files instead of failing.)\npathGlobFilter --> *.csv (Filters file paths based on a specified glob pattern.)\nrecursiveFileLookup --> false (Enables recursive file lookup in directories.)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Extra Options Values",
          "description": "Config Values for the Corresponding keys",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "5",
      "name": "Columns Rename",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "422.35px",
      "y": "490.375px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentColNames",
          "value": "[\"item_id\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "newColNames",
          "value": "[\"sku\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "6",
      "name": "SQL",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "details": "<h2>SQL Details</h2>\n<br>\nSQL node receives an input data frame. It creates a temporary table on top of that data frame. It executes the provided SQL in the node on the temporary table.<br>\n<br>\nThe resulting data frame of running the SQL is passed on to the next node.<br>",
      "examples": "<h2>SQL Examples</h2>\n<br>\nBelow are some examples of SQL. <br>\n<br>\nTemporary table name used : tempTable<br>\n<br>\nThe schema of the Input Dataframe is : id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> find the average price of houses</h4>\n<br>\nselect avg(price) as avg_price from tempTable<br>\n<br>\n<br>\n<h4> find bedrooms with avg price greater than 10000</h4>\n<br>\nselect bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000<br>\n<br>\n<br>\n<h4> details of houses with bedrooms avg price greater than 10000</h4>\n<br>\nselect tempTable.* , inner_table.avg_price from<br>\n(select bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000) as inner_table<br>\nJOIN tempTable ON(inner_table.bedrooms = tempTable.bedrooms)<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "156px",
      "y": "237px",
      "hint": "Whenever the table is changed, go to Schema tab and Refresh the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "sql",
          "value": "SELECT *, \nAVG(total_sales_units) OVER(PARTITION BY store_id, sku ORDER BY date) AS daily_sales_units\nFROM fire_temp_table",
          "widget": "textarea_large",
          "type": "sql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"replenishment_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"on_hand_inventory_units\",\"promotion_flag\",\"replenishment_flag\",\"daily_sales_units\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "8",
      "name": "Window Analytics",
      "description": "",
      "details": "This node Generates a new Dataframe with Analytics Column appended to the incoming Dataframe.<br>\n<br>\nAnalytics Column is populated with value based on the Window Function selected.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT    |    SALARY    |    AGE    <br>\n------------------------------------------------------------------------<br>\nE01       |    ANTHONY     |    HR      |    50000     |    40<br>\nE02       |    LISA        |    HR      |    45000     |    35<br>\nE03       |    MARTIN      |    HR      |    20000     |    25<br>\nE04       |    DAVID       |    SALES   |    55000     |    40<br>\nE05       |    MARK        |    SALES   |    60000     |    45<br>\nE06       |    JOE         |    SALES   |    40000     |    25<br>\nE07       |    BELLA       |    HR      |    60000     |    24<br>\n<br>\n<h2> If WindowAnalytics node is configured as below:</h2>\n<br>\nPARTITIONBY      :     DEPT<br>\nORDERBY          :     AGE<br>\nWINDOW FUNCTION  :     first_value<br>\nANALYTICS COLUMN :     SALARY : integer<br>\nWINDOW OFFSET    :     1<br>\n<br>\nthen outgoing Dataframe would be created as below <br>\nwhere incoming Dataframe is partitioned by [DEPT] and data is sorted by [AGE] and [FIRST VALUE] of Analytics Column [SALARY] within a partition is appended as new column:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT    |    SALARY    |    AGE    |    first_value<br>\n---------------------------------------------------------------------------------------<br>\nE07       |    BELLA       |    HR      |    60000     |    24     |    60000<br>\nE03       |    MARTIN      |    HR      |    20000     |    25     |    60000<br>\nE02       |    LISA        |    HR      |    45000     |    35     |    60000<br>\nE01       |    ANTHONY     |    HR      |    50000     |    40     |    60000<br>\nE06       |    JOE         |    SALES   |    40000     |    25     |    40000<br>\nE04       |    DAVID       |    SALES   |    55000     |    40     |    40000<br>\nE05       |    MARK        |    SALES   |    60000     |    45     |    40000<br>\n<br>\n<h2> If WindowAnalytics node is configured as below:</h2>\n<br>\nPARTITIONBY      :     DEPT<br>\nORDERBY          :     AGE<br>\nWINDOW FUNCTION  :     lead<br>\nANALYTICS COLUMN :     SALARY : integer<br>\nWINDOW OFFSET    :     2<br>\n<br>\nthen outgoing Dataframe would be created as below <br>\nwhere incoming Dataframe is partitioned by [DEPT] and data is sorted by [AGE] and <br>\nAnalytics Column [SALARY] value of leading 2 or [WINDOW OFFSET] rows within a partition is appended as new column:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT    |    SALARY    |    AGE    |    first_value<br>\n---------------------------------------------------------------------------------------<br>\nE07       |    BELLA       |    HR      |    60000     |    24     |    45000<br>\nE03       |    MARTIN      |    HR      |    20000     |    25     |    50000<br>\nE02       |    LISA        |    HR      |    45000     |    35     |    <br>\nE01       |    ANTHONY     |    HR      |    50000     |    40     |    <br>\nE06       |    JOE         |    SALES   |    40000     |    25     |    60000<br>\nE04       |    DAVID       |    SALES   |    55000     |    40     |    <br>\nE05       |    MARK        |    SALES   |    60000     |    45     |<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeWindowAnalytics",
      "x": "268px",
      "y": "236px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "partitionByCols",
          "value": "store_id, sku",
          "widget": "textfield",
          "title": "PartitionBy",
          "description": "partition column names separated by comma(,) ",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "orderByCols",
          "value": "date",
          "widget": "textfield",
          "title": "OrderBy",
          "description": "order by column names separated by comma(,)",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "windowFunction",
          "value": "lag",
          "widget": "array",
          "title": "Window Function",
          "description": "Window Function Name",
          "optionsArray": [
            "first_value",
            "last_value",
            "lag",
            "lead"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "analyticsCol",
          "value": "on_hand_inventory_units",
          "widget": "variable",
          "title": "Analytics Column",
          "description": "",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "window_offset",
          "value": "1",
          "widget": "textfield",
          "title": "Window Offset",
          "description": "It's used in lead and lag functions.",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "10",
      "name": "SQL",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "details": "<h2>SQL Details</h2>\n<br>\nSQL node receives an input data frame. It creates a temporary table on top of that data frame. It executes the provided SQL in the node on the temporary table.<br>\n<br>\nThe resulting data frame of running the SQL is passed on to the next node.<br>",
      "examples": "<h2>SQL Examples</h2>\n<br>\nBelow are some examples of SQL. <br>\n<br>\nTemporary table name used : tempTable<br>\n<br>\nThe schema of the Input Dataframe is : id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> find the average price of houses</h4>\n<br>\nselect avg(price) as avg_price from tempTable<br>\n<br>\n<br>\n<h4> find bedrooms with avg price greater than 10000</h4>\n<br>\nselect bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000<br>\n<br>\n<br>\n<h4> details of houses with bedrooms avg price greater than 10000</h4>\n<br>\nselect tempTable.* , inner_table.avg_price from<br>\n(select bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000) as inner_table<br>\nJOIN tempTable ON(inner_table.bedrooms = tempTable.bedrooms)<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "380.984px",
      "y": "234px",
      "hint": "Whenever the table is changed, go to Schema tab and Refresh the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "sql",
          "value": "SELECT date, store_id, sku, product_category, total_sales_units, replenishment_units, inventory_pipeline, units_in_transit, units_in_dc, \nunits_on_order, units_under_promotion, shelf_capacity, on_hand_inventory_units, promotion_flag, replenishment_flag, daily_sales_units, \nCOALESCE(lag, nvl(on_hand_inventory_units,0) + nvl(total_sales_units,0) - nvl(replenishment_units,0)) AS start_on_hand_units\nFROM fire_temp_table",
          "widget": "textarea_large",
          "type": "sql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"replenishment_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"on_hand_inventory_units\",\"promotion_flag\",\"replenishment_flag\",\"daily_sales_units\",\"start_on_hand_units\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "13",
      "name": "Expressions",
      "description": "This node creates a new DataFrame by adding new columns to the incoming Dataframe as per the Expression computation",
      "details": "<h2>Expressions Node Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the expressions computated.<br>\n<br>\nIt computes expressions to calculate the value of a metric column based on mathematical or logical operations performed on other metric columns.<br>\n<br>\nNew column can also be computed using existing columns in the Dataframe.<br>\n<br>\n<h3>Following functions can be used in Expressions:</h3>\n<br>\n<h3> Mathematical Computations</h3>\n<br>\n<ul>\n<li>\tMaths Operations -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n<li>\tMaths Operations -> Example : DISCOUNT / LIST_PRICE</li>\n<li>\tMaths Operations -> Example : (DISCOUNT / LIST_PRICE) * 100</li>\n</ul>\n<h3>String Functions</h3>\n<br>\n<ul>\n<li>\tConcatenation     -> Example : CONCAT(PRD_CD,':',PRD_NAME)</li>\n<li>\tSubstring     -> Example : SUBSTR(PRD_NAME,1,3)</li>\n<li>\tReplace\t\t \t-> Example : REPLACE(PRD_NAME,'M','$')</li>\n<li>\tRight\t\t \t-> Example : RIGHT(PRD_NAME, 5)</li>\n<li>\tLeft\t\t \t-> Example : LEFT(PRD_NAME, 5)</li>\n<li>\tRight Trim\t \t-> Example : RTRIM(PRD_NAME)</li>\n<li>\tIntial Caps\t \t-> Example : INITCAP(LOWER(PRD_NAME))</li>\n<li>\tLength\t\t \t-> Example : LENGTH(PRD_NAME)</li>\n<li>\tSplit\t\t \t-> Example : SPLIT(PRD_NAME, ' ')</li>\n</ul>\n<h3>Number Format Functions</h3>\n<br>\n<ul>\n<li>\tFormat Number\t-> Example : FORMAT_NUMBER(LIST_PRICE, '#,###,###,###.00')</li>\n</ul>\n<h3>Date and Timestamp Functions</h3>\n<br>\n<h4>Fetch Current Date and Time</h4>\n<br>\n<ul>\n<li>\tCurrent Date value\t\t\t\t          -> Example : CURRENT_DATE</li>\n<li>\tCurrent Date Time value\t\t\t\t      -> Example : CURRENT_TIMESTAMP</li>\n</ul>\n<h4>Format Date-Time values</h4>\n<ul>\n<li>\tDate Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy')</li>\n<li>\tDate-Time Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy hh:mm:ss')</li>\n</ul>\n<h4>String to Date-Time conversion</h4>\n<ul>\n<li>\tConvert a String to Date\t      \t\t-> Example : TO_DATE('12-DEC-21', 'dd-MMM-yy')</li>\n<li>\tConvert a String to Datetime\t\t\t\t\t\t            \t-> TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS')</li>\n</ul>\n<h4>Date-Time addition and substraction</h4>\n<ul>\n<li>\tAdd/Substract Years to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 12)</li>\n<li>\tAdd/Substract Months to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 3)</li>\n<li>\tAdd/Substract Days to a Date\t\t    -> Example : DATE_ADD(CURRENT_DATE, -1)</li>\n<li>\tAdd/Substract Hours to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours</li>\n<li>\tAdd/Substract Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Minutes</li>\n<li>\tAdd/Substract Seconds to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Seconds</li>\n<li>\tAdd/Substract Hours and Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours + Interval 2 Minutes</li>\n<li>\tSubstract Hours and Minutes from a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') - Interval 2 Hours - Interval 2 Minutes</li>\n</ul>\n<h4>Fetch Next Day and Last Day of Month</h4>\n<ul>\n<li>\tLast Day of a Month   \t\t\t\t      -> Example : LAST_DAY(CURRENT_DATE)</li>\n<li>\tNext Day value\t\t   \t\t\t\t        -> Example : NEXT_DAY(CURRENT_DATE, 'Sunday')</li>\n<li>\tFirst Day of Year/Month\t\t\t\t      -> Example : DATE_TRUNC('MONTH', CURRENT_DATE)</li>\n<li>\tYear/Month/Quarter/DayOfMonth value\t-> Example : YEAR(CURRENT_DATE)/MONTH(CURRENT_DATE)/QUARTER(CURRENT_DATE)/DAYOFMONTH(CURRENT_DATE)/DAYOFWEEK(CURRENT_DATE)</li>\n<li>\tDay/Week count of the Year\t\t\t    -> Example : DAYOFWEEK(CURRENT_DATE)/WEEKOFYEAR(CURRENT_DATE)</li>\n</ul>\n<h4>Date Difference functions</h4>\n<ul>\n<li>\tDate Diff between two Dates\t\t\t    -> Example : DATEDIFF(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Months between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Years between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy')) / 12</li>\n</ul>\n<h3>Regex Functions</h3>\n<br>\n<ul>\n<li>\tReplace using Regex\t\t-> Example : REGEXP_REPLACE(PRD_NAME, 'E', '#')</li>\n</ul>",
      "examples": "<h2>Expressions Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\n<h4>Expressions Node Configuration</h4>\n<br>\nExpressions node is configured to compute new columns as below:<br>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nNET_AMT                  |    LIST_PRICE + TAX_AMT - DISCOUNT<br>\nPRD_DETAILS              |    CONCAT(PRD_CD,':',PRD_NAME)<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutgoing Dataframe would be created as below with new columns added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    |    PRD_DETAILS<br>\n--------------------------------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0     |    P01:DRILL MACHINE<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0     |    P02:WEIGHING MACHINE<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0      |    P03:HAMMER<br>\n<br>\n<h4>Computing Current Date value using Expression:</h4>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nCURRENT_DATE_VAL         |    CURRENT_DATE<br>\nCURRENT_DATETIME_VAL     |    CURRENT_TIMESTAMP<br>\n<br>\nOutput would contain below value<br>\n<br>\nCURRENT_DATE_VAL         |    CURRENT_DATETIME_VAL<br>\n-----------------------------------------------------------------<br>\n2022-09-07               |    2022-09-07 10:05:12.432<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExpressions",
      "x": "508.369px",
      "y": "127.381px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textfield",
          "title": "Description",
          "description": "Description to capture processing in this node",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"end_on_hand_units\"]",
          "widget": "key_array",
          "title": "New Column Names",
          "description": "New Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "expressions",
          "value": "[\"nvl(\\ton_hand_inventory_units,0)\"]",
          "widget": "value_array",
          "title": "Expressions",
          "description": "Expressions to create new columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "14",
      "name": "Expressions",
      "description": "This node creates a new DataFrame by adding new columns to the incoming Dataframe as per the Expression computation",
      "details": "<h2>Expressions Node Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the expressions computated.<br>\n<br>\nIt computes expressions to calculate the value of a metric column based on mathematical or logical operations performed on other metric columns.<br>\n<br>\nNew column can also be computed using existing columns in the Dataframe.<br>\n<br>\n<h3>Following functions can be used in Expressions:</h3>\n<br>\n<h3> Mathematical Computations</h3>\n<br>\n<ul>\n<li>\tMaths Operations -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n<li>\tMaths Operations -> Example : DISCOUNT / LIST_PRICE</li>\n<li>\tMaths Operations -> Example : (DISCOUNT / LIST_PRICE) * 100</li>\n</ul>\n<h3>String Functions</h3>\n<br>\n<ul>\n<li>\tConcatenation     -> Example : CONCAT(PRD_CD,':',PRD_NAME)</li>\n<li>\tSubstring     -> Example : SUBSTR(PRD_NAME,1,3)</li>\n<li>\tReplace\t\t \t-> Example : REPLACE(PRD_NAME,'M','$')</li>\n<li>\tRight\t\t \t-> Example : RIGHT(PRD_NAME, 5)</li>\n<li>\tLeft\t\t \t-> Example : LEFT(PRD_NAME, 5)</li>\n<li>\tRight Trim\t \t-> Example : RTRIM(PRD_NAME)</li>\n<li>\tIntial Caps\t \t-> Example : INITCAP(LOWER(PRD_NAME))</li>\n<li>\tLength\t\t \t-> Example : LENGTH(PRD_NAME)</li>\n<li>\tSplit\t\t \t-> Example : SPLIT(PRD_NAME, ' ')</li>\n</ul>\n<h3>Number Format Functions</h3>\n<br>\n<ul>\n<li>\tFormat Number\t-> Example : FORMAT_NUMBER(LIST_PRICE, '#,###,###,###.00')</li>\n</ul>\n<h3>Date and Timestamp Functions</h3>\n<br>\n<h4>Fetch Current Date and Time</h4>\n<br>\n<ul>\n<li>\tCurrent Date value\t\t\t\t          -> Example : CURRENT_DATE</li>\n<li>\tCurrent Date Time value\t\t\t\t      -> Example : CURRENT_TIMESTAMP</li>\n</ul>\n<h4>Format Date-Time values</h4>\n<ul>\n<li>\tDate Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy')</li>\n<li>\tDate-Time Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy hh:mm:ss')</li>\n</ul>\n<h4>String to Date-Time conversion</h4>\n<ul>\n<li>\tConvert a String to Date\t      \t\t-> Example : TO_DATE('12-DEC-21', 'dd-MMM-yy')</li>\n<li>\tConvert a String to Datetime\t\t\t\t\t\t            \t-> TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS')</li>\n</ul>\n<h4>Date-Time addition and substraction</h4>\n<ul>\n<li>\tAdd/Substract Years to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 12)</li>\n<li>\tAdd/Substract Months to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 3)</li>\n<li>\tAdd/Substract Days to a Date\t\t    -> Example : DATE_ADD(CURRENT_DATE, -1)</li>\n<li>\tAdd/Substract Hours to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours</li>\n<li>\tAdd/Substract Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Minutes</li>\n<li>\tAdd/Substract Seconds to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Seconds</li>\n<li>\tAdd/Substract Hours and Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours + Interval 2 Minutes</li>\n<li>\tSubstract Hours and Minutes from a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') - Interval 2 Hours - Interval 2 Minutes</li>\n</ul>\n<h4>Fetch Next Day and Last Day of Month</h4>\n<ul>\n<li>\tLast Day of a Month   \t\t\t\t      -> Example : LAST_DAY(CURRENT_DATE)</li>\n<li>\tNext Day value\t\t   \t\t\t\t        -> Example : NEXT_DAY(CURRENT_DATE, 'Sunday')</li>\n<li>\tFirst Day of Year/Month\t\t\t\t      -> Example : DATE_TRUNC('MONTH', CURRENT_DATE)</li>\n<li>\tYear/Month/Quarter/DayOfMonth value\t-> Example : YEAR(CURRENT_DATE)/MONTH(CURRENT_DATE)/QUARTER(CURRENT_DATE)/DAYOFMONTH(CURRENT_DATE)/DAYOFWEEK(CURRENT_DATE)</li>\n<li>\tDay/Week count of the Year\t\t\t    -> Example : DAYOFWEEK(CURRENT_DATE)/WEEKOFYEAR(CURRENT_DATE)</li>\n</ul>\n<h4>Date Difference functions</h4>\n<ul>\n<li>\tDate Diff between two Dates\t\t\t    -> Example : DATEDIFF(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Months between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Years between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy')) / 12</li>\n</ul>\n<h3>Regex Functions</h3>\n<br>\n<ul>\n<li>\tReplace using Regex\t\t-> Example : REGEXP_REPLACE(PRD_NAME, 'E', '#')</li>\n</ul>",
      "examples": "<h2>Expressions Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\n<h4>Expressions Node Configuration</h4>\n<br>\nExpressions node is configured to compute new columns as below:<br>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nNET_AMT                  |    LIST_PRICE + TAX_AMT - DISCOUNT<br>\nPRD_DETAILS              |    CONCAT(PRD_CD,':',PRD_NAME)<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutgoing Dataframe would be created as below with new columns added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    |    PRD_DETAILS<br>\n--------------------------------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0     |    P01:DRILL MACHINE<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0     |    P02:WEIGHING MACHINE<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0      |    P03:HAMMER<br>\n<br>\n<h4>Computing Current Date value using Expression:</h4>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nCURRENT_DATE_VAL         |    CURRENT_DATE<br>\nCURRENT_DATETIME_VAL     |    CURRENT_TIMESTAMP<br>\n<br>\nOutput would contain below value<br>\n<br>\nCURRENT_DATE_VAL         |    CURRENT_DATETIME_VAL<br>\n-----------------------------------------------------------------<br>\n2022-09-07               |    2022-09-07 10:05:12.432<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExpressions",
      "x": "626.175px",
      "y": "124.194px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textfield",
          "title": "Description",
          "description": "Description to capture processing in this node",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"phantom_inventory\"]",
          "widget": "key_array",
          "title": "New Column Names",
          "description": "New Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "expressions",
          "value": "[\"start_on_hand_units + replenishment_units - total_sales_units - end_on_hand_units\"]",
          "widget": "value_array",
          "title": "Expressions",
          "description": "Expressions to create new columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "15",
      "name": "Case When",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "747.175px",
      "y": "126.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "phantom_inventory_ind",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"phantom_inventory <> 0 AND ABS(phantom_inventory) > 5 * daily_sales_units\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"1\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "0",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "16",
      "name": "Expressions",
      "description": "This node creates a new DataFrame by adding new columns to the incoming Dataframe as per the Expression computation",
      "details": "<h2>Expressions Node Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the expressions computated.<br>\n<br>\nIt computes expressions to calculate the value of a metric column based on mathematical or logical operations performed on other metric columns.<br>\n<br>\nNew column can also be computed using existing columns in the Dataframe.<br>\n<br>\n<h3>Following functions can be used in Expressions:</h3>\n<br>\n<h3> Mathematical Computations</h3>\n<br>\n<ul>\n<li>\tMaths Operations -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n<li>\tMaths Operations -> Example : DISCOUNT / LIST_PRICE</li>\n<li>\tMaths Operations -> Example : (DISCOUNT / LIST_PRICE) * 100</li>\n</ul>\n<h3>String Functions</h3>\n<br>\n<ul>\n<li>\tConcatenation     -> Example : CONCAT(PRD_CD,':',PRD_NAME)</li>\n<li>\tSubstring     -> Example : SUBSTR(PRD_NAME,1,3)</li>\n<li>\tReplace\t\t \t-> Example : REPLACE(PRD_NAME,'M','$')</li>\n<li>\tRight\t\t \t-> Example : RIGHT(PRD_NAME, 5)</li>\n<li>\tLeft\t\t \t-> Example : LEFT(PRD_NAME, 5)</li>\n<li>\tRight Trim\t \t-> Example : RTRIM(PRD_NAME)</li>\n<li>\tIntial Caps\t \t-> Example : INITCAP(LOWER(PRD_NAME))</li>\n<li>\tLength\t\t \t-> Example : LENGTH(PRD_NAME)</li>\n<li>\tSplit\t\t \t-> Example : SPLIT(PRD_NAME, ' ')</li>\n</ul>\n<h3>Number Format Functions</h3>\n<br>\n<ul>\n<li>\tFormat Number\t-> Example : FORMAT_NUMBER(LIST_PRICE, '#,###,###,###.00')</li>\n</ul>\n<h3>Date and Timestamp Functions</h3>\n<br>\n<h4>Fetch Current Date and Time</h4>\n<br>\n<ul>\n<li>\tCurrent Date value\t\t\t\t          -> Example : CURRENT_DATE</li>\n<li>\tCurrent Date Time value\t\t\t\t      -> Example : CURRENT_TIMESTAMP</li>\n</ul>\n<h4>Format Date-Time values</h4>\n<ul>\n<li>\tDate Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy')</li>\n<li>\tDate-Time Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy hh:mm:ss')</li>\n</ul>\n<h4>String to Date-Time conversion</h4>\n<ul>\n<li>\tConvert a String to Date\t      \t\t-> Example : TO_DATE('12-DEC-21', 'dd-MMM-yy')</li>\n<li>\tConvert a String to Datetime\t\t\t\t\t\t            \t-> TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS')</li>\n</ul>\n<h4>Date-Time addition and substraction</h4>\n<ul>\n<li>\tAdd/Substract Years to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 12)</li>\n<li>\tAdd/Substract Months to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 3)</li>\n<li>\tAdd/Substract Days to a Date\t\t    -> Example : DATE_ADD(CURRENT_DATE, -1)</li>\n<li>\tAdd/Substract Hours to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours</li>\n<li>\tAdd/Substract Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Minutes</li>\n<li>\tAdd/Substract Seconds to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Seconds</li>\n<li>\tAdd/Substract Hours and Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours + Interval 2 Minutes</li>\n<li>\tSubstract Hours and Minutes from a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') - Interval 2 Hours - Interval 2 Minutes</li>\n</ul>\n<h4>Fetch Next Day and Last Day of Month</h4>\n<ul>\n<li>\tLast Day of a Month   \t\t\t\t      -> Example : LAST_DAY(CURRENT_DATE)</li>\n<li>\tNext Day value\t\t   \t\t\t\t        -> Example : NEXT_DAY(CURRENT_DATE, 'Sunday')</li>\n<li>\tFirst Day of Year/Month\t\t\t\t      -> Example : DATE_TRUNC('MONTH', CURRENT_DATE)</li>\n<li>\tYear/Month/Quarter/DayOfMonth value\t-> Example : YEAR(CURRENT_DATE)/MONTH(CURRENT_DATE)/QUARTER(CURRENT_DATE)/DAYOFMONTH(CURRENT_DATE)/DAYOFWEEK(CURRENT_DATE)</li>\n<li>\tDay/Week count of the Year\t\t\t    -> Example : DAYOFWEEK(CURRENT_DATE)/WEEKOFYEAR(CURRENT_DATE)</li>\n</ul>\n<h4>Date Difference functions</h4>\n<ul>\n<li>\tDate Diff between two Dates\t\t\t    -> Example : DATEDIFF(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Months between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Years between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy')) / 12</li>\n</ul>\n<h3>Regex Functions</h3>\n<br>\n<ul>\n<li>\tReplace using Regex\t\t-> Example : REGEXP_REPLACE(PRD_NAME, 'E', '#')</li>\n</ul>",
      "examples": "<h2>Expressions Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\n<h4>Expressions Node Configuration</h4>\n<br>\nExpressions node is configured to compute new columns as below:<br>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nNET_AMT                  |    LIST_PRICE + TAX_AMT - DISCOUNT<br>\nPRD_DETAILS              |    CONCAT(PRD_CD,':',PRD_NAME)<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutgoing Dataframe would be created as below with new columns added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    |    PRD_DETAILS<br>\n--------------------------------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0     |    P01:DRILL MACHINE<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0     |    P02:WEIGHING MACHINE<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0      |    P03:HAMMER<br>\n<br>\n<h4>Computing Current Date value using Expression:</h4>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nCURRENT_DATE_VAL         |    CURRENT_DATE<br>\nCURRENT_DATETIME_VAL     |    CURRENT_TIMESTAMP<br>\n<br>\nOutput would contain below value<br>\n<br>\nCURRENT_DATE_VAL         |    CURRENT_DATETIME_VAL<br>\n-----------------------------------------------------------------<br>\n2022-09-07               |    2022-09-07 10:05:12.432<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExpressions",
      "x": "872.194px",
      "y": "127.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textfield",
          "title": "Description",
          "description": "Description to capture processing in this node",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"phantom_inventory_new\"]",
          "widget": "key_array",
          "title": "New Column Names",
          "description": "New Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "expressions",
          "value": "[\"NVL(phantom_inventory,0)\"]",
          "widget": "value_array",
          "title": "Expressions",
          "description": "Expressions to create new columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "17",
      "name": "Case When",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "990.394px",
      "y": "125.375px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "on_hand_inventory_units_new",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"on_hand_inventory_units < 0\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"0\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "NVL(on_hand_inventory_units,0)",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "18",
      "name": "Case When",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "1105.39px",
      "y": "123.381px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "replenishment_units_new",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"replenishment_flag = 1\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"replenishment_units\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "0",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "19",
      "name": "Add  Columns",
      "description": "This node allows adding new columns with certain values",
      "details": "It creates a new DataFrame by adding new columns to the input Dataframe. <br>\n<br>\nNew columns can be created for Current Date value, Current Datetime value, a Constant String value or a Constant Integer value.<br>\n<br>\nNames for new columns along with values can be provided.<br>",
      "examples": "If option for adding new columns is selected as below with new column names specified in bracket<br>\n<br>\n<ul>\n<li> CURRENT DATE (Column Name CURRENT_DATE)</li>\n<li> CURRENT TIME (Column Name CURRENT_TIME)</li>\n<li> STRING Column with a value DrillMachine (Column Name MACHINE_NAME)</li>\n<li> INTEGER column with a value 100 (Column Name MACHINE_WEIGHT)</li>\n</ul>\nthen following columns would be added to the output Dataframe with mentioned values:<br>\n<br>\n<ul>\n<li> CURRENT_DATE : 2021-10-22 </li>\n<li> CURRENT_TIME : 2021-10-22 04:34:00.532</li>\n<li> MACHINE_NAME : DrillMachine</li>\n<li> MACHINE_WEIGHT : 100</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeAddColumns",
      "x": "1230.39px",
      "y": "121.381px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addCurrentDateCol",
          "value": "false",
          "widget": "array",
          "title": "Add Current Date Column",
          "description": "Whether to add the current date as a new column",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentDateColName",
          "value": "",
          "widget": "textfield",
          "title": "Current Date Column Name",
          "description": "Name of the new Current Date Column Created",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addCurrentTimeCol",
          "value": "false",
          "widget": "array",
          "title": "Add Current Time Column",
          "description": "Whether to add the current time as a new column",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentTimeColName",
          "value": "",
          "widget": "textfield",
          "title": "Current Time Column Name",
          "description": "Name of the new Current Time Column Created",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addConstantStringCol1",
          "value": "false",
          "widget": "array",
          "title": "Add Constant String Column",
          "description": "Whether to add a new columns with constant string value",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constantStringColName1",
          "value": "",
          "widget": "textfield",
          "title": "Constant String Column Name",
          "description": "Constant String Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constantStringColValue1",
          "value": "",
          "widget": "textfield",
          "title": "Constant String Column Value",
          "description": "Constant String Value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addConstantIntCol1",
          "value": "true",
          "widget": "array",
          "title": "Add Constant Integer Column",
          "description": "Whether to add a new columns with constant integer value",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constantIntColName1",
          "value": "estimated_on_hand_inventory",
          "widget": "textfield",
          "title": "Constant Integer Column Name",
          "description": "Constant Integer Column Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constantIntColValue1",
          "value": "0",
          "widget": "textfield",
          "title": "Constant Integer Column Value",
          "description": "Constant Integer Value",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addConstantDoubleCol1",
          "value": "false",
          "widget": "array",
          "title": "Add Constant Double Column",
          "description": "Whether to add a new columns with constant double value",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constantDoubleColName1",
          "value": "",
          "widget": "textfield",
          "title": "Constant Double Column Name",
          "description": "Constant Double Column Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constantDoubleColValue1",
          "value": "",
          "widget": "textfield",
          "title": "Constant Double Column Value",
          "description": "Constant Double Value",
          "datatypes": [
            "double"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "20",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "1358.39px",
      "y": "118.375px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"promotion_flag\",\"replenishment_flag\",\"daily_sales_units\",\"start_on_hand_units\",\"end_on_hand_units\",\"phantom_inventory_ind\",\"phantom_inventory_new\",\"on_hand_inventory_units_new\",\"replenishment_units_new\",\"estimated_on_hand_inventory\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "21",
      "name": "Columns Rename",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "1534.38px",
      "y": "116.381px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentColNames",
          "value": "[\"on_hand_inventory_units_new\",\"phantom_inventory_new\",\"replenishment_units_new\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "newColNames",
          "value": "[\"on_hand_inventory_units\",\"phantom_inventory\",\"replenishment_units\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "23",
      "name": "Imputing With Constant",
      "description": "It imputes missing value with constant value. It fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.",
      "details": "This node imputes the missing value with constant value.<br>\n<br>\nIt fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.<br>",
      "examples": "Incoming Dataframe has following rows and [AGE] column has missing values / [NULL] for some rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |\t\t\t<br>\nCD04       |    MATT         |\t\t\t<br>\n<br>\nIf imputingwithconstatnt node is configured to Impute [AGE] with 45 then missing values in [AGE] column would be replaced with 45.<br>\nOutgoing Dataframe would result as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |    45\t\t\t<br>\nCD04       |    MATT         |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeReplaceMissingValueWithConstant",
      "x": "1481.69px",
      "y": "238.719px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "colNames",
          "value": "[\"shelf_capacity\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns to be processed for missing values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constants",
          "value": "[\"0\"]",
          "widget": "variables_list_textfield",
          "title": "Constants",
          "description": "Missing value will be replaced with constant",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "25",
      "name": "Expressions",
      "description": "This node creates a new DataFrame by adding new columns to the incoming Dataframe as per the Expression computation",
      "details": "<h2>Expressions Node Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the expressions computated.<br>\n<br>\nIt computes expressions to calculate the value of a metric column based on mathematical or logical operations performed on other metric columns.<br>\n<br>\nNew column can also be computed using existing columns in the Dataframe.<br>\n<br>\n<h3>Following functions can be used in Expressions:</h3>\n<br>\n<h3> Mathematical Computations</h3>\n<br>\n<ul>\n<li>\tMaths Operations -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n<li>\tMaths Operations -> Example : DISCOUNT / LIST_PRICE</li>\n<li>\tMaths Operations -> Example : (DISCOUNT / LIST_PRICE) * 100</li>\n</ul>\n<h3>String Functions</h3>\n<br>\n<ul>\n<li>\tConcatenation     -> Example : CONCAT(PRD_CD,':',PRD_NAME)</li>\n<li>\tSubstring     -> Example : SUBSTR(PRD_NAME,1,3)</li>\n<li>\tReplace\t\t \t-> Example : REPLACE(PRD_NAME,'M','$')</li>\n<li>\tRight\t\t \t-> Example : RIGHT(PRD_NAME, 5)</li>\n<li>\tLeft\t\t \t-> Example : LEFT(PRD_NAME, 5)</li>\n<li>\tRight Trim\t \t-> Example : RTRIM(PRD_NAME)</li>\n<li>\tIntial Caps\t \t-> Example : INITCAP(LOWER(PRD_NAME))</li>\n<li>\tLength\t\t \t-> Example : LENGTH(PRD_NAME)</li>\n<li>\tSplit\t\t \t-> Example : SPLIT(PRD_NAME, ' ')</li>\n</ul>\n<h3>Number Format Functions</h3>\n<br>\n<ul>\n<li>\tFormat Number\t-> Example : FORMAT_NUMBER(LIST_PRICE, '#,###,###,###.00')</li>\n</ul>\n<h3>Date and Timestamp Functions</h3>\n<br>\n<h4>Fetch Current Date and Time</h4>\n<br>\n<ul>\n<li>\tCurrent Date value\t\t\t\t          -> Example : CURRENT_DATE</li>\n<li>\tCurrent Date Time value\t\t\t\t      -> Example : CURRENT_TIMESTAMP</li>\n</ul>\n<h4>Format Date-Time values</h4>\n<ul>\n<li>\tDate Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy')</li>\n<li>\tDate-Time Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy hh:mm:ss')</li>\n</ul>\n<h4>String to Date-Time conversion</h4>\n<ul>\n<li>\tConvert a String to Date\t      \t\t-> Example : TO_DATE('12-DEC-21', 'dd-MMM-yy')</li>\n<li>\tConvert a String to Datetime\t\t\t\t\t\t            \t-> TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS')</li>\n</ul>\n<h4>Date-Time addition and substraction</h4>\n<ul>\n<li>\tAdd/Substract Years to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 12)</li>\n<li>\tAdd/Substract Months to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 3)</li>\n<li>\tAdd/Substract Days to a Date\t\t    -> Example : DATE_ADD(CURRENT_DATE, -1)</li>\n<li>\tAdd/Substract Hours to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours</li>\n<li>\tAdd/Substract Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Minutes</li>\n<li>\tAdd/Substract Seconds to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Seconds</li>\n<li>\tAdd/Substract Hours and Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours + Interval 2 Minutes</li>\n<li>\tSubstract Hours and Minutes from a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') - Interval 2 Hours - Interval 2 Minutes</li>\n</ul>\n<h4>Fetch Next Day and Last Day of Month</h4>\n<ul>\n<li>\tLast Day of a Month   \t\t\t\t      -> Example : LAST_DAY(CURRENT_DATE)</li>\n<li>\tNext Day value\t\t   \t\t\t\t        -> Example : NEXT_DAY(CURRENT_DATE, 'Sunday')</li>\n<li>\tFirst Day of Year/Month\t\t\t\t      -> Example : DATE_TRUNC('MONTH', CURRENT_DATE)</li>\n<li>\tYear/Month/Quarter/DayOfMonth value\t-> Example : YEAR(CURRENT_DATE)/MONTH(CURRENT_DATE)/QUARTER(CURRENT_DATE)/DAYOFMONTH(CURRENT_DATE)/DAYOFWEEK(CURRENT_DATE)</li>\n<li>\tDay/Week count of the Year\t\t\t    -> Example : DAYOFWEEK(CURRENT_DATE)/WEEKOFYEAR(CURRENT_DATE)</li>\n</ul>\n<h4>Date Difference functions</h4>\n<ul>\n<li>\tDate Diff between two Dates\t\t\t    -> Example : DATEDIFF(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Months between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Years between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy')) / 12</li>\n</ul>\n<h3>Regex Functions</h3>\n<br>\n<ul>\n<li>\tReplace using Regex\t\t-> Example : REGEXP_REPLACE(PRD_NAME, 'E', '#')</li>\n</ul>",
      "examples": "<h2>Expressions Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\n<h4>Expressions Node Configuration</h4>\n<br>\nExpressions node is configured to compute new columns as below:<br>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nNET_AMT                  |    LIST_PRICE + TAX_AMT - DISCOUNT<br>\nPRD_DETAILS              |    CONCAT(PRD_CD,':',PRD_NAME)<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutgoing Dataframe would be created as below with new columns added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    |    PRD_DETAILS<br>\n--------------------------------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0     |    P01:DRILL MACHINE<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0     |    P02:WEIGHING MACHINE<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0      |    P03:HAMMER<br>\n<br>\n<h4>Computing Current Date value using Expression:</h4>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nCURRENT_DATE_VAL         |    CURRENT_DATE<br>\nCURRENT_DATETIME_VAL     |    CURRENT_TIMESTAMP<br>\n<br>\nOutput would contain below value<br>\n<br>\nCURRENT_DATE_VAL         |    CURRENT_DATETIME_VAL<br>\n-----------------------------------------------------------------<br>\n2022-09-07               |    2022-09-07 10:05:12.432<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExpressions",
      "x": "1356.34px",
      "y": "238.394px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textfield",
          "title": "Description",
          "description": "Description to capture processing in this node",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"exp_computed1\"]",
          "widget": "key_array",
          "title": "New Column Names",
          "description": "New Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "expressions",
          "value": "[\"if((replenishment_units - total_sales_units - phantom_inventory) < 0, 0, (replenishment_units - total_sales_units - phantom_inventory))\"]",
          "widget": "value_array",
          "title": "Expressions",
          "description": "Expressions to create new columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "26",
      "name": "SQL",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "details": "<h2>SQL Details</h2>\n<br>\nSQL node receives an input data frame. It creates a temporary table on top of that data frame. It executes the provided SQL in the node on the temporary table.<br>\n<br>\nThe resulting data frame of running the SQL is passed on to the next node.<br>",
      "examples": "<h2>SQL Examples</h2>\n<br>\nBelow are some examples of SQL. <br>\n<br>\nTemporary table name used : tempTable<br>\n<br>\nThe schema of the Input Dataframe is : id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> find the average price of houses</h4>\n<br>\nselect avg(price) as avg_price from tempTable<br>\n<br>\n<br>\n<h4> find bedrooms with avg price greater than 10000</h4>\n<br>\nselect bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000<br>\n<br>\n<br>\n<h4> details of houses with bedrooms avg price greater than 10000</h4>\n<br>\nselect tempTable.* , inner_table.avg_price from<br>\n(select bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000) as inner_table<br>\nJOIN tempTable ON(inner_table.bedrooms = tempTable.bedrooms)<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "1223.4px",
      "y": "238.381px",
      "hint": "Whenever the table is changed, go to Schema tab and Refresh the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "sql",
          "value": "SELECT date, store_id, sku, product_category, total_sales_units, inventory_pipeline, units_in_transit, units_in_dc, units_on_order, \nunits_under_promotion, shelf_capacity, promotion_flag, replenishment_flag, daily_sales_units, start_on_hand_units, end_on_hand_units, \nphantom_inventory_ind, phantom_inventory, on_hand_inventory_units, replenishment_units, estimated_on_hand_inventory, exp_computed1,\nSUM(exp_computed1) over (PARTITION BY store_id, sku ORDER BY date) AS exp_computed1_cumsum\nFROM fire_temp_table\nORDER BY store_id, sku, date",
          "widget": "textarea_large",
          "type": "sql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"promotion_flag\",\"replenishment_flag\",\"daily_sales_units\",\"start_on_hand_units\",\"end_on_hand_units\",\"phantom_inventory_ind\",\"phantom_inventory\",\"on_hand_inventory_units\",\"replenishment_units\",\"estimated_on_hand_inventory\",\"exp_computed1\",\"exp_computed1_cumsum\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"STRING\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "27",
      "name": "Case When",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "1098.19px",
      "y": "243.188px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "exp_computed1_cumsum_new",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"exp_computed1_cumsum < 0\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"0\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "exp_computed1_cumsum",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "28",
      "name": "Case When",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "984.187px",
      "y": "240.194px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "exp_computed1_cumsum_new2",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"exp_computed1_cumsum_new > on_hand_inventory_units\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"on_hand_inventory_units\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "exp_computed1_cumsum_new",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "29",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "860.187px",
      "y": "241.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"promotion_flag\",\"replenishment_flag\",\"daily_sales_units\",\"start_on_hand_units\",\"end_on_hand_units\",\"phantom_inventory_ind\",\"phantom_inventory\",\"on_hand_inventory_units\",\"replenishment_units\",\"exp_computed1_cumsum_new2\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "30",
      "name": "Columns Rename",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "746.194px",
      "y": "241.194px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentColNames",
          "value": "[\"exp_computed1_cumsum_new2\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "newColNames",
          "value": "[\"estimated_on_hand_inventory\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "31",
      "name": "Window Analytics",
      "description": "",
      "details": "This node Generates a new Dataframe with Analytics Column appended to the incoming Dataframe.<br>\n<br>\nAnalytics Column is populated with value based on the Window Function selected.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT    |    SALARY    |    AGE    <br>\n------------------------------------------------------------------------<br>\nE01       |    ANTHONY     |    HR      |    50000     |    40<br>\nE02       |    LISA        |    HR      |    45000     |    35<br>\nE03       |    MARTIN      |    HR      |    20000     |    25<br>\nE04       |    DAVID       |    SALES   |    55000     |    40<br>\nE05       |    MARK        |    SALES   |    60000     |    45<br>\nE06       |    JOE         |    SALES   |    40000     |    25<br>\nE07       |    BELLA       |    HR      |    60000     |    24<br>\n<br>\n<h2> If WindowAnalytics node is configured as below:</h2>\n<br>\nPARTITIONBY      :     DEPT<br>\nORDERBY          :     AGE<br>\nWINDOW FUNCTION  :     first_value<br>\nANALYTICS COLUMN :     SALARY : integer<br>\nWINDOW OFFSET    :     1<br>\n<br>\nthen outgoing Dataframe would be created as below <br>\nwhere incoming Dataframe is partitioned by [DEPT] and data is sorted by [AGE] and [FIRST VALUE] of Analytics Column [SALARY] within a partition is appended as new column:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT    |    SALARY    |    AGE    |    first_value<br>\n---------------------------------------------------------------------------------------<br>\nE07       |    BELLA       |    HR      |    60000     |    24     |    60000<br>\nE03       |    MARTIN      |    HR      |    20000     |    25     |    60000<br>\nE02       |    LISA        |    HR      |    45000     |    35     |    60000<br>\nE01       |    ANTHONY     |    HR      |    50000     |    40     |    60000<br>\nE06       |    JOE         |    SALES   |    40000     |    25     |    40000<br>\nE04       |    DAVID       |    SALES   |    55000     |    40     |    40000<br>\nE05       |    MARK        |    SALES   |    60000     |    45     |    40000<br>\n<br>\n<h2> If WindowAnalytics node is configured as below:</h2>\n<br>\nPARTITIONBY      :     DEPT<br>\nORDERBY          :     AGE<br>\nWINDOW FUNCTION  :     lead<br>\nANALYTICS COLUMN :     SALARY : integer<br>\nWINDOW OFFSET    :     2<br>\n<br>\nthen outgoing Dataframe would be created as below <br>\nwhere incoming Dataframe is partitioned by [DEPT] and data is sorted by [AGE] and <br>\nAnalytics Column [SALARY] value of leading 2 or [WINDOW OFFSET] rows within a partition is appended as new column:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT    |    SALARY    |    AGE    |    first_value<br>\n---------------------------------------------------------------------------------------<br>\nE07       |    BELLA       |    HR      |    60000     |    24     |    45000<br>\nE03       |    MARTIN      |    HR      |    20000     |    25     |    50000<br>\nE02       |    LISA        |    HR      |    45000     |    35     |    <br>\nE01       |    ANTHONY     |    HR      |    50000     |    40     |    <br>\nE06       |    JOE         |    SALES   |    40000     |    25     |    60000<br>\nE04       |    DAVID       |    SALES   |    55000     |    40     |    <br>\nE05       |    MARK        |    SALES   |    60000     |    45     |<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeWindowAnalytics",
      "x": "633.194px",
      "y": "239.194px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "partitionByCols",
          "value": "store_id, sku",
          "widget": "textfield",
          "title": "PartitionBy",
          "description": "partition column names separated by comma(,) ",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "orderByCols",
          "value": "date",
          "widget": "textfield",
          "title": "OrderBy",
          "description": "order by column names separated by comma(,)",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "windowFunction",
          "value": "lag",
          "widget": "array",
          "title": "Window Function",
          "description": "Window Function Name",
          "optionsArray": [
            "first_value",
            "last_value",
            "lag",
            "lead"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "analyticsCol",
          "value": "estimated_on_hand_inventory",
          "widget": "variable",
          "title": "Analytics Column",
          "description": "",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "window_offset",
          "value": "1",
          "widget": "textfield",
          "title": "Window Offset",
          "description": "It's used in lead and lag functions.",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "32",
      "name": "Imputing With Constant",
      "description": "It imputes missing value with constant value. It fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.",
      "details": "This node imputes the missing value with constant value.<br>\n<br>\nIt fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.<br>",
      "examples": "Incoming Dataframe has following rows and [AGE] column has missing values / [NULL] for some rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |\t\t\t<br>\nCD04       |    MATT         |\t\t\t<br>\n<br>\nIf imputingwithconstatnt node is configured to Impute [AGE] with 45 then missing values in [AGE] column would be replaced with 45.<br>\nOutgoing Dataframe would result as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |    45\t\t\t<br>\nCD04       |    MATT         |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeReplaceMissingValueWithConstant",
      "x": "496.362px",
      "y": "231.381px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "colNames",
          "value": "[\"lag\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns to be processed for missing values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constants",
          "value": "[\"0\"]",
          "widget": "variables_list_textfield",
          "title": "Constants",
          "description": "Missing value will be replaced with constant",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "33",
      "name": "Case When",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "466.175px",
      "y": "375.194px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "prior_inventory",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"replenishment_flag=1\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"lag\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "0",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "34",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "602px",
      "y": "369px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"promotion_flag\",\"replenishment_flag\",\"daily_sales_units\",\"start_on_hand_units\",\"end_on_hand_units\",\"phantom_inventory_ind\",\"phantom_inventory\",\"on_hand_inventory_units\",\"replenishment_units\",\"estimated_on_hand_inventory\",\"prior_inventory\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "36",
      "name": "SQL",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "details": "<h2>SQL Details</h2>\n<br>\nSQL node receives an input data frame. It creates a temporary table on top of that data frame. It executes the provided SQL in the node on the temporary table.<br>\n<br>\nThe resulting data frame of running the SQL is passed on to the next node.<br>",
      "examples": "<h2>SQL Examples</h2>\n<br>\nBelow are some examples of SQL. <br>\n<br>\nTemporary table name used : tempTable<br>\n<br>\nThe schema of the Input Dataframe is : id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> find the average price of houses</h4>\n<br>\nselect avg(price) as avg_price from tempTable<br>\n<br>\n<br>\n<h4> find bedrooms with avg price greater than 10000</h4>\n<br>\nselect bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000<br>\n<br>\n<br>\n<h4> details of houses with bedrooms avg price greater than 10000</h4>\n<br>\nselect tempTable.* , inner_table.avg_price from<br>\n(select bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000) as inner_table<br>\nJOIN tempTable ON(inner_table.bedrooms = tempTable.bedrooms)<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "734.2px",
      "y": "367.194px",
      "hint": "Whenever the table is changed, go to Schema tab and Refresh the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "sql",
          "value": "SELECT date, store_id, sku, product_category, total_sales_units, inventory_pipeline, units_in_transit, units_in_dc, units_on_order, units_under_promotion, \nshelf_capacity, promotion_flag, replenishment_flag, daily_sales_units, start_on_hand_units, end_on_hand_units, phantom_inventory_ind, phantom_inventory, \non_hand_inventory_units, replenishment_units, estimated_on_hand_inventory, prior_inventory,\nSUM(prior_inventory) OVER(PARTITION BY store_id, sku ORDER BY date ROWS BETWEEN 90 PRECEDING AND CURRENT ROW) /\n      (SUM(replenishment_flag) OVER(PARTITION BY store_id, sku ORDER BY date ROWS BETWEEN 90 PRECEDING AND CURRENT ROW) + 1) AS rolling_stock_onhand\n      FROM fire_temp_table",
          "widget": "textarea_large",
          "type": "sql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"promotion_flag\",\"replenishment_flag\",\"daily_sales_units\",\"start_on_hand_units\",\"end_on_hand_units\",\"phantom_inventory_ind\",\"phantom_inventory\",\"on_hand_inventory_units\",\"replenishment_units\",\"estimated_on_hand_inventory\",\"prior_inventory\",\"rolling_stock_onhand\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "37",
      "name": "Case When",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "854.975px",
      "y": "360.187px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "rolling_min_expected_stock",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"replenishment_flag != 1\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"0\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "rolling_stock_onhand",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "38",
      "name": "Imputing With Constant",
      "description": "It imputes missing value with constant value. It fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.",
      "details": "This node imputes the missing value with constant value.<br>\n<br>\nIt fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.<br>",
      "examples": "Incoming Dataframe has following rows and [AGE] column has missing values / [NULL] for some rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |\t\t\t<br>\nCD04       |    MATT         |\t\t\t<br>\n<br>\nIf imputingwithconstatnt node is configured to Impute [AGE] with 45 then missing values in [AGE] column would be replaced with 45.<br>\nOutgoing Dataframe would result as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |    45\t\t\t<br>\nCD04       |    MATT         |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeReplaceMissingValueWithConstant",
      "x": "967.975px",
      "y": "356.194px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "colNames",
          "value": "[\"rolling_min_expected_stock\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns to be processed for missing values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constants",
          "value": "[\"0\"]",
          "widget": "variables_list_textfield",
          "title": "Constants",
          "description": "Missing value will be replaced with constant",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "39",
      "name": "Expressions",
      "description": "This node creates a new DataFrame by adding new columns to the incoming Dataframe as per the Expression computation",
      "details": "<h2>Expressions Node Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the expressions computated.<br>\n<br>\nIt computes expressions to calculate the value of a metric column based on mathematical or logical operations performed on other metric columns.<br>\n<br>\nNew column can also be computed using existing columns in the Dataframe.<br>\n<br>\n<h3>Following functions can be used in Expressions:</h3>\n<br>\n<h3> Mathematical Computations</h3>\n<br>\n<ul>\n<li>\tMaths Operations -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n<li>\tMaths Operations -> Example : DISCOUNT / LIST_PRICE</li>\n<li>\tMaths Operations -> Example : (DISCOUNT / LIST_PRICE) * 100</li>\n</ul>\n<h3>String Functions</h3>\n<br>\n<ul>\n<li>\tConcatenation     -> Example : CONCAT(PRD_CD,':',PRD_NAME)</li>\n<li>\tSubstring     -> Example : SUBSTR(PRD_NAME,1,3)</li>\n<li>\tReplace\t\t \t-> Example : REPLACE(PRD_NAME,'M','$')</li>\n<li>\tRight\t\t \t-> Example : RIGHT(PRD_NAME, 5)</li>\n<li>\tLeft\t\t \t-> Example : LEFT(PRD_NAME, 5)</li>\n<li>\tRight Trim\t \t-> Example : RTRIM(PRD_NAME)</li>\n<li>\tIntial Caps\t \t-> Example : INITCAP(LOWER(PRD_NAME))</li>\n<li>\tLength\t\t \t-> Example : LENGTH(PRD_NAME)</li>\n<li>\tSplit\t\t \t-> Example : SPLIT(PRD_NAME, ' ')</li>\n</ul>\n<h3>Number Format Functions</h3>\n<br>\n<ul>\n<li>\tFormat Number\t-> Example : FORMAT_NUMBER(LIST_PRICE, '#,###,###,###.00')</li>\n</ul>\n<h3>Date and Timestamp Functions</h3>\n<br>\n<h4>Fetch Current Date and Time</h4>\n<br>\n<ul>\n<li>\tCurrent Date value\t\t\t\t          -> Example : CURRENT_DATE</li>\n<li>\tCurrent Date Time value\t\t\t\t      -> Example : CURRENT_TIMESTAMP</li>\n</ul>\n<h4>Format Date-Time values</h4>\n<ul>\n<li>\tDate Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy')</li>\n<li>\tDate-Time Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy hh:mm:ss')</li>\n</ul>\n<h4>String to Date-Time conversion</h4>\n<ul>\n<li>\tConvert a String to Date\t      \t\t-> Example : TO_DATE('12-DEC-21', 'dd-MMM-yy')</li>\n<li>\tConvert a String to Datetime\t\t\t\t\t\t            \t-> TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS')</li>\n</ul>\n<h4>Date-Time addition and substraction</h4>\n<ul>\n<li>\tAdd/Substract Years to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 12)</li>\n<li>\tAdd/Substract Months to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 3)</li>\n<li>\tAdd/Substract Days to a Date\t\t    -> Example : DATE_ADD(CURRENT_DATE, -1)</li>\n<li>\tAdd/Substract Hours to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours</li>\n<li>\tAdd/Substract Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Minutes</li>\n<li>\tAdd/Substract Seconds to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Seconds</li>\n<li>\tAdd/Substract Hours and Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours + Interval 2 Minutes</li>\n<li>\tSubstract Hours and Minutes from a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') - Interval 2 Hours - Interval 2 Minutes</li>\n</ul>\n<h4>Fetch Next Day and Last Day of Month</h4>\n<ul>\n<li>\tLast Day of a Month   \t\t\t\t      -> Example : LAST_DAY(CURRENT_DATE)</li>\n<li>\tNext Day value\t\t   \t\t\t\t        -> Example : NEXT_DAY(CURRENT_DATE, 'Sunday')</li>\n<li>\tFirst Day of Year/Month\t\t\t\t      -> Example : DATE_TRUNC('MONTH', CURRENT_DATE)</li>\n<li>\tYear/Month/Quarter/DayOfMonth value\t-> Example : YEAR(CURRENT_DATE)/MONTH(CURRENT_DATE)/QUARTER(CURRENT_DATE)/DAYOFMONTH(CURRENT_DATE)/DAYOFWEEK(CURRENT_DATE)</li>\n<li>\tDay/Week count of the Year\t\t\t    -> Example : DAYOFWEEK(CURRENT_DATE)/WEEKOFYEAR(CURRENT_DATE)</li>\n</ul>\n<h4>Date Difference functions</h4>\n<ul>\n<li>\tDate Diff between two Dates\t\t\t    -> Example : DATEDIFF(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Months between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Years between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy')) / 12</li>\n</ul>\n<h3>Regex Functions</h3>\n<br>\n<ul>\n<li>\tReplace using Regex\t\t-> Example : REGEXP_REPLACE(PRD_NAME, 'E', '#')</li>\n</ul>",
      "examples": "<h2>Expressions Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\n<h4>Expressions Node Configuration</h4>\n<br>\nExpressions node is configured to compute new columns as below:<br>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nNET_AMT                  |    LIST_PRICE + TAX_AMT - DISCOUNT<br>\nPRD_DETAILS              |    CONCAT(PRD_CD,':',PRD_NAME)<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutgoing Dataframe would be created as below with new columns added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    |    PRD_DETAILS<br>\n--------------------------------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0     |    P01:DRILL MACHINE<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0     |    P02:WEIGHING MACHINE<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0      |    P03:HAMMER<br>\n<br>\n<h4>Computing Current Date value using Expression:</h4>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nCURRENT_DATE_VAL         |    CURRENT_DATE<br>\nCURRENT_DATETIME_VAL     |    CURRENT_TIMESTAMP<br>\n<br>\nOutput would contain below value<br>\n<br>\nCURRENT_DATE_VAL         |    CURRENT_DATETIME_VAL<br>\n-----------------------------------------------------------------<br>\n2022-09-07               |    2022-09-07 10:05:12.432<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExpressions",
      "x": "1084.4px",
      "y": "366.194px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textfield",
          "title": "Description",
          "description": "Description to capture processing in this node",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"min_expected_stock\"]",
          "widget": "key_array",
          "title": "New Column Names",
          "description": "New Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "expressions",
          "value": "[\"NULLIF(rolling_min_expected_stock,0)\"]",
          "widget": "value_array",
          "title": "Expressions",
          "description": "Expressions to create new columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "40",
      "name": "SQL",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "details": "<h2>SQL Details</h2>\n<br>\nSQL node receives an input data frame. It creates a temporary table on top of that data frame. It executes the provided SQL in the node on the temporary table.<br>\n<br>\nThe resulting data frame of running the SQL is passed on to the next node.<br>",
      "examples": "<h2>SQL Examples</h2>\n<br>\nBelow are some examples of SQL. <br>\n<br>\nTemporary table name used : tempTable<br>\n<br>\nThe schema of the Input Dataframe is : id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> find the average price of houses</h4>\n<br>\nselect avg(price) as avg_price from tempTable<br>\n<br>\n<br>\n<h4> find bedrooms with avg price greater than 10000</h4>\n<br>\nselect bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000<br>\n<br>\n<br>\n<h4> details of houses with bedrooms avg price greater than 10000</h4>\n<br>\nselect tempTable.* , inner_table.avg_price from<br>\n(select bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000) as inner_table<br>\nJOIN tempTable ON(inner_table.bedrooms = tempTable.bedrooms)<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "1208.59px",
      "y": "374.194px",
      "hint": "Whenever the table is changed, go to Schema tab and Refresh the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "sql",
          "value": "SELECT date, store_id, sku, product_category, total_sales_units, inventory_pipeline, units_in_transit, units_in_dc, units_on_order, units_under_promotion, shelf_capacity,\npromotion_flag, replenishment_flag, daily_sales_units, start_on_hand_units, end_on_hand_units, phantom_inventory_ind, phantom_inventory, on_hand_inventory_units,\nreplenishment_units, estimated_on_hand_inventory, prior_inventory, rolling_stock_onhand, rolling_min_expected_stock, min_expected_stock,\nLAST(min_expected_stock, True) OVER(PARTITION BY store_id, sku ORDER BY date) AS min_expected_stock_2\nFROM fire_temp_table",
          "widget": "textarea_large",
          "type": "sql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"promotion_flag\",\"replenishment_flag\",\"daily_sales_units\",\"start_on_hand_units\",\"end_on_hand_units\",\"phantom_inventory_ind\",\"phantom_inventory\",\"on_hand_inventory_units\",\"replenishment_units\",\"estimated_on_hand_inventory\",\"prior_inventory\",\"rolling_stock_onhand\",\"rolling_min_expected_stock\",\"min_expected_stock\",\"min_expected_stock_2\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "41",
      "name": "Imputing With Constant",
      "description": "It imputes missing value with constant value. It fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.",
      "details": "This node imputes the missing value with constant value.<br>\n<br>\nIt fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.<br>",
      "examples": "Incoming Dataframe has following rows and [AGE] column has missing values / [NULL] for some rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |\t\t\t<br>\nCD04       |    MATT         |\t\t\t<br>\n<br>\nIf imputingwithconstatnt node is configured to Impute [AGE] with 45 then missing values in [AGE] column would be replaced with 45.<br>\nOutgoing Dataframe would result as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |    45\t\t\t<br>\nCD04       |    MATT         |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeReplaceMissingValueWithConstant",
      "x": "1319.6px",
      "y": "368.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "colNames",
          "value": "[\"min_expected_stock_2\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns to be processed for missing values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constants",
          "value": "[\"0\"]",
          "widget": "variables_list_textfield",
          "title": "Constants",
          "description": "Missing value will be replaced with constant",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "42",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "1465.79px",
      "y": "364.387px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"promotion_flag\",\"replenishment_flag\",\"daily_sales_units\",\"start_on_hand_units\",\"end_on_hand_units\",\"phantom_inventory_ind\",\"phantom_inventory\",\"on_hand_inventory_units\",\"replenishment_units\",\"estimated_on_hand_inventory\",\"prior_inventory\",\"rolling_stock_onhand\",\"rolling_min_expected_stock\",\"min_expected_stock_2\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "43",
      "name": "Columns Rename",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "1465.97px",
      "y": "494.581px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentColNames",
          "value": "[\"min_expected_stock_2\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "newColNames",
          "value": "[\"min_expected_stock\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "44",
      "name": "SQL",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "details": "<h2>SQL Details</h2>\n<br>\nSQL node receives an input data frame. It creates a temporary table on top of that data frame. It executes the provided SQL in the node on the temporary table.<br>\n<br>\nThe resulting data frame of running the SQL is passed on to the next node.<br>",
      "examples": "<h2>SQL Examples</h2>\n<br>\nBelow are some examples of SQL. <br>\n<br>\nTemporary table name used : tempTable<br>\n<br>\nThe schema of the Input Dataframe is : id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> find the average price of houses</h4>\n<br>\nselect avg(price) as avg_price from tempTable<br>\n<br>\n<br>\n<h4> find bedrooms with avg price greater than 10000</h4>\n<br>\nselect bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000<br>\n<br>\n<br>\n<h4> details of houses with bedrooms avg price greater than 10000</h4>\n<br>\nselect tempTable.* , inner_table.avg_price from<br>\n(select bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000) as inner_table<br>\nJOIN tempTable ON(inner_table.bedrooms = tempTable.bedrooms)<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "1318.19px",
      "y": "500.375px",
      "hint": "Whenever the table is changed, go to Schema tab and Refresh the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "sql",
          "value": "SELECT date, store_id, sku, product_category, total_sales_units, inventory_pipeline, units_in_transit, units_in_dc, units_on_order, units_under_promotion, shelf_capacity,\npromotion_flag, replenishment_flag, start_on_hand_units, end_on_hand_units, phantom_inventory_ind, phantom_inventory, on_hand_inventory_units, \nreplenishment_units, estimated_on_hand_inventory, prior_inventory, rolling_stock_onhand, rolling_min_expected_stock, min_expected_stock,\nnvl(daily_sales_units, 0) AS daily_sales_units\nFROM\n(\n  SELECT date, store_id, sku, product_category, total_sales_units, inventory_pipeline, units_in_transit, units_in_dc, units_on_order, units_under_promotion, shelf_capacity,\n  promotion_flag, replenishment_flag, start_on_hand_units, end_on_hand_units, phantom_inventory_ind, phantom_inventory, on_hand_inventory_units, \n  replenishment_units, estimated_on_hand_inventory, prior_inventory, rolling_stock_onhand, rolling_min_expected_stock, min_expected_stock,\n  LAST(daily_sales_units, True) OVER(PARTITION BY store_id, sku ORDER BY date) AS daily_sales_units\n  FROM\n  (\n    SELECT date, store_id, sku, product_category, total_sales_units, inventory_pipeline, units_in_transit, units_in_dc, units_on_order, units_under_promotion, shelf_capacity,\n    promotion_flag, replenishment_flag, start_on_hand_units, end_on_hand_units, phantom_inventory_ind, phantom_inventory, on_hand_inventory_units, \n    replenishment_units, estimated_on_hand_inventory, prior_inventory, rolling_stock_onhand, rolling_min_expected_stock, min_expected_stock,\n    AVG(total_sales_units) OVER(PARTITION BY store_id, sku ORDER BY date ROWS BETWEEN 90 PRECEDING AND CURRENT ROW) AS daily_sales_units\n    FROM fire_temp_table\n  )\n)",
          "widget": "textarea_large",
          "type": "sql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"date\",\"store_id\",\"sku\",\"product_category\",\"total_sales_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"promotion_flag\",\"replenishment_flag\",\"start_on_hand_units\",\"end_on_hand_units\",\"phantom_inventory_ind\",\"phantom_inventory\",\"on_hand_inventory_units\",\"replenishment_units\",\"estimated_on_hand_inventory\",\"prior_inventory\",\"rolling_stock_onhand\",\"rolling_min_expected_stock\",\"min_expected_stock\",\"daily_sales_units\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "45",
      "name": "Expressions",
      "description": "This node creates a new DataFrame by adding new columns to the incoming Dataframe as per the Expression computation",
      "details": "<h2>Expressions Node Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the expressions computated.<br>\n<br>\nIt computes expressions to calculate the value of a metric column based on mathematical or logical operations performed on other metric columns.<br>\n<br>\nNew column can also be computed using existing columns in the Dataframe.<br>\n<br>\n<h3>Following functions can be used in Expressions:</h3>\n<br>\n<h3> Mathematical Computations</h3>\n<br>\n<ul>\n<li>\tMaths Operations -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n<li>\tMaths Operations -> Example : DISCOUNT / LIST_PRICE</li>\n<li>\tMaths Operations -> Example : (DISCOUNT / LIST_PRICE) * 100</li>\n</ul>\n<h3>String Functions</h3>\n<br>\n<ul>\n<li>\tConcatenation     -> Example : CONCAT(PRD_CD,':',PRD_NAME)</li>\n<li>\tSubstring     -> Example : SUBSTR(PRD_NAME,1,3)</li>\n<li>\tReplace\t\t \t-> Example : REPLACE(PRD_NAME,'M','$')</li>\n<li>\tRight\t\t \t-> Example : RIGHT(PRD_NAME, 5)</li>\n<li>\tLeft\t\t \t-> Example : LEFT(PRD_NAME, 5)</li>\n<li>\tRight Trim\t \t-> Example : RTRIM(PRD_NAME)</li>\n<li>\tIntial Caps\t \t-> Example : INITCAP(LOWER(PRD_NAME))</li>\n<li>\tLength\t\t \t-> Example : LENGTH(PRD_NAME)</li>\n<li>\tSplit\t\t \t-> Example : SPLIT(PRD_NAME, ' ')</li>\n</ul>\n<h3>Number Format Functions</h3>\n<br>\n<ul>\n<li>\tFormat Number\t-> Example : FORMAT_NUMBER(LIST_PRICE, '#,###,###,###.00')</li>\n</ul>\n<h3>Date and Timestamp Functions</h3>\n<br>\n<h4>Fetch Current Date and Time</h4>\n<br>\n<ul>\n<li>\tCurrent Date value\t\t\t\t          -> Example : CURRENT_DATE</li>\n<li>\tCurrent Date Time value\t\t\t\t      -> Example : CURRENT_TIMESTAMP</li>\n</ul>\n<h4>Format Date-Time values</h4>\n<ul>\n<li>\tDate Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy')</li>\n<li>\tDate-Time Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy hh:mm:ss')</li>\n</ul>\n<h4>String to Date-Time conversion</h4>\n<ul>\n<li>\tConvert a String to Date\t      \t\t-> Example : TO_DATE('12-DEC-21', 'dd-MMM-yy')</li>\n<li>\tConvert a String to Datetime\t\t\t\t\t\t            \t-> TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS')</li>\n</ul>\n<h4>Date-Time addition and substraction</h4>\n<ul>\n<li>\tAdd/Substract Years to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 12)</li>\n<li>\tAdd/Substract Months to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 3)</li>\n<li>\tAdd/Substract Days to a Date\t\t    -> Example : DATE_ADD(CURRENT_DATE, -1)</li>\n<li>\tAdd/Substract Hours to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours</li>\n<li>\tAdd/Substract Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Minutes</li>\n<li>\tAdd/Substract Seconds to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Seconds</li>\n<li>\tAdd/Substract Hours and Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours + Interval 2 Minutes</li>\n<li>\tSubstract Hours and Minutes from a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') - Interval 2 Hours - Interval 2 Minutes</li>\n</ul>\n<h4>Fetch Next Day and Last Day of Month</h4>\n<ul>\n<li>\tLast Day of a Month   \t\t\t\t      -> Example : LAST_DAY(CURRENT_DATE)</li>\n<li>\tNext Day value\t\t   \t\t\t\t        -> Example : NEXT_DAY(CURRENT_DATE, 'Sunday')</li>\n<li>\tFirst Day of Year/Month\t\t\t\t      -> Example : DATE_TRUNC('MONTH', CURRENT_DATE)</li>\n<li>\tYear/Month/Quarter/DayOfMonth value\t-> Example : YEAR(CURRENT_DATE)/MONTH(CURRENT_DATE)/QUARTER(CURRENT_DATE)/DAYOFMONTH(CURRENT_DATE)/DAYOFWEEK(CURRENT_DATE)</li>\n<li>\tDay/Week count of the Year\t\t\t    -> Example : DAYOFWEEK(CURRENT_DATE)/WEEKOFYEAR(CURRENT_DATE)</li>\n</ul>\n<h4>Date Difference functions</h4>\n<ul>\n<li>\tDate Diff between two Dates\t\t\t    -> Example : DATEDIFF(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Months between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Years between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy')) / 12</li>\n</ul>\n<h3>Regex Functions</h3>\n<br>\n<ul>\n<li>\tReplace using Regex\t\t-> Example : REGEXP_REPLACE(PRD_NAME, 'E', '#')</li>\n</ul>",
      "examples": "<h2>Expressions Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\n<h4>Expressions Node Configuration</h4>\n<br>\nExpressions node is configured to compute new columns as below:<br>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nNET_AMT                  |    LIST_PRICE + TAX_AMT - DISCOUNT<br>\nPRD_DETAILS              |    CONCAT(PRD_CD,':',PRD_NAME)<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutgoing Dataframe would be created as below with new columns added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    |    PRD_DETAILS<br>\n--------------------------------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0     |    P01:DRILL MACHINE<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0     |    P02:WEIGHING MACHINE<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0      |    P03:HAMMER<br>\n<br>\n<h4>Computing Current Date value using Expression:</h4>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nCURRENT_DATE_VAL         |    CURRENT_DATE<br>\nCURRENT_DATETIME_VAL     |    CURRENT_TIMESTAMP<br>\n<br>\nOutput would contain below value<br>\n<br>\nCURRENT_DATE_VAL         |    CURRENT_DATETIME_VAL<br>\n-----------------------------------------------------------------<br>\n2022-09-07               |    2022-09-07 10:05:12.432<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExpressions",
      "x": "676.513px",
      "y": "487.587px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textfield",
          "title": "Description",
          "description": "Description to capture processing in this node",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"min_lead_time\"]",
          "widget": "key_array",
          "title": "New Column Names",
          "description": "New Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "expressions",
          "value": "[\"LEAST(lead_time_in_dc, lead_time_in_transit, lead_time_on_order)\"]",
          "widget": "value_array",
          "title": "Expressions",
          "description": "Expressions to create new columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "46",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "879.975px",
      "y": "490.175px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"store_id\",\"sku\",\"LEAD_TIME_IN_DC\",\"LEAD_TIME_IN_TRANSIT\",\"LEAD_TIME_ON_ORDER\",\"min_lead_time\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "50",
      "name": "Join On Columns",
      "description": "Joins the incoming Dataframes on the given columns",
      "details": "<h2>Join On Columns Node Details</h2>\n<br>\n<ul>\n<li> This node joins the incoming dataframes based on a specified column between the two dataframes.</li>\n<li> The new Dataframe will contain all the columns from both Dataframe.</li>\n</ul>\nJoining modes supported by this node are as follows:<br>\n<ul>\n<li> inner : The joined table will have records that have matching values in both tables.</li>\n<li> outer : The joined table contains either all the records from both the tables or fills in NULL values for missing matches on either side.</li>\n<li> left_outer  : Even if there are no matches in the right table it returns all the rows from the left table.</li>\n<li> right_outer : Even if there are no matches in the left table it returns all the rows from the right table.</li>\n<li> leftsemi : This gives only those rows in the left table that have a matching row in the right table.</li>\n</ul>",
      "examples": "<h2>Join On Columns Example</h2>\n<br>\n<h4> Incoming Dataframes</h4>\n<br>\n1st Incoming Dataframe table1 has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO       <br>\n-------------------------------------------<br>\nE01       |    DAVID       |    10         <br>\nE02       |    JOHN        |    20      <br>\nE03       |    MARTIN      |    30  <br>\nE04       |    TONY        |    40  <br>\n<br>\n2nd Incoming Dataframe table2 has the following rows:<br>\n<br>\nDEPT_ID    |      DEPT_NAME   |    LOC       <br>\n-------------------------------------------<br>\n10         |      HR          |    IND  <br>\n20         |      SALES       |    AUS  <br>\n30         |      MARKETING   |    UK         <br>\n50         |      RESEARCH    |    NZ      <br>\n<br>\n<h4> Selected columns for joining are following </h4>\n<ul>\n<li> From table1 is DEPT_NO</li>\n<li> From table2 is DEPT_ID</li>\n</ul>\n<h4> When the Joining condition is `inner` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_ID    |      DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |     10       |      HR         |    IND<br>\nE02       |    JOHN        |    20        |     20       |      SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |     30       |      MARKETING  |    UK<br>\n<br>\n<h4> When the Joining condition `outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_ID    |      DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |     10       |      HR         |    IND<br>\nE02       |    JOHN        |    20        |     20       |      SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |     30       |      MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |                 |    <br>\n          |                |              |     50       |      RESEARCH   |    NZ<br>\n<br>\n<h4> When the Joining condition is `left_outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_ID    |      DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |     10       |      HR         |    IND<br>\nE02       |    JOHN        |    20        |     20       |      SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |     30       |      MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |                 |    <br>\n<br>\n<h4> When the Joining condition `right_outer` we have</h4>\n<h4> Final Output</h4>\n          <br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_ID    |      DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |     10       |      HR         |    IND<br>\nE02       |    JOHN        |    20        |     20       |      SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |     30       |      MARKETING  |    UK<br>\n          |                |              |     50       |      RESEARCH   |    NZ<br>",
      "type": "join2inputs",
      "nodeClass": "fire.nodes.etl.JoinOnColumns",
      "x": "1073.35px",
      "y": "496.375px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinType",
          "value": "left_outer",
          "widget": "array",
          "title": "Join Type",
          "description": "Type of Join",
          "optionsArray": [
            "inner",
            "outer",
            "left_outer",
            "right_outer",
            "leftsemi"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "leftTableJoinColumn",
          "value": "[\"store_id\",\"sku\"]",
          "widget": "key_array_join",
          "title": "LeftTableJoinColumn",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "rightTableJoinColumn",
          "value": "[\"store_id\",\"sku\"]",
          "widget": "value_array_join",
          "title": "RightTableJoinColumn",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "51",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "1140.57px",
      "y": "631.187px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"left_store_id\",\"left_sku\",\"date\",\"product_category\",\"total_sales_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"promotion_flag\",\"replenishment_flag\",\"start_on_hand_units\",\"end_on_hand_units\",\"phantom_inventory_ind\",\"phantom_inventory\",\"on_hand_inventory_units\",\"replenishment_units\",\"estimated_on_hand_inventory\",\"prior_inventory\",\"rolling_stock_onhand\",\"rolling_min_expected_stock\",\"min_expected_stock\",\"daily_sales_units\",\"LEAD_TIME_IN_DC\",\"LEAD_TIME_IN_TRANSIT\",\"LEAD_TIME_ON_ORDER\",\"min_lead_time\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "52",
      "name": "Columns Rename",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "983.237px",
      "y": "630.85px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentColNames",
          "value": "[\"left_store_id\",\"left_sku\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "newColNames",
          "value": "[\"store_id\",\"sku\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "53",
      "name": "Expressions",
      "description": "This node creates a new DataFrame by adding new columns to the incoming Dataframe as per the Expression computation",
      "details": "<h2>Expressions Node Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the expressions computated.<br>\n<br>\nIt computes expressions to calculate the value of a metric column based on mathematical or logical operations performed on other metric columns.<br>\n<br>\nNew column can also be computed using existing columns in the Dataframe.<br>\n<br>\n<h3>Following functions can be used in Expressions:</h3>\n<br>\n<h3> Mathematical Computations</h3>\n<br>\n<ul>\n<li>\tMaths Operations -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n<li>\tMaths Operations -> Example : DISCOUNT / LIST_PRICE</li>\n<li>\tMaths Operations -> Example : (DISCOUNT / LIST_PRICE) * 100</li>\n</ul>\n<h3>String Functions</h3>\n<br>\n<ul>\n<li>\tConcatenation     -> Example : CONCAT(PRD_CD,':',PRD_NAME)</li>\n<li>\tSubstring     -> Example : SUBSTR(PRD_NAME,1,3)</li>\n<li>\tReplace\t\t \t-> Example : REPLACE(PRD_NAME,'M','$')</li>\n<li>\tRight\t\t \t-> Example : RIGHT(PRD_NAME, 5)</li>\n<li>\tLeft\t\t \t-> Example : LEFT(PRD_NAME, 5)</li>\n<li>\tRight Trim\t \t-> Example : RTRIM(PRD_NAME)</li>\n<li>\tIntial Caps\t \t-> Example : INITCAP(LOWER(PRD_NAME))</li>\n<li>\tLength\t\t \t-> Example : LENGTH(PRD_NAME)</li>\n<li>\tSplit\t\t \t-> Example : SPLIT(PRD_NAME, ' ')</li>\n</ul>\n<h3>Number Format Functions</h3>\n<br>\n<ul>\n<li>\tFormat Number\t-> Example : FORMAT_NUMBER(LIST_PRICE, '#,###,###,###.00')</li>\n</ul>\n<h3>Date and Timestamp Functions</h3>\n<br>\n<h4>Fetch Current Date and Time</h4>\n<br>\n<ul>\n<li>\tCurrent Date value\t\t\t\t          -> Example : CURRENT_DATE</li>\n<li>\tCurrent Date Time value\t\t\t\t      -> Example : CURRENT_TIMESTAMP</li>\n</ul>\n<h4>Format Date-Time values</h4>\n<ul>\n<li>\tDate Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy')</li>\n<li>\tDate-Time Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy hh:mm:ss')</li>\n</ul>\n<h4>String to Date-Time conversion</h4>\n<ul>\n<li>\tConvert a String to Date\t      \t\t-> Example : TO_DATE('12-DEC-21', 'dd-MMM-yy')</li>\n<li>\tConvert a String to Datetime\t\t\t\t\t\t            \t-> TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS')</li>\n</ul>\n<h4>Date-Time addition and substraction</h4>\n<ul>\n<li>\tAdd/Substract Years to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 12)</li>\n<li>\tAdd/Substract Months to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 3)</li>\n<li>\tAdd/Substract Days to a Date\t\t    -> Example : DATE_ADD(CURRENT_DATE, -1)</li>\n<li>\tAdd/Substract Hours to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours</li>\n<li>\tAdd/Substract Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Minutes</li>\n<li>\tAdd/Substract Seconds to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Seconds</li>\n<li>\tAdd/Substract Hours and Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours + Interval 2 Minutes</li>\n<li>\tSubstract Hours and Minutes from a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') - Interval 2 Hours - Interval 2 Minutes</li>\n</ul>\n<h4>Fetch Next Day and Last Day of Month</h4>\n<ul>\n<li>\tLast Day of a Month   \t\t\t\t      -> Example : LAST_DAY(CURRENT_DATE)</li>\n<li>\tNext Day value\t\t   \t\t\t\t        -> Example : NEXT_DAY(CURRENT_DATE, 'Sunday')</li>\n<li>\tFirst Day of Year/Month\t\t\t\t      -> Example : DATE_TRUNC('MONTH', CURRENT_DATE)</li>\n<li>\tYear/Month/Quarter/DayOfMonth value\t-> Example : YEAR(CURRENT_DATE)/MONTH(CURRENT_DATE)/QUARTER(CURRENT_DATE)/DAYOFMONTH(CURRENT_DATE)/DAYOFWEEK(CURRENT_DATE)</li>\n<li>\tDay/Week count of the Year\t\t\t    -> Example : DAYOFWEEK(CURRENT_DATE)/WEEKOFYEAR(CURRENT_DATE)</li>\n</ul>\n<h4>Date Difference functions</h4>\n<ul>\n<li>\tDate Diff between two Dates\t\t\t    -> Example : DATEDIFF(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Months between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Years between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy')) / 12</li>\n</ul>\n<h3>Regex Functions</h3>\n<br>\n<ul>\n<li>\tReplace using Regex\t\t-> Example : REGEXP_REPLACE(PRD_NAME, 'E', '#')</li>\n</ul>",
      "examples": "<h2>Expressions Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\n<h4>Expressions Node Configuration</h4>\n<br>\nExpressions node is configured to compute new columns as below:<br>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nNET_AMT                  |    LIST_PRICE + TAX_AMT - DISCOUNT<br>\nPRD_DETAILS              |    CONCAT(PRD_CD,':',PRD_NAME)<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutgoing Dataframe would be created as below with new columns added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    |    PRD_DETAILS<br>\n--------------------------------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0     |    P01:DRILL MACHINE<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0     |    P02:WEIGHING MACHINE<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0      |    P03:HAMMER<br>\n<br>\n<h4>Computing Current Date value using Expression:</h4>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nCURRENT_DATE_VAL         |    CURRENT_DATE<br>\nCURRENT_DATETIME_VAL     |    CURRENT_TIMESTAMP<br>\n<br>\nOutput would contain below value<br>\n<br>\nCURRENT_DATE_VAL         |    CURRENT_DATETIME_VAL<br>\n-----------------------------------------------------------------<br>\n2022-09-07               |    2022-09-07 10:05:12.432<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExpressions",
      "x": "831.887px",
      "y": "623.531px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "description",
          "value": "",
          "widget": "textfield",
          "title": "Description",
          "description": "Description to capture processing in this node",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"ss_sales_velocity\"]",
          "widget": "key_array",
          "title": "New Column Names",
          "description": "New Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "expressions",
          "value": "[\"daily_sales_units * min_lead_time\"]",
          "widget": "value_array",
          "title": "Expressions",
          "description": "Expressions to create new columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "54",
      "name": "Case When",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "690.419px",
      "y": "628.85px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "safety_stock1",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"min_expected_stock < ss_sales_velocity\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"min_expected_stock\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "ss_sales_velocity",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "55",
      "name": "Case When",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "552.412px",
      "y": "630.862px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "safety_stock2",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"replenishment_flag != 1\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"0\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "safety_stock1",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "56",
      "name": "Imputing With Constant",
      "description": "It imputes missing value with constant value. It fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.",
      "details": "This node imputes the missing value with constant value.<br>\n<br>\nIt fills missing values (None) in selected columns with given constant value for the corresponding column, in the incoming DataFrame.<br>",
      "examples": "Incoming Dataframe has following rows and [AGE] column has missing values / [NULL] for some rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |\t\t\t<br>\nCD04       |    MATT         |\t\t\t<br>\n<br>\nIf imputingwithconstatnt node is configured to Impute [AGE] with 45 then missing values in [AGE] column would be replaced with 45.<br>\nOutgoing Dataframe would result as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |    45\t\t\t<br>\nCD04       |    MATT         |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeReplaceMissingValueWithConstant",
      "x": "405.25px",
      "y": "622.667px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "colNames",
          "value": "[\"safety_stock2\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns to be processed for missing values",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "constants",
          "value": "[\"0\"]",
          "widget": "variables_list_textfield",
          "title": "Constants",
          "description": "Missing value will be replaced with constant",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "57",
      "name": "Case When",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "404.769px",
      "y": "782.194px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol",
          "value": "safety_stock3",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions",
          "value": "[\"safety_stock2=0\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"min_expected_stock\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse",
          "value": "safety_stock2",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "58",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "576.287px",
      "y": "775.894px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"store_id\",\"sku\",\"date\",\"product_category\",\"total_sales_units\",\"inventory_pipeline\",\"units_in_transit\",\"units_in_dc\",\"units_on_order\",\"units_under_promotion\",\"shelf_capacity\",\"promotion_flag\",\"replenishment_flag\",\"start_on_hand_units\",\"end_on_hand_units\",\"phantom_inventory_ind\",\"phantom_inventory\",\"on_hand_inventory_units\",\"replenishment_units\",\"estimated_on_hand_inventory\",\"prior_inventory\",\"rolling_stock_onhand\",\"rolling_min_expected_stock\",\"min_expected_stock\",\"daily_sales_units\",\"LEAD_TIME_IN_DC\",\"LEAD_TIME_IN_TRANSIT\",\"LEAD_TIME_ON_ORDER\",\"min_lead_time\",\"ss_sales_velocity\",\"safety_stock3\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "59",
      "name": "Columns Rename",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "723.287px",
      "y": "778.906px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentColNames",
          "value": "[\"safety_stock3\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "newColNames",
          "value": "[\"safety_stock\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "73",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "15px",
      "y": "32px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "bgColor",
          "value": "blue",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "width",
          "value": "406px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "height",
          "value": "175px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "comment",
          "value": "<p>This workflow computes below features</p><ul><li>Phantom Inventory - It denotes the gap between the Inventory and the Sales System. This might result due to the misplacement of Products, stolen, loss or issue with the Inventory Tracking system. </li><li>Safety Stock - It acts as the trigger point to order a product. </li></ul>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "110",
      "name": "Save CSV-Phantom Inventory",
      "description": "Saves the DataFrame into the specified location in CSV Format",
      "details": "This node saves incoming Dataframe into the specified location in CSV format.<br>",
      "examples": "path-folder1/folder2/filename<br>\n<br>\nthe file will be saved under the file name at the path provided<br>\nif folder is not present it will be created and save the file<br>\nif the file already exists selection in save mode determines what happens to the file,append-adds the file data to it overwrite-replaces the file altogether<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveCSV",
      "x": "1036.05px",
      "y": "4.375px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/CPG/CPG-On-Shelf-Availability/Phantom-Inventory",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the CSV files",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "112",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "831.25px",
      "y": "1.51875px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"date\",\"store_id\",\"sku\",\"replenishment_units\",\"daily_sales_units\",\"start_on_hand_units\",\"total_sales_units\",\"end_on_hand_units\",\"phantom_inventory\",\"phantom_inventory_ind\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "113",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "1246.52px",
      "y": "-1px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "bgColor",
          "value": "gray",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "width",
          "value": "527px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "height",
          "value": "103px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "comment",
          "value": "<p>Computing and Saving Phantom Inventory data</p><p><br></p><p>Phantom Inventory refers to the gap between Inventory and Sales System i.e. inaccurately tracked in Inventory System.</p><p>It may be caused due to misplaced, stolen or lost inventory items.</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "114",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "866.525px",
      "y": "781.925px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"store_id\",\"sku\",\"date\",\"product_category\",\"total_sales_units\",\"on_hand_inventory_units\",\"replenishment_units\",\"replenishment_flag\",\"phantom_inventory\",\"estimated_on_hand_inventory\",\"prior_inventory\",\"rolling_min_expected_stock\",\"min_expected_stock\",\"daily_sales_units\",\"safety_stock\",\"units_on_order\",\"units_in_transit\",\"units_in_dc\",\"LEAD_TIME_IN_DC\",\"LEAD_TIME_IN_TRANSIT\",\"LEAD_TIME_ON_ORDER\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "115",
      "name": "Coalesce",
      "description": "This node coalesces the DataFrame into specified number of Partitions",
      "details": "This node coalesces the DataFrame into specified number of Partitions.<br>\n<br>\nIt is specially helpful for the case when too many small files are being created. In such a scenario, the Coalesce node can be used to limit the number of output files produced.<br>",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCoalesce",
      "x": "1159.71px",
      "y": "778.312px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "numPartitions",
          "value": "8",
          "widget": "textfield",
          "title": "Number of Partitions",
          "description": "input for number of partitions",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "116",
      "name": "Save CSV-Safety Stock",
      "description": "Saves the DataFrame into the specified location in CSV Format",
      "details": "This node saves incoming Dataframe into the specified location in CSV format.<br>",
      "examples": "path-folder1/folder2/filename<br>\n<br>\nthe file will be saved under the file name at the path provided<br>\nif folder is not present it will be created and save the file<br>\nif the file already exists selection in save mode determines what happens to the file,append-adds the file data to it overwrite-replaces the file altogether<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveCSV",
      "x": "1307.91px",
      "y": "777.3px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/CPG/CPG-On-Shelf-Availability/Safety-Stock",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the CSV files",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "117",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "1612.4px",
      "y": "110.187px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "bgColor",
          "value": "gray",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "width",
          "value": "267px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "height",
          "value": "81px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "comment",
          "value": "<p>Computing Estimated On-Hand Inventory Units</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "118",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "1570.79px",
      "y": "246.594px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "bgColor",
          "value": "gray",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "width",
          "value": "250px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "height",
          "value": "67px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "comment",
          "value": "<p>Computing Average Daily Sales</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "119",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "138.8px",
      "y": "373.8px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "bgColor",
          "value": "gray",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "width",
          "value": "252px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "height",
          "value": "74px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "comment",
          "value": "<p>Computing Shortest Lead Time for Each Store-SKU</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "120",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "1229.91px",
      "y": "640.106px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "bgColor",
          "value": "gray",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "width",
          "value": "272px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "height",
          "value": "75px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "comment",
          "value": "<p>Saving Safety Stock information</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "121",
      "name": "Cast To Single Type",
      "description": "This node creates a new DataFrame by casting the specified input columns to a new data type",
      "details": "This node creates a new DataFrame by casting the specified input columns to a new data type. All the selected columns would be cast to the specified data type.<br>\n<br>\nThe boolean field Replace Existing Columns indicates whether the existing column should be replaced or a new column should be created.<br>",
      "examples": "If incoming Dataframe has following columns with below specified datatype:<br>\n<br>\n<ul>\n<li> CUST_ID : Integer</li>\n<li> CUST_NAME : String</li>\n<li> DOB : Datetime</li>\n<li> AGE : Integer</li>\n</ul>\nand [DOB] and [AGE] are selected for casting to [STRING] datatype then outgoing Dataframe would have below datatypes:<br>\n<br>\n<ul>\n<li> CUST_ID : Integer</li>\n<li> CUST_NAME : String</li>\n<li> DOB : String</li>\n<li> AGE : String</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCastColumnType",
      "x": "1022.53px",
      "y": "781.512px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "inputCols",
          "value": "[\"safety_stock\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be cast to new data type",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColType",
          "value": "INTEGER",
          "widget": "array",
          "title": "New Data Type",
          "description": "New data type for the selected columns (INTEGER, DOUBLE, STRING, LONG, SHORT)",
          "optionsArray": [
            "BOOLEAN",
            "BYTE",
            "DATE",
            "DECIMAL",
            "DOUBLE",
            "FLOAT",
            "INTEGER",
            "LONG",
            "SHORT",
            "STRING",
            "TIMESTAMP"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "replaceExistingCols",
          "value": "true",
          "widget": "array",
          "title": "Replace Existing Cols?",
          "description": "Whether to replace existing columns or create new ones?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "122",
      "name": "Coalesce",
      "description": "This node coalesces the DataFrame into specified number of Partitions",
      "details": "This node coalesces the DataFrame into specified number of Partitions.<br>\n<br>\nIt is specially helpful for the case when too many small files are being created. In such a scenario, the Coalesce node can be used to limit the number of output files produced.<br>",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCoalesce",
      "x": "947px",
      "y": "18px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "numPartitions",
          "value": "1",
          "widget": "textfield",
          "title": "Number of Partitions",
          "description": "input for number of partitions",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "4",
      "target": "5",
      "id": 1
    },
    {
      "source": "1",
      "target": "6",
      "id": 2
    },
    {
      "source": "6",
      "target": "8",
      "id": 3
    },
    {
      "source": "8",
      "target": "10",
      "id": 4
    },
    {
      "source": "10",
      "target": "13",
      "id": 5
    },
    {
      "source": "13",
      "target": "14",
      "id": 6
    },
    {
      "source": "14",
      "target": "15",
      "id": 7
    },
    {
      "source": "15",
      "target": "16",
      "id": 8
    },
    {
      "source": "16",
      "target": "17",
      "id": 9
    },
    {
      "source": "17",
      "target": "18",
      "id": 10
    },
    {
      "source": "18",
      "target": "19",
      "id": 11
    },
    {
      "source": "19",
      "target": "20",
      "id": 12
    },
    {
      "source": "20",
      "target": "21",
      "id": 13
    },
    {
      "source": "21",
      "target": "23",
      "id": 14
    },
    {
      "source": "23",
      "target": "25",
      "id": 15
    },
    {
      "source": "25",
      "target": "26",
      "id": 16
    },
    {
      "source": "26",
      "target": "27",
      "id": 17
    },
    {
      "source": "27",
      "target": "28",
      "id": 18
    },
    {
      "source": "28",
      "target": "29",
      "id": 19
    },
    {
      "source": "29",
      "target": "30",
      "id": 20
    },
    {
      "source": "30",
      "target": "31",
      "id": 21
    },
    {
      "source": "31",
      "target": "32",
      "id": 22
    },
    {
      "source": "32",
      "target": "33",
      "id": 23
    },
    {
      "source": "33",
      "target": "34",
      "id": 24
    },
    {
      "source": "34",
      "target": "36",
      "id": 25
    },
    {
      "source": "36",
      "target": "37",
      "id": 26
    },
    {
      "source": "37",
      "target": "38",
      "id": 27
    },
    {
      "source": "38",
      "target": "39",
      "id": 28
    },
    {
      "source": "39",
      "target": "40",
      "id": 29
    },
    {
      "source": "40",
      "target": "41",
      "id": 30
    },
    {
      "source": "41",
      "target": "42",
      "id": 31
    },
    {
      "source": "42",
      "target": "43",
      "id": 32
    },
    {
      "source": "43",
      "target": "44",
      "id": 33
    },
    {
      "source": "5",
      "target": "45",
      "id": 34
    },
    {
      "source": "45",
      "target": "46",
      "id": 35
    },
    {
      "source": "44",
      "target": "50",
      "id": 36
    },
    {
      "source": "46",
      "target": "50",
      "id": 37
    },
    {
      "source": "50",
      "target": "51",
      "id": 38
    },
    {
      "source": "51",
      "target": "52",
      "id": 39
    },
    {
      "source": "52",
      "target": "53",
      "id": 40
    },
    {
      "source": "53",
      "target": "54",
      "id": 41
    },
    {
      "source": "54",
      "target": "55",
      "id": 42
    },
    {
      "source": "55",
      "target": "56",
      "id": 43
    },
    {
      "source": "56",
      "target": "57",
      "id": 44
    },
    {
      "source": "57",
      "target": "58",
      "id": 45
    },
    {
      "source": "58",
      "target": "59",
      "id": 46
    },
    {
      "source": "15",
      "target": "112",
      "id": 47
    },
    {
      "source": "59",
      "target": "114",
      "id": 48
    },
    {
      "source": "115",
      "target": "116",
      "id": 49
    },
    {
      "source": "114",
      "target": "121",
      "id": 50
    },
    {
      "source": "121",
      "target": "115",
      "id": 51
    },
    {
      "source": "112",
      "target": "122",
      "id": 52
    },
    {
      "source": "122",
      "target": "110",
      "id": 53
    }
  ],
  "dataSetDetails": [],
  "engine": "scala"
}