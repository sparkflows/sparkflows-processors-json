{
  "name": "User-Document-Query",
  "uuid": "e69756e0-e8a2-4e2c-b3cd-b7c8b8bbaf37",
  "category": "-",
  "description": "-",
  "parameters": "--var getStarted=true --var destinationPath1=data/BFSI/ComplianceAI-Document-Query/Master-Document/ --var read=false --var refresh=false --var checkbox1=false --var view1=false --var back12=false --var destinationPathuser=/home/sparkflows/fire-data/data/BFSI/ComplianceAI-Document-Query/User-Document/V2 ABC Bank - Anti-Money Laundering (AML) Policy Document - 2025.docx --var read=true --var translates=true",
  "nodes": [
    {
      "id": "1",
      "name": "Document To Text",
      "iconImage": "/images/icons/node-icon/PDF.svg",
      "description": "The DocumentToText node extracts text content from documents, including PDF, TXT, DOCX, and image files, located in a specified file path or directory. It processes either a single file or an entire directory, producing a structured DataFrame with columns for the extracted text, file name, page numbers, and optionally, base64-encoded data for PDFs and images.",
      "details": "<h2>DocumentToText Node Details</h2><br>\nThe DocumentToText node extracts text content from documents, including PDF, DOCX, and image files, located in a specified file path or directory. It processes either a single file or an entire directory, producing a structured DataFrame with columns for the extracted text, file name, page numbers, and optionally, base64-encoded data for PDFs and images.<br>\n<br>\n<br>\n<h4>General:</h4><br>\n<br>\n<h5>Directory/File Path:</h5> Specifies the path to a single document file or a directory containing multiple documents. This field is required and must be accessible to the PySpark engine.<br>\n<br>\n<h5>Document Type:</h5> Selects the types of documents to process. Options include:<br>\n<br>\n<ul>\n<li> pdf: Processes PDF files, extracting text and optionally converting pages to base64-encoded images.</li>\n<li> docx: Processes Microsoft Word documents, extracting text only.</li>\n<li> image: Processes image files (e.g., PNG, JPEG) for text extraction via OCR, with optional base64 encoding.</li>\n</ul>\nIf left empty, the node processes all supported file types (PDF, DOCX, and images) in the specified path.<br>\n<br>\n<br>\n<h5>Image Encoding:</h5> Determines whether to include a column with base64-encoded data for PDFs and images. Options are:<br>\n<ul>\n<li> true: Adds a column with base64-encoded representations of PDF pages and image files.</li>\n<li> false: Does not include base64-encoded data (default).</li>\n</ul>\nNote: TXT and DOCX files are not converted to base64 encodings, even if this option is enabled.<br>\n<br>\n<br>\n<h4>Recursive Processing:</h4><br>\n<h5>Recursive:</h5> Controls whether the node processes documents in subdirectories. Options are:<br>\n<ul>\n<li> true: Recursively processes all documents in the specified directory and its subdirectories.</li>\n<li> false: Processes only documents directly in the specified directory (default).</li>\n</ul>\n<br>\n<h4>Output Storage:</h4><br>\n<br>\n<h4>Output:</h4><br>\nThe node outputs a DataFrame with the following default columns:<br>\n<br>\n<ul>\n<li> fileName: The name of the source file.</li>\n<li> content: The extracted text content from the document.</li>\n<li> pageNumber:> The page number of the extracted content (for multi-page documents like PDFs; single-page documents like TXT, DOCX, and images use page number 1).</li>\n<li> If Image Encoding is set to true, a base64ImageData column is included for PDFs and images, containing base64-encoded representations of the pages or images. TXT and DOCX files will have null in this column.</li>\n</ul>",
      "examples": "<h2> Example: DocumentToText Node</h2>\n<br>\n<h3> Input:</h3>\nA directory /data/documents/ contains the following files:<br>\n- report.pdf (a 2-page PDF document)<br>\n- proposal.docx (a Microsoft Word document)<br>\n- chart.png (an image file with text)<br>\n<br>\nThe DocumentToText node is configured as follows:<br>\n<ul>\n<li> Directory/File Path: /data/documents/</li>\n<li> Document Type: [\"pdf\", \"docx\", \"image\"] (process all supported types)</li>\n<li> Image Encoding: true (includes base64-encoded data for PDFs and images)</li>\n<li> Recursive: false (processes only files in the specified directory)</li>\n</ul>\n<h3> Output:</h3>\nThe node processes the files and produces a DataFrame with the following structure:<br>\n<br>\nfileName       | content                              | pageNumber | base64ImageData<br>\n---------------|--------------------------------------|------------|----------------------------------<br>\nreport.pdf     | This is page 1 of the report...      | 1          | iVBORw0KGgoAAAANSUhEUg...<br>\nreport.pdf     | This is page 2 of the report...      | 2          | iVBORw0KGgoAAAANSUhEUg...<br>\nproposal.docx  | Proposal for new project...          | 1          | null<br>\nchart.png      | Sales: Q1 2025...                    | 1          | iVBORw0KGgoAAAANSUhEUg...<br>\n<br>\n<h3> Explanation:</h3>\n- The report.pdf file is processed, extracting text from both pages, resulting in two rows (one per page). With Image Encoding set to true, each page is also converted to a base64-encoded image in the base64ImageData column.<br>\n- The proposal.docx file is processed, extracting its text content into a single row. No base64 encoding is applied, so base64ImageData is null.<br>\n- The chart.png file is processed using OCR to extract text, and its base64-encoded image data is included in the base64ImageData column.<br>\n- Since Recursive is set to false, only files directly in /data/documents/ are processed.<br>",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeDocumentToText",
      "x": "309.187px",
      "y": "237.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "filePath",
          "value": "${destinationPathuser}",
          "widget": "textfield",
          "title": "Directory/File Path",
          "description": "Select a Pdf/Docx/Images File or Directory",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileType",
          "value": "",
          "widget": "array",
          "title": "Document Type",
          "description": "Choose a Document Type.If Empty all three types of files will be processed.",
          "optionsArray": [
            "pdf",
            "docx",
            "image"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "recursive",
          "value": "false",
          "widget": "array",
          "title": "Recursive",
          "description": "Recursively process the documents in the given Directory",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "isImage",
          "value": "false",
          "widget": "array",
          "title": "Image Encoding",
          "description": "Adds a column for base64 encoded pages",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "columns",
          "value": "",
          "widget": "tab",
          "title": "Rename Output Cols",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileNameCol",
          "value": "fileName",
          "widget": "textfield",
          "title": "File Name Column",
          "description": "Rename File Name Column. Defaults to fileName",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "contentCol",
          "value": "content",
          "widget": "textfield",
          "title": "Content Column",
          "description": "Rename Content Column. Defaults to content",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pageNumberCol",
          "value": "pageNumber",
          "widget": "textfield",
          "title": "Page Number Column",
          "description": "Rename Page Number Column. Defaults to pageNumber",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "base64ImageCol",
          "value": "base64ImageCol",
          "widget": "textfield",
          "title": "Base64 Image Column",
          "description": "Rename Image Column. Defaults to base64ImageCol",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "2",
      "name": " Multi LLM Query",
      "iconImage": "/images/icons/node-icon/Graph_group_by_column.svg",
      "description": "The Multi LLM Query node is designed to query multiple large language models (LLMs) from providers such as OpenAI, Bedrock, and Gemini, using a DataFrame as input. It processes user queries, text content, and/or base64-encoded images to generate responses based on the selected model and task, producing a structured DataFrame output.",
      "details": "<h2>Multi LLM Query Node Details</h2>\n<br>\nThe Multi LLM Query node is designed to query multiple large language models (LLMs) from providers such as OpenAI, Bedrock, and Gemini, using a DataFrame as input. It processes user queries, text content, and/or base64-encoded images to generate responses based on the selected connection and task, producing a structured DataFrame output.<br>\n<br>\n<h3>General:</h3>\n<br>\n<h4>Select Task:</h4>\nSpecifies the task to perform. Options include:<br>\n- summary: Generates a summary of the content in bullet points.<br>\n- translation: Translates the content to English.<br>\n- topic_extraction: Extracts key topics from the content.<br>\n- other: Allows for a custom task defined by the user.<br>\n<br>\n<h4>Prompt:</h4>\nAllows users to provide a custom prompt / instructions for the selected task.<br>\n<br>\n<h4>Content Column:</h4>\nSpecifies the DataFrame column containing the text content to be processed. Required for text or text+image modes.<br>\n<br>\n<h4>Select Connection:</h4>\nSpecifies the connection details for the selected LLM provider (e.g., API keys for OpenAI/Gemini, AWS credentials for Bedrock). Required to authenticate and access the respective model.<br>\n<br>\n<h4>Temperature:</h4>\nControls the randomness of the LLM's output. Default is 0.7. Higher values increase creativity, while lower values ensure more deterministic responses.<br>\n<br>\n<h4>Image Column:</h4>\nSpecifies the DataFrame column containing base64-encoded images. Required for image or text+image modes.<br>\n<br>\n<h4>Mode Selection:</h4>\nDetermines the input mode for the LLM. Options are:<br>\n- text: Processes text-only input from the content column or custom prompt.<br>\n- image: Processes base64-encoded images from the image column.<br>\n- text+image: Processes both text and base64-encoded images.<br>\n<br>\n<h4>Timeout (seconds):</h4>\nSpecifies the maximum time (in seconds) to wait for the model response. Visible when OpenAI or Gemini is selected.<br>\n<br>\n<h4>Thinking Budget:</h4>\nControls the computational budget (e.g., steps or tokens) for Gemini models. Only visible when Gemini is selected.<br>\n<br>\n<h3>Advanced:</h3>\n<br>\n<h4>Aggregate Response:</h4>\nSpecifies how to aggregate input data before processing. Options are:<br>\n- none: Processes each row individually, retaining fileName and pageNumber (if provided).<br>\n- all: Aggregates all rows into a single response.<br>\n- perfile: Aggregates rows by fileName, producing one response per file.<br>\n<br>\n<h4>Number of Partitions:</h4>\nSpecifies the number of Spark partitions for distributed processing. Default is 3.<br>\n<br>\n<h4>File Name Column:</h4>\nSpecifies the DataFrame column containing file names. Required for perfile aggregation mode.<br>\n<br>\n<h4>Page Number Column:</h4>\nSpecifies the DataFrame column containing page numbers (e.g., for PDFs). Optional, used for row-wise processing with none aggregation mode.<br>\n<br>\n<h3>Output:</h3>\nThe node outputs a DataFrame with columns based on the aggregation mode:<br>\n- none: Includes fileName (if provided), pageNumber (if provided), and response.<br>\n- perfile: Includes fileName and response.<br>\n- all: Includes only the response column.<br>\nThe response column contains the LLM-generated text or error messages if the API call fails.<br>",
      "examples": "<h2>Multi LLM Query Node Examples</h2>\n<br>\n<h3>Input:</h3>\nA DataFrame contains the following data:<br>\n- fileName: [\"doc1.pdf\", \"doc1.pdf\", \"doc2.pdf\"]<br>\n- pageNumber: [\"1\", \"2\", null]<br>\n- content: [\"Article about climate change...\", \"Climate change impacts...\", \"Renewable energy report...\"]<br>\n- imageBase64: [null, \"iVBORw0KGgoAAAANSUhEUg...\", null]<br>\n<br>\nThe Multi LLM Query node is configured as follows:<br>\n- Select Task: summary<br>\n- Prompt: \"Summarize the content in bullet points.\"<br>\n- Content Column: content<br>\n- Select Connection: Configured with valid OpenAI API key<br>\n- Temperature: 0.7<br>\n- Timeout (seconds): 90<br>\n- Image Column: imageBase64<br>\n- Mode Selection: text+image<br>\n- Aggregate Response: perfile<br>\n- Number of Partitions: 3<br>\n- File Name Column: fileName<br>\n- Page Number Column: pageNumber<br>\n<br>\n<h3>Output:</h3>\nThe node processes the DataFrame and produces a DataFrame with the following structure:<br>\n- fileName: doc1.pdf<br>\nresponse:<br>\n- Climate change effects on ecosystems<br>\n- Rising temperatures<br>\n<br>\n- fileName: doc2.pdf<br>\nresponse:<br>\n- Renewable energy advancements<br>\n- Solar and wind adoption<br>",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeMultiLLMQuery",
      "x": "427.125px",
      "y": "224.15px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "llmConnection",
          "value": "openai-api-connection",
          "widget": "object_array",
          "title": "Select Connection",
          "description": "Select Connection",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "temperature",
          "value": "0",
          "widget": "textfield",
          "title": "Temperature",
          "description": "Temperature setting for the model (default: 0).",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "contentCol",
          "value": "content",
          "widget": "variable",
          "title": "Content Column",
          "description": "Column name for the text content.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "imageCol",
          "value": "",
          "widget": "variable",
          "title": "Image Column",
          "description": "Column name for the base 64 image.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputMode",
          "value": "text",
          "widget": "array",
          "title": "Mode Selection",
          "description": "Select the model to use (text, image, text+image).",
          "optionsArray": [
            "text",
            "image",
            "text+image"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Prompt",
          "value": "",
          "widget": "tab",
          "title": "Prompt",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "task",
          "value": "other",
          "widget": "key_value_array",
          "title": "Select Prompt",
          "description": "Specify the task to perform: summary, translation, topic extraction, or other.",
          "optionsMap": {
            "summary": "Generate a concise, multi-level bullet-point summary capturing key facts, insights, and implications from the content. Preserve structure and section hierarchy.",
            "translation": "Translate the content into fluent, formal English while preserving tone, context, cultural nuances, and domain-specific terminology (e.g., legal, medical, technical).",
            "topic_extraction": "Identify and extract key topics, subtopics, and entities. Categorize them with tags (e.g., Person, Location, Concept) and provide brief descriptions or summaries of each.",
            "other": ""
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "customPrompt",
          "value": "You are an expert compliance auditor specializing in Indian banking regulations. Your task is to perform a detailed analysis of an internal bank policy document against a specific checklist of mandatory RBI rules.\n\n\nYou must be meticulous and base your findings exclusively on the content of the provided internal document.\n\n\n**Here is the full internal document you must analyze:**\n---\n[DEVELOPER: PASTE THE ENTIRE TEXT OF THE USER-UPLOADED DOCUMENT HERE]\n---\n\n\n**Here is the checklist of compliance rules you must verify:**\n---\n[\n  {\n    \"id\": \"RISK-01\",\n    \"category\": \"Risk Categorisation\",\n    \"question\": \"Does the policy explicitly mandate a three-tier risk categorization system of 'low', 'medium', and 'high' for all customers?\"\n  },\n  {\n    \"id\": \"RISK-02\",\n    \"category\": \"Risk Assessment\",\n    \"question\": \"Does the policy require a process for identifying and assessing ML/TF risks associated with new products or new technologies before they are launched?\"\n  },\n  {\n    \"id\": \"CDD-01\",\n    \"category\": \"Customer Due Diligence\",\n    \"question\": \"Does the policy clearly state that the full Customer Due Diligence (CDD) process must be completed *before* an account is opened or a relationship is established?\"\n  },\n  {\n    \"id\": \"ONGOING-01\",\n    \"category\": \"Ongoing Due Diligence\",\n    \"question\": \"Does the policy specify the exact periodic KYC update timelines of 2, 8, and 10 years for high, medium, and low-risk customers respectively?\"\n  },\n  {\n    \"id\": \"MONITOR-01\",\n    \"category\": \"Transaction Monitoring\",\n    \"question\": \"Does the policy require that a robust software system be used to generate alerts for transactions that are inconsistent with a customer's profile?\"\n  },\n  {\n    \"id\": \"REPORT-01\",\n    \"category\": \"Reporting Requirements\",\n    \"question\": \"Does the policy explicitly state that suspicious transactions must be reported to the Financial Intelligence Unit-India (FIU-IND)?\"\n  },\n  {\n    \"id\": \"COMP-01\",\n    \"category\": \"Compliance Structure\",\n    \"question\": \"Does the policy require that a concurrent or internal audit system be implemented to verify compliance with KYC/AML policies?\"\n  }\n]\n---\n\n\n**Your Task:**\nCarefully read the internal document and analyze it against each rule in the checklist. Then, generate a response in the format of a single, valid JSON object.\n\n\nThe JSON object must have two top-level keys: \"overall_assessment\" and \"findings\".\n\n\n1.  **\"overall_assessment\"**: A brief, one-sentence summary of the document's compliance level.\n2.  **\"findings\"**: An array of JSON objects, where each object corresponds to one rule from the checklist and contains the following keys:\n    *   **\"id\"**: The ID of the rule from the checklist (e.g., \"RISK-01\").\n    *   **\"category\"**: The category of the rule from the checklist.\n    *   **\"status\"**: Your one-word assessment. Must be one of: \"Compliant\", \"Non-Compliant\", or \"Needs Improvement\".\n    *   **\"finding\"**: A concise, one-sentence explanation of why you chose that status.\n    *   **\"evidence\"**: The EXACT quote from the internal document that supports your finding. If no evidence is found, state \"No specific evidence found in the document.\"\n    *   **\"recommendation\"**: A short, actionable step the bank should take to fix the compliance gap, if any.\n\n\nDo not include any other text, explanations, or markdown formatting outside of the final JSON object.",
          "widget": "textareafield",
          "title": "Prompt",
          "description": "Custom prompt to override the default instructions.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "userQueryCol",
          "value": "",
          "widget": "variable",
          "title": "User Query Column",
          "description": "Column name for user query, (if the query is in a column)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateMode",
          "value": "ALL",
          "widget": "enum",
          "title": "Aggregate Response",
          "optionsMap": {
            "NONE": "Do not aggregate rows",
            "ALL": "Aggregate all rows",
            "PERFILE": "Aggregate per file"
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "numPartitions",
          "value": "0",
          "widget": "textfield",
          "title": "Number of Partitions",
          "description": "Number of Partitions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileNameCol",
          "value": "",
          "widget": "variable",
          "title": "File Name Column",
          "description": "Select File Name Column",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pageNumberCol",
          "value": "",
          "widget": "variable",
          "title": "Page Number Column",
          "description": " Select Page Number column.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "timeout",
          "value": "180",
          "widget": "textfield",
          "title": "Timeout (seconds)",
          "description": "Maximum time to wait for Openai and Gemini API response",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "thinkingBudget",
          "value": "-1",
          "widget": "textfield",
          "title": "Thinking Budget",
          "description": "Configure the Gemini thinking budget by specifying the number of tokens to allocate for thinking. For Flash and Flash Lite models, values can range from 0 to 24,576 or -1 for dynamic thinking. For 2.5 Pro model, values must be between 1 and 24,576; setting 0 is not allowed.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "3",
      "name": "Output Formatter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node formats output from Columns.",
      "details": "<h2> Output Formatter Node Details</h2>\nThe Output Formatter node formats data from a specified column in an input DataFrame and outputs it with a user-defined key. It is designed for use in PySpark-based data processing pipelines to extract and present data in a structured format, typically for downstream use or display. The node processes a single column from the input DataFrame, formats the content, and sends it as a JSON message with a specified key.<br>\n<br>\n<h4> General:</h4>\n<br>\nh5: Select Column:<br>\nSpecifies the column in the input DataFrame from which to extract data. This field is required and must correspond to a valid column name in the DataFrame.<br>\n<br>\nh5: Key:<br>\nDefines a key name for the formatted output. This field is required and is used to label the extracted column value in the output JSON message.<br>\n<br>\n<h4> Output:</h4>\nThe node does not modify the input DataFrame but instead generates a JSON-formatted message containing the following:<br>\n<ul>\n<li> id: The node’s ID.</li>\n<li> name: The node’s name (\"Output Formatter\").</li>\n<li> title: The display title (\"Output Formatter\").</li>\n<li> type: The node type (\"formatter\").</li>\n<li> resultType: Set to 3, indicating the output is a formatted message.</li>\n<li> visibility: Set to \"EXPANDED\" for display purposes.</li>\n<li> text: A nested structure containing:</li>\n<li> key: The user-specified key name.</li>\n<li> string: The value extracted from the selected column (from the first row of the DataFrame).</li>\n<li> format: Set to \"plaintext\" for the output format.</li>\n</ul>\nThe JSON message is sent to the workflow context for further processing or display. The input DataFrame is passed through unchanged as the node’s output schema.<br>",
      "examples": "<h2> Example: Output Formatter Node</h2>\n<br>\n<h3> Input:</h3>\nA DataFrame with the following structure, containing a single row of data:<br>\n<br>\n| summary_text                     |<br>\n|----------------------------------|<br>\n| Project meeting: Plan Q1 goals...|<br>\n<br>\nThe Output Formatter node is configured as follows:<br>\n<ul>\n<li> Select Column: summary_text</li>\n<li> Key: meeting_summary</li>\n</ul>\n<h3> Output:</h3>\nThe node processes the DataFrame and generates a JSON-formatted message sent to the workflow context, with the following structure:<br>\n<br>\n```json<br>\n{<br>\n\"id\": \"11\",<br>\n\"name\": \"Output Formatter\",<br>\n\"title\": \"Output Formatter\",<br>\n\"type\": \"formatter\",<br>\n\"resultType\": 3,<br>\n\"visibility\": \"EXPANDED\",<br>\n\"text\": {<br>\n\"key\": \"meeting_summary\",<br>\n\"string\": \"Project meeting: Plan Q1 goals...\",<br>\n\"format\": \"plaintext\"<br>\n}<br>\n}<br>\n```<br>\n<br>\nThe input DataFrame is passed through unchanged as the node’s output schema.<br>\n<br>\n<h3> Explanation:</h3>\n<ul>\n<li> The summary_text column is selected, and the value from its first row (\"Project meeting: Plan Q1 goals...\") is extracted.</li>\n<li> The key field is set to \"meeting_summary\", which is used to label the extracted value in the output JSON.</li>\n<li> The node formats the extracted value into a JSON message with a nested text object, specifying the key, string value, and format (\"plaintext\").</li>\n<li> The JSON message is sent to the workflow context for further processing or display.</li>\n<li> The original DataFrame is returned as the output schema without modification.</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.graph.NodeOutputFormatter",
      "x": "608.194px",
      "y": "192.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "column",
          "value": "response",
          "widget": "variable",
          "title": " Select Column",
          "description": "Select Column to format",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "key",
          "value": "genAiResponse",
          "widget": "textfield",
          "title": "Key",
          "description": "Specify a key Name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "5",
      "name": "Save Parquet",
      "iconImage": "fa fa-tumblr-square",
      "description": "Saves the DataFrame into the specified location in Parquet Format. When running on Hadoop, it is saved onto HDFS.",
      "details": "<h2> Save Parquet Node Details</h2>\n<br>\nSaves the DataFrame into the specified location in Parquet Format. When running on Hadoop, it is saved onto HDFS.<br>\n<br>\n<h4> Parameters to be set:</h4>\nGeneral:<br>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> PATH : Specify the path of the Parquet file to be saved.</li>\n<li> SAVE MODE : Specify the save mode - Append, Overwrite, ErrorIfExists and Ignore.</li>\n</ul>\n<ul>\n<li> PARTITION COLUMN NAMES : Specify the columns to be used for partitioning the Parquet files.</li>\n</ul>",
      "examples": "<h2> Save Parquet Node Examples</h2>\n<br>\n<h4> Example of Values</h4>\nGeneral:<br>\n<ul>\n<li> PATH : /tmp/sample.parquet</li>\n<li> SAVE MODE : Append</li>\n</ul>\n<ul>\n<li> PARTITION COLUMN NAMES : col1,col2</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveParquet",
      "x": "499.187px",
      "y": "116.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "/home/sparkflows/fire-data/data/BFSI/ComplianceAI-Document-Query/Report",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the Parquet files",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "createDataset",
          "value": "false",
          "widget": "array_single",
          "title": "Auto create dataset",
          "description": "Select Models",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "datasetName",
          "value": "",
          "widget": "textfield",
          "wdgtCommon": "createDataset",
          "title": "Dataset Name",
          "description": "Dataset Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": "true"
        }
      ],
      "engine": "all"
    },
    {
      "id": "7",
      "name": "Parse JSON Col",
      "iconImage": "/images/icons/node-icon/JSON.svg",
      "description": "Parses JSON content in a given column",
      "details": "<h2> Parse JSON Column Node</h2>\n<br>\n<h4> Overview:</h4>\n<br>\nThe Parse JSON Column node parses a JSON column into individual columns. It's useful for extracting specific fields from JSON data.<br>\n<br>\n<h4> Input:</h4>\n<br>\nJSON Column Name: The name of the column containing the JSON data.<br>\nVariables: A table to define the JSON fields to extract and their corresponding data types.<br>\n<h4> Output:</h4>\n<br>\nThe node creates new columns for each specified JSON field, extracting the relevant data from the JSON column.<br>",
      "examples": "Example:<br>\n<br>\nLet's assume we have a column named json_data containing JSON data like this:<br>\n<br>\nJSON<br>\n{<br>\n  \"name\": \"John Doe\",<br>\n  \"age\": 30,<br>\n  \"city\": \"New York\"<br>\n}<br>\n<br>\nConfigure the Node:<br>\n<br>\nJSON Column Name: json_data<br>\nVariables:<br>\nInput Col: json_data<br>\nJSON Field Name: name<br>\nJSON Field Type: string<br>\nInput Col: json_data<br>\nJSON Field Name: age<br>\nJSON Field Type: integer<br>\nInput Col: json_data<br>\nJSON Field Name: city<br>\nJSON Field Type: string<br>\nNode Execution:<br>\n<br>\nThe node will create three new columns: name, age, and city, extracting the corresponding values from the json_data column.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeParseJSONColumn",
      "x": "485.381px",
      "y": "420.4px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "jsonColName",
          "value": "",
          "widget": "variable",
          "title": "JSON Col Name",
          "description": "Specifies the input column containing the JSON data",
          "datatypes": [
            "string"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCol",
          "value": "[]",
          "widget": "variables_list_select",
          "title": "Input Col",
          "description": "Input Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "jsonFieldNames",
          "value": "[]",
          "widget": "variables_list_textfield",
          "title": "JSON Field names",
          "description": "JSON Field names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "jsonFieldTypes",
          "value": "[]",
          "widget": "variables_list_array",
          "title": "JSON Field Type",
          "description": "Data Type of the JSON field",
          "optionsArray": [
            "STRING",
            "INTEGER",
            "DOUBLE",
            "FLOAT",
            "LONG",
            "BOOLEAN",
            "BYTE",
            "SHORT",
            "STRUCT",
            "ARRAY",
            "MAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "advance",
          "value": "",
          "widget": "tab",
          "title": "Advance",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "stringJsonColNames",
          "value": "[\"response\"]",
          "widget": "variables_list_select",
          "title": "String Json ColNames",
          "description": "Specifies the input column containing the JSON data",
          "datatypes": [
            "string"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputJsonColNames",
          "value": "[\"response_struct\"]",
          "widget": "variables_list_textfield",
          "title": "Output ColNames",
          "description": "uses the schema from the column you provide and create the new output column.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputSchema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"response\",\"response_struct\"]",
          "widget": "schema_col_names",
          "title": "Output Column Name",
          "description": "Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRUCT\"]",
          "widget": "schema_col_types",
          "title": "Output Column Type",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"{\\\"response_struct\\\":{\\\"fields\\\":[{\\\"metadata\\\":{},\\\"name\\\":\\\"findings\\\",\\\"nullable\\\":true,\\\"type\\\":{\\\"containsNull\\\":true,\\\"elementType\\\":{\\\"fields\\\":[{\\\"metadata\\\":{},\\\"name\\\":\\\"category\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"},{\\\"metadata\\\":{},\\\"name\\\":\\\"evidence\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"},{\\\"metadata\\\":{},\\\"name\\\":\\\"finding\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"},{\\\"metadata\\\":{},\\\"name\\\":\\\"id\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"},{\\\"metadata\\\":{},\\\"name\\\":\\\"recommendation\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"},{\\\"metadata\\\":{},\\\"name\\\":\\\"status\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"}],\\\"type\\\":\\\"struct\\\"},\\\"type\\\":\\\"array\\\"}},{\\\"metadata\\\":{},\\\"name\\\":\\\"overall_assessment\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"}],\\\"type\\\":\\\"struct\\\"}}\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Format",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "8",
      "name": "Flatten",
      "iconImage": "fa fa-tumblr-square",
      "description": "",
      "details": "",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFlatten",
      "x": "620.194px",
      "y": "416.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "ids",
          "value": "[\"00\"]",
          "widget": "flatten_ids",
          "title": "Id",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values1",
          "value": "[\"response_struct.findings\"]",
          "widget": "flatten_value1",
          "title": "Input Colums",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values2",
          "value": "[\"findings\"]",
          "widget": "flatten_value2",
          "title": "OutputColumns",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values3",
          "value": "[\"array\"]",
          "widget": "flatten_value3",
          "title": "OutputColumnsType",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "9",
      "name": "Explode",
      "iconImage": "fa fa-tumblr-square",
      "description": "Explode the array of values into multiple rows with columnname_explode.",
      "details": "<h2> Explode Node</h2>\n<br>\nThis node explodes a column containing arrays or maps into multiple rows, creating a new row for each element in the array or map. This is useful for flattening nested data structures.<br>",
      "examples": "<h2> Explode Node Example</h2>\n<br>\nGiven the following dataset:<br>\n<br>\nProductID\tProductName\tCategories<br>\nP1\tLaptop\t[\"Electronics\", \"Computers\"]<br>\nP2\tPhone\t[\"Electronics\", \"Mobile\"]<br>\n<br>\nIf we configure the Explode Node to explode the Categories column, the output would look like this:<br>\n<br>\nProductID\tProductName\tCategories<br>\nP1\tLaptop\tElectronics<br>\nP1\tLaptop\tComputers<br>\nP2\tPhone\tElectronics<br>\nP2\tPhone\tMobile<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExplode",
      "x": "762.2px",
      "y": "417.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"findings\"]",
          "widget": "variables",
          "title": "Input Colums",
          "description": "Select the columns to be exploded.",
          "datatypes": [
            "array"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "10",
      "name": "Flatten",
      "iconImage": "fa fa-tumblr-square",
      "description": "",
      "details": "",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFlatten",
      "x": "856.187px",
      "y": "398.194px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "ids",
          "value": "[\"03\",\"00\",\"05\",\"02\",\"01\",\"04\"]",
          "widget": "flatten_ids",
          "title": "Id",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values1",
          "value": "[\"findings_explode.id\",\"findings_explode.category\",\"findings_explode.status\",\"findings_explode.finding\",\"findings_explode.evidence\",\"findings_explode.recommendation\"]",
          "widget": "flatten_value1",
          "title": "Input Colums",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values2",
          "value": "[\"id\",\"category\",\"status\",\"finding\",\"evidence\",\"recommendation\"]",
          "widget": "flatten_value2",
          "title": "OutputColumns",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values3",
          "value": "[\"string\",\"string\",\"string\",\"string\",\"string\",\"string\"]",
          "widget": "flatten_value3",
          "title": "OutputColumnsType",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "11",
      "name": "Print N Rows",
      "iconImage": "/images/icons/node-icon/print_n_rows.svg",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "1166.96px",
      "y": "379.975px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "REPORT",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "n",
          "value": "1000",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "12",
      "name": "Drop Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by dropping the specified columns",
      "details": "<h2>Drop Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame by dropping the selected columns.<br>\n<br>\nIt drops the selected columns from the outgoing dataframe. <br>\n<br>\nColumns that need to be dropped are to be selected in the 'Selected' list. Multiple columns can be selected in the list that needs to be dropped.<br>",
      "examples": "<h2>Drop Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe having following columns:<br>\n<br>\n<ul>\n<li> CUST_CD</li>\n<li> CUST_NAME</li>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>\n<h4>Drop Columns Node Configuration And Output</h4>\n<br>\n[DOB] and [ADDRESS] columns are selected to be dropped from the outgoing Dataframe. <br>\nOutgoing dataframe would contain only below two columns after dropping the selected columns:<br>\n<br>\n<ul>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropColumns",
      "x": "958.562px",
      "y": "360.587px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropCols",
          "value": "[\"response\",\"response_struct\",\"findings\",\"findings_explode\",\"findings\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "The columns to be excluded from the output DataFrame",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "13",
      "name": "Split By Expression",
      "description": "This node splits the incoming DataFrame into two output DataFrames by applying the conditional logic",
      "details": "This node splits the incoming DataFrame into two output DataFrames by applying the conditional logic.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nCUST_CD   |   CUST_NAME   |   AGE   <br>\n------------------------------------<br>\nC01       |   MATT        |   50    <br>\nC02       |   LISA        |   45<br>\nC03       |   ROBIN       |   35<br>\nC04       |   MARCUS      |   30 <br>\n<br>\nIf SplitByExpression node is configured to split the incoming Dataframe into two Dataframes based on Expression [AGE > 40] <br>\nthen two outgoing Dataframes would be created as below:<br>\n<br>\n<h2>First Dataframe where [AGE] is greater than 40</h2>\n<br>\nCUST_CD   |   CUST_NAME   |   AGE   <br>\n------------------------------------<br>\nC01       |   MATT        |   50    <br>\nC02       |   LISA        |   45<br>\n<br>\n<h2>Second Dataframe where [AGE] is less than 40</h2>\n<br>\nCUST_CD   |   CUST_NAME   |   AGE   <br>\n------------------------------------<br>\nC03       |   ROBIN       |   35<br>\nC04       |   MARCUS      |   30<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSplitByExpression",
      "x": "991.2px",
      "y": "225.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "conditionExpr",
          "value": "status!='Compliant'",
          "widget": "textfield",
          "title": "Conditional Expression to split the Data on",
          "description": "Conditional Expression to be used for Splitting the DataFrame into two. DataFrame which matches the condition will go to the lower edge output. The other would go to the higher edge output.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": true,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "14",
      "name": "Print N Rows",
      "iconImage": "/images/icons/node-icon/print_n_rows.svg",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "1266.96px",
      "y": "389.975px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "REPORT",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "n",
          "value": "1000",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "1",
      "target": "2",
      "id": 1
    },
    {
      "source": "2",
      "target": "3",
      "id": 2
    },
    {
      "source": "2",
      "target": "5",
      "id": 3
    },
    {
      "source": "7",
      "target": "8",
      "id": 4
    },
    {
      "source": "8",
      "target": "9",
      "id": 5
    },
    {
      "source": "9",
      "target": "10",
      "id": 6
    },
    {
      "source": "10",
      "target": "12",
      "id": 7
    },
    {
      "source": "2",
      "target": "7",
      "id": 8
    },
    {
      "source": "12",
      "target": "13",
      "id": 9
    },
    {
      "source": "13",
      "target": "11",
      "id": 10
    },
    {
      "source": "13",
      "target": "14",
      "id": 11
    }
  ],
  "dataSetDetails": [],
  "engine": "pyspark"
}