{
  "name": "01-Data-Preparation",
  "uuid": "d5b59ec0-499f-4ec4-b0e0-ecca6d36cd1c",
  "category": "Data-Preparation",
  "parameters": "",
  "nodes": [
    {
      "id": "1",
      "name": "Read CSV",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>Refresh Schema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the refresh schema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "58.9667px",
      "y": "405.95px",
      "hint": "Refresh the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/HEALTHCARE/Healthcare-Payer-Payment-Rate-Classification/Raw-Data/Encounters.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Id\",\"START\",\"STOP\",\"PATIENT\",\"ORGANIZATION\",\"PROVIDER\",\"PAYER\",\"ENCOUNTERCLASS\",\"CODE\",\"DESCRIPTION\",\"BASE_ENCOUNTER_COST\",\"TOTAL_CLAIM_COST\",\"PAYER_COVERAGE\",\"REASONCODE\",\"REASONDESCRIPTION\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptions",
          "value": "",
          "widget": "tab",
          "title": "Extra Options",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Extra Options Keys",
          "description": "Extra options available when reading CSV files. Examples :\n comment --> # (ignore comment lines in the file)\nignoreLeadingWhiteSpace --> false (Ignores leading white spaces in string columns)\nignoreTrailingWhiteSpace --> false (Ignores trailing white spaces in string columns).\nfilterPushdown --> true (Enables filter pushdown to optimize query performance.)\nsamplingRatio --> 1.0 (Specifies the ratio of rows to sample when inferring schema.)\nignoreCorruptFiles --> false (Skips files with corrupt data instead of failing.)\nignoreMissingFiles --> false (Skips missing files instead of failing.)\npathGlobFilter --> *.csv (Filters file paths based on a specified glob pattern.)\nrecursiveFileLookup --> false (Enables recursive file lookup in directories.)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "Extra Options",
          "size": "100%"
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Extra Options Values",
          "description": "Config Values for the Corresponding keys",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "2",
      "name": "Read CSV",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>Refresh Schema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the refresh schema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "57.3px",
      "y": "631.3px",
      "hint": "Refresh the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/HEALTHCARE/Healthcare-Payer-Payment-Rate-Classification/Raw-Data/Observations.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"DATE\",\"PATIENT\",\"ENCOUNTER\",\"CATEGORY\",\"CODE\",\"DESCRIPTION\",\"VALUE\",\"UNITS\",\"TYPE\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptions",
          "value": "",
          "widget": "tab",
          "title": "Extra Options",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Extra Options Keys",
          "description": "Extra options available when reading CSV files. Examples :\n comment --> # (ignore comment lines in the file)\nignoreLeadingWhiteSpace --> false (Ignores leading white spaces in string columns)\nignoreTrailingWhiteSpace --> false (Ignores trailing white spaces in string columns).\nfilterPushdown --> true (Enables filter pushdown to optimize query performance.)\nsamplingRatio --> 1.0 (Specifies the ratio of rows to sample when inferring schema.)\nignoreCorruptFiles --> false (Skips files with corrupt data instead of failing.)\nignoreMissingFiles --> false (Skips missing files instead of failing.)\npathGlobFilter --> *.csv (Filters file paths based on a specified glob pattern.)\nrecursiveFileLookup --> false (Enables recursive file lookup in directories.)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "Extra Options",
          "size": "100%"
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Extra Options Values",
          "description": "Config Values for the Corresponding keys",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "3",
      "name": "Columns Rename",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "295px",
      "y": "390px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentColNames",
          "value": "[\"Id\",\"CODE\",\"DESCRIPTION\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "newColNames",
          "value": "[\"ENCOUNTER\",\"ENCOUNTER_CODE\",\"ENCOUNTER_DESCRIPTION\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "4",
      "name": "Join On Common Columns",
      "description": "This node joins the incoming dataframes on 1 or more columns",
      "details": "<h2>Join On Common Columns Node Details</h2>\n<br>\nThis node joins the incoming dataframes using one or more than one common column between the two dataframes. <br>\n<br>\nJoin Types supported by this node are as follows<br>\n<ul>\n<li> inner : The joined table will have records that have matching values in both tables.</li>\n<li> outer : The joined table contains either all the records from both the tables or fills in NULL values for missing matches on either side.</li>\n<li> left_outer  : Even if there are no matches in the right table it returns all the rows from the left table.</li>\n<li> right_outer : Even if there are no matches in the left table it returns all the rows from the right table.</li>\n<li> leftsemi : This gives only those rows in the left table that have a matching row in the right table.</li>\n</ul>\nThe `WHERE CLAUSE` section is used to filter any records once the two or more tables have  been joined.<br>",
      "examples": "<h2>Join On Common Columns Node Example</h2>\n<br>\n<h4> Incoming Dataframe</h4>\n<br>\n1st Incoming dataframe table1 has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO    <br>\n-------------------------------------------<br>\nE01       |    DAVID       |    10         <br>\nE02       |    JOHN        |    20      <br>\nE03       |    MARTIN      |    30  <br>\nE04       |    TONY        |    40  <br>\n<br>\n2nd Incoming dataframe table2 has the following rows:<br>\n<br>\nDEPT_NO    |      DEPT_NAME   |    LOC     |   EMP_CD <br>\n----------------------------------------------------<br>\n10         |      HR          |    IND     |   E01<br>\n20         |      SALES       |    AUS     |   E02<br>\n40         |      RESEARCH    |    NZ      |   E04<br>\n50         |      ADMIN       |    UK      |   E05<br>\n<br>\nSelected common columns for both the dataframes are following <br>\n<ul>\n<li> From table1 is DEPT_NO and EMP_CD</li>\n<li> From table2 is DEPT_NO and EMP_CD</li>\n</ul>\n<h4> When the JOIN condition is `inner` with a WHERE clause of `DEPT_NO = 10` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\n<br>\n<h4> When the JOIN condition is `inner` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\nE02       |    JOHN        |    20        |      SALES      |    AUS<br>\nE04       |    TONY        |    40        |      RESEARCH   |    NZ<br>\n<br>\n<h4> When the Joining condition `outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |              |    <br>\nE04       |    TONY        |    40        |   RESEARCH   |    NZ<br>\nE05       |                |    50        |   ADMIN      |    UK<br>\n<br>\n<h4> When the Joining condition is `left_outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |    <br>\n<br>\n<h4> When the Joining condition `right_outer` we have</h4>\n<h4> Final Output</h4>\n          <br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE04       |    MARTIN      |    30        |   RESEARCH   |    UK<br>\nE05       |                |    50        |   ADMIN      |    NZ<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingColumns",
      "x": "296.95px",
      "y": "628.95px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinCols",
          "value": "[\"PATIENT\",\"ENCOUNTER\"]",
          "widget": "variables_common",
          "title": "Common Join Columns",
          "description": "Space separated list of columns on which to join",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinType",
          "value": "inner",
          "widget": "array",
          "title": "Join Type",
          "description": "Type of Join",
          "optionsArray": [
            "inner",
            "outer",
            "left_outer",
            "right_outer",
            "leftsemi"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition after join function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"PATIENT\",\"ENCOUNTER\",\"DATE\",\"CATEGORY\",\"CODE\",\"DESCRIPTION\",\"VALUE\",\"UNITS\",\"TYPE\",\"START\",\"STOP\",\"ORGANIZATION\",\"PROVIDER\",\"PAYER\",\"ENCOUNTERCLASS\",\"CODE\",\"DESCRIPTION\",\"BASE_ENCOUNTER_COST\",\"TOTAL_CLAIM_COST\",\"PAYER_COVERAGE\",\"REASONCODE\",\"REASONDESCRIPTION\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "5",
      "name": "Print N Rows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "486.3px",
      "y": "628.3px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Row Values",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "6",
      "name": "Read CSV",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>Refresh Schema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the refresh schema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "64.9833px",
      "y": "260.017px",
      "hint": "Refresh the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/HEALTHCARE/Healthcare-Payer-Payment-Rate-Classification/Raw-Data/Patients.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Id\",\"BIRTHDATE\",\"DEATHDATE\",\"SSN\",\"DRIVERS\",\"PASSPORT\",\"PREFIX\",\"FIRST\",\"LAST\",\"SUFFIX\",\"MAIDEN\",\"MARITAL\",\"RACE\",\"ETHNICITY\",\"GENDER\",\"BIRTHPLACE\",\"ADDRESS\",\"CITY\",\"STATE\",\"COUNTY\",\"FIPS\",\"ZIP\",\"LAT\",\"LON\",\"HEALTHCARE_EXPENSES\",\"HEALTHCARE_COVERAGE\",\"INCOME\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptions",
          "value": "",
          "widget": "tab",
          "title": "Extra Options",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Extra Options Keys",
          "description": "Extra options available when reading CSV files. Examples :\n comment --> # (ignore comment lines in the file)\nignoreLeadingWhiteSpace --> false (Ignores leading white spaces in string columns)\nignoreTrailingWhiteSpace --> false (Ignores trailing white spaces in string columns).\nfilterPushdown --> true (Enables filter pushdown to optimize query performance.)\nsamplingRatio --> 1.0 (Specifies the ratio of rows to sample when inferring schema.)\nignoreCorruptFiles --> false (Skips files with corrupt data instead of failing.)\nignoreMissingFiles --> false (Skips missing files instead of failing.)\npathGlobFilter --> *.csv (Filters file paths based on a specified glob pattern.)\nrecursiveFileLookup --> false (Enables recursive file lookup in directories.)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "Extra Options",
          "size": "100%"
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Extra Options Values",
          "description": "Config Values for the Corresponding keys",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "7",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "304px",
      "y": "256px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"Id\",\"BIRTHDATE\",\"DEATHDATE\",\"RACE\",\"ETHNICITY\",\"GENDER\",\"MARITAL\",\"HEALTHCARE_EXPENSES\",\"HEALTHCARE_COVERAGE\",\"INCOME\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "8",
      "name": "Columns Rename",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "659.633px",
      "y": "256.633px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentColNames",
          "value": "[\"Id\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "newColNames",
          "value": "[\"PATIENT\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "9",
      "name": "Join On Common Columns",
      "description": "This node joins the incoming dataframes on 1 or more columns",
      "details": "<h2>Join On Common Columns Node Details</h2>\n<br>\nThis node joins the incoming dataframes using one or more than one common column between the two dataframes. <br>\n<br>\nJoin Types supported by this node are as follows<br>\n<ul>\n<li> inner : The joined table will have records that have matching values in both tables.</li>\n<li> outer : The joined table contains either all the records from both the tables or fills in NULL values for missing matches on either side.</li>\n<li> left_outer  : Even if there are no matches in the right table it returns all the rows from the left table.</li>\n<li> right_outer : Even if there are no matches in the left table it returns all the rows from the right table.</li>\n<li> leftsemi : This gives only those rows in the left table that have a matching row in the right table.</li>\n</ul>\nThe `WHERE CLAUSE` section is used to filter any records once the two or more tables have  been joined.<br>",
      "examples": "<h2>Join On Common Columns Node Example</h2>\n<br>\n<h4> Incoming Dataframe</h4>\n<br>\n1st Incoming dataframe table1 has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO    <br>\n-------------------------------------------<br>\nE01       |    DAVID       |    10         <br>\nE02       |    JOHN        |    20      <br>\nE03       |    MARTIN      |    30  <br>\nE04       |    TONY        |    40  <br>\n<br>\n2nd Incoming dataframe table2 has the following rows:<br>\n<br>\nDEPT_NO    |      DEPT_NAME   |    LOC     |   EMP_CD <br>\n----------------------------------------------------<br>\n10         |      HR          |    IND     |   E01<br>\n20         |      SALES       |    AUS     |   E02<br>\n40         |      RESEARCH    |    NZ      |   E04<br>\n50         |      ADMIN       |    UK      |   E05<br>\n<br>\nSelected common columns for both the dataframes are following <br>\n<ul>\n<li> From table1 is DEPT_NO and EMP_CD</li>\n<li> From table2 is DEPT_NO and EMP_CD</li>\n</ul>\n<h4> When the JOIN condition is `inner` with a WHERE clause of `DEPT_NO = 10` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\n<br>\n<h4> When the JOIN condition is `inner` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\nE02       |    JOHN        |    20        |      SALES      |    AUS<br>\nE04       |    TONY        |    40        |      RESEARCH   |    NZ<br>\n<br>\n<h4> When the Joining condition `outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |              |    <br>\nE04       |    TONY        |    40        |   RESEARCH   |    NZ<br>\nE05       |                |    50        |   ADMIN      |    UK<br>\n<br>\n<h4> When the Joining condition is `left_outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |    <br>\n<br>\n<h4> When the Joining condition `right_outer` we have</h4>\n<h4> Final Output</h4>\n          <br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE04       |    MARTIN      |    30        |   RESEARCH   |    UK<br>\nE05       |                |    50        |   ADMIN      |    NZ<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingColumns",
      "x": "660.317px",
      "y": "626.317px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinCols",
          "value": "[\"PATIENT\"]",
          "widget": "variables_common",
          "title": "Common Join Columns",
          "description": "Space separated list of columns on which to join",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinType",
          "value": "inner",
          "widget": "array",
          "title": "Join Type",
          "description": "Type of Join",
          "optionsArray": [
            "inner",
            "outer",
            "left_outer",
            "right_outer",
            "leftsemi"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition after join function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"PATIENT\",\"BIRTHDATE\",\"DEATHDATE\",\"RACE\",\"ETHNICITY\",\"GENDER\",\"MARITAL\",\"HEALTHCARE_EXPENSES\",\"HEALTHCARE_COVERAGE\",\"INCOME\",\"ENCOUNTER\",\"DATE\",\"CATEGORY\",\"CODE\",\"DESCRIPTION\",\"VALUE\",\"UNITS\",\"TYPE\",\"START\",\"STOP\",\"ORGANIZATION\",\"PROVIDER\",\"PAYER\",\"ENCOUNTERCLASS\",\"ENCOUNTER_CODE\",\"ENCOUNTER_DESCRIPTION\",\"BASE_ENCOUNTER_COST\",\"TOTAL_CLAIM_COST\",\"PAYER_COVERAGE\",\"REASONCODE\",\"REASONDESCRIPTION\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "10",
      "name": "Print N Rows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "917.95px",
      "y": "628.95px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Row Values",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "11",
      "name": "Read CSV",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>Refresh Schema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the refresh schema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "64.6167px",
      "y": "109.667px",
      "hint": "Refresh the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/HEALTHCARE/Healthcare-Payer-Payment-Rate-Classification/Raw-Data/Payers.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"Id\",\"NAME\",\"OWNERSHIP\",\"ADDRESS\",\"CITY\",\"STATE_HEADQUARTERED\",\"ZIP\",\"PHONE\",\"AMOUNT_COVERED\",\"AMOUNT_UNCOVERED\",\"REVENUE\",\"COVERED_ENCOUNTERS\",\"UNCOVERED_ENCOUNTERS\",\"COVERED_MEDICATIONS\",\"UNCOVERED_MEDICATIONS\",\"COVERED_PROCEDURES\",\"UNCOVERED_PROCEDURES\",\"COVERED_IMMUNIZATIONS\",\"UNCOVERED_IMMUNIZATIONS\",\"UNIQUE_CUSTOMERS\",\"QOLS_AVG\",\"MEMBER_MONTHS\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptions",
          "value": "",
          "widget": "tab",
          "title": "Extra Options",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Extra Options Keys",
          "description": "Extra options available when reading CSV files. Examples :\n comment --> # (ignore comment lines in the file)\nignoreLeadingWhiteSpace --> false (Ignores leading white spaces in string columns)\nignoreTrailingWhiteSpace --> false (Ignores trailing white spaces in string columns).\nfilterPushdown --> true (Enables filter pushdown to optimize query performance.)\nsamplingRatio --> 1.0 (Specifies the ratio of rows to sample when inferring schema.)\nignoreCorruptFiles --> false (Skips files with corrupt data instead of failing.)\nignoreMissingFiles --> false (Skips missing files instead of failing.)\npathGlobFilter --> *.csv (Filters file paths based on a specified glob pattern.)\nrecursiveFileLookup --> false (Enables recursive file lookup in directories.)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "Extra Options",
          "size": "100%"
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Extra Options Values",
          "description": "Config Values for the Corresponding keys",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "12",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "313.667px",
      "y": "109.667px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"Id\",\"NAME\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "13",
      "name": "Columns Rename",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "656.633px",
      "y": "104.633px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "currentColNames",
          "value": "[\"Id\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "newColNames",
          "value": "[\"PAYER\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "14",
      "name": "Join On Common Columns",
      "description": "This node joins the incoming dataframes on 1 or more columns",
      "details": "<h2>Join On Common Columns Node Details</h2>\n<br>\nThis node joins the incoming dataframes using one or more than one common column between the two dataframes. <br>\n<br>\nJoin Types supported by this node are as follows<br>\n<ul>\n<li> inner : The joined table will have records that have matching values in both tables.</li>\n<li> outer : The joined table contains either all the records from both the tables or fills in NULL values for missing matches on either side.</li>\n<li> left_outer  : Even if there are no matches in the right table it returns all the rows from the left table.</li>\n<li> right_outer : Even if there are no matches in the left table it returns all the rows from the right table.</li>\n<li> leftsemi : This gives only those rows in the left table that have a matching row in the right table.</li>\n</ul>\nThe `WHERE CLAUSE` section is used to filter any records once the two or more tables have  been joined.<br>",
      "examples": "<h2>Join On Common Columns Node Example</h2>\n<br>\n<h4> Incoming Dataframe</h4>\n<br>\n1st Incoming dataframe table1 has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO    <br>\n-------------------------------------------<br>\nE01       |    DAVID       |    10         <br>\nE02       |    JOHN        |    20      <br>\nE03       |    MARTIN      |    30  <br>\nE04       |    TONY        |    40  <br>\n<br>\n2nd Incoming dataframe table2 has the following rows:<br>\n<br>\nDEPT_NO    |      DEPT_NAME   |    LOC     |   EMP_CD <br>\n----------------------------------------------------<br>\n10         |      HR          |    IND     |   E01<br>\n20         |      SALES       |    AUS     |   E02<br>\n40         |      RESEARCH    |    NZ      |   E04<br>\n50         |      ADMIN       |    UK      |   E05<br>\n<br>\nSelected common columns for both the dataframes are following <br>\n<ul>\n<li> From table1 is DEPT_NO and EMP_CD</li>\n<li> From table2 is DEPT_NO and EMP_CD</li>\n</ul>\n<h4> When the JOIN condition is `inner` with a WHERE clause of `DEPT_NO = 10` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\n<br>\n<h4> When the JOIN condition is `inner` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC   <br>\n-------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\nE02       |    JOHN        |    20        |      SALES      |    AUS<br>\nE04       |    TONY        |    40        |      RESEARCH   |    NZ<br>\n<br>\n<h4> When the Joining condition `outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |              |    <br>\nE04       |    TONY        |    40        |   RESEARCH   |    NZ<br>\nE05       |                |    50        |   ADMIN      |    UK<br>\n<br>\n<h4> When the Joining condition is `left_outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |    <br>\n<br>\n<h4> When the Joining condition `right_outer` we have</h4>\n<h4> Final Output</h4>\n          <br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE04       |    MARTIN      |    30        |   RESEARCH   |    UK<br>\nE05       |                |    50        |   ADMIN      |    NZ<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingColumns",
      "x": "923.3px",
      "y": "386.267px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinCols",
          "value": "[\"PAYER\"]",
          "widget": "variables_common",
          "title": "Common Join Columns",
          "description": "Space separated list of columns on which to join",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "joinType",
          "value": "inner",
          "widget": "array",
          "title": "Join Type",
          "description": "Type of Join",
          "optionsArray": [
            "inner",
            "outer",
            "left_outer",
            "right_outer",
            "leftsemi"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition after join function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"PAYER\",\"NAME\",\"PATIENT\",\"BIRTHDATE\",\"DEATHDATE\",\"RACE\",\"ETHNICITY\",\"GENDER\",\"MARITAL\",\"HEALTHCARE_EXPENSES\",\"HEALTHCARE_COVERAGE\",\"INCOME\",\"ENCOUNTER\",\"DATE\",\"CATEGORY\",\"CODE\",\"DESCRIPTION\",\"VALUE\",\"UNITS\",\"TYPE\",\"START\",\"STOP\",\"ORGANIZATION\",\"PROVIDER\",\"ENCOUNTERCLASS\",\"ENCOUNTER_CODE\",\"ENCOUNTER_DESCRIPTION\",\"BASE_ENCOUNTER_COST\",\"TOTAL_CLAIM_COST\",\"PAYER_COVERAGE\",\"REASONCODE\",\"REASONDESCRIPTION\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "15",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "1144.17px",
      "y": "272.267px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"NAME\",\"PATIENT\",\"RACE\",\"ETHNICITY\",\"GENDER\",\"MARITAL\",\"HEALTHCARE_EXPENSES\",\"HEALTHCARE_COVERAGE\",\"INCOME\",\"CATEGORY\",\"ENCOUNTER_DESCRIPTION\",\"BASE_ENCOUNTER_COST\",\"TOTAL_CLAIM_COST\",\"PAYER_COVERAGE\",\"CHECKUP_DATE\",\"BIRTH_DATE\",\"DEATH_DATE\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "16",
      "name": "Print N Rows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "1689.92px",
      "y": "253.933px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Row Values",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "17",
      "name": "Drop Duplicate Rows",
      "description": "Drops duplicate rows from the incoming DataFrame. Specific columns can be selected to be used when comparing two rows",
      "details": "This node drops duplicate rows from the incoming DataFrame. <br>\n<br>\nSpecific columns can be selected to be used when comparing two rows.<br>\n<br>\nOne of the matching rows is included in the outgoing Dataframe.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE05       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    JOHN        |    MARKETING  |    40<br>\nE04       |    JOHN        |    MARKETING  |    45<br>\n<br>\n<h2> If DropDuplicateRows node is configured to drop duplicate rows having duplicate values in [EMP_NAME] and [DEPT] then outgoing dataframe would be created as below:</h2>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE01       |    DAVID       |    HR         |    25<br>\nE03       |    JOHN        |    MARKETING  |    40<br>\n<br>\n<h2> If DropDuplicateRows node is configured to drop duplicate rows having duplicate values in [EMP_NAME], [DEPT] and [AGE] then outgoing dataframe would be created as below:</h2>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    JOHN        |    MARKETING  |    40<br>\nE04       |    JOHN        |    MARKETING  |    45<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropDuplicateRows",
      "x": "1175.5px",
      "y": "484.633px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "colNames",
          "value": "[\"NAME\",\"PATIENT\",\"RACE\",\"ETHNICITY\",\"GENDER\",\"MARITAL\",\"HEALTHCARE_EXPENSES\",\"HEALTHCARE_COVERAGE\",\"INCOME\",\"CATEGORY\",\"ENCOUNTER_DESCRIPTION\",\"BASE_ENCOUNTER_COST\",\"TOTAL_CLAIM_COST\",\"PAYER_COVERAGE\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be used in determining if any two rows are duplication. No columns indicate to use all the available columns.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "18",
      "name": "String To Date",
      "description": "This node converts string columns to date using the specified date/time format",
      "details": "<h2>String To Date Multi Details</h2>\n<br>\nThis node converts a string column to a date or timestamp datatype column. This node can be used to convert multiple string columns to new Date or Timestmp columns. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select the String field(s) which needs to be converted.</li>\n<li>   INPUT COLUMN FORMATS :-The format of the input column is specified here.</li>\n<li>   OUTPUT COLUMN NAMES :- Specify the output column name for the converted value. </li>\n<li>   NEW DATA TYPES :- Select the output type as either of DATE or TIMESTAMP datatype.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li>   It will convert all the specified columns into the specified  datatype.</li>\n</ul>\n<h4>Example</h4>\n<ul>\n<li>   Input : 04/13/2019</li>\n<li>   Format : MM/dd/yyyy</li>\n<li>   NEW DATA TYPES : DATE</li>\n</ul>\n<br>\n<ul>\n<li>   Input : 04/13/2019</li>\n<li>   Format : MM/dd/yyyy</li>\n<li>   NEW DATA TYPES : TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Format Examples</h2>\n<br>\n<ul>\n<li> dd-MM-yy : 31-01-12</li>\n<li> dd-MM-yyyy : 31-01-2012</li>\n<li> MM-dd-yyyy : 01-31-2012</li>\n<li> yyyy-MM-dd : 2012-01-31</li>\n<li> yyyy-MM-dd HH:mm:ss : 2012-01-31 23:59:59</li>\n<li> yyyy-MM-dd HH:mm:ss.SSS : 2012-01-31 23:59:59.999</li>\n<li> yyyy-MM-dd HH:mm:ss.SSSZ : 2012-01-31 23:59:59.999+0100</li>\n<li> EEEEE MMMMM yyyy HH:mm:ss.SSSZ : Saturday November 2012 10:45:42.720+0100</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeMultiStringToDate",
      "x": "980.667px",
      "y": "100.65px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "inputColNames",
          "value": "[\"DATE\",\"BIRTHDATE\",\"DEATHDATE\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "inputColFormats",
          "value": "[\"yyyy-MM-dd\",\"yyyy-MM-dd\",\"yyyy-MM-dd\"]",
          "widget": "variables_list_textfield",
          "title": "Input Column Formats",
          "description": "Input Column Formats. eg: yyyy-MM-dd yyyy-MM-dd HH:mm:ss",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColNames",
          "value": "[\"CHECKUP_DATE\",\"BIRTH_DATE\",\"DEATH_DATE\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputColTypes",
          "value": "[\"DATE\",\"DATE\",\"DATE\"]",
          "widget": "variables_list_array",
          "title": "New Data Types",
          "description": "New data types (DATE, TIMESTAMP)",
          "optionsArray": [
            "DATE",
            "TIMESTAMP"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "19",
      "name": "Date Difference",
      "description": "This node finds difference between two dates",
      "details": "<h2>Date Difference Details</h2>\n<br>\nCalculates the difference between two given date/datetime columns.<br>\n<br>\n<h4>Input</h4>\n<ul>\n<li> FROMDATE :- The input column (i.e from which date) is selected here and it should be of Date\\TimeStump datatype. </li>\n<li> TODATE :- The input column (i.e upto which date) is selected here and it should be of Date\\TimeStump datatype.</li>\n<li> USECURRENTDATEASTOCOL :- When set to true, uses current Date as the 'TODATE' value </li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> Difference between the two date fields can be displayed in terms of days, hours, minutes and seconds.</li>\n<li> To enable the new column(s) set the value of the field as true ( By Default, it is set to false )</li>\n</ul>\n<h4>Example</h4>\n<ul>\n<li> Date Difference output when all fields are enabled as true. </li>\n</ul>",
      "examples": "<h2>Format Examples</h2>\n<br>\n<ul>\n<li> dd-MM-yy : 30-11-95 to 19-02-18 diff- 8608 days : 206609 hours : 12396574 min :\t743794461 : second</li>\n<li> dd-MM-yyyy : 10-02-1996 to 20-09-2017 diff- 8536 days : 204881 hours : 12292884 min :\t737573070 : second</li>\n<li> MM-dd-yyyy : 19-10-1994 to 06-12-2017 diff- 9015 days : 216377 hours : 12982644 min :\t778958670 : second</li>\n<li> yyyy-MM-dd : 1994-12-25 to 2019-01-16 diff- 8948 days : 214769 hours : 12886164 min :\t773169870 : second</li>\n<li> yyyy-MM-dd HH:mm:ss : 2012-01-31 23:59:59 to 2010-12-30 22:59:59 diff-397 days: 1 hour: 0 minutes : 0 seconds</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDateDiff",
      "x": "1368.67px",
      "y": "481.667px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "fromDate",
          "value": "BIRTH_DATE",
          "widget": "variable",
          "title": "FromDate",
          "description": "From date column name",
          "datatypes": [
            "timestamp",
            "date"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "toDate",
          "value": "CHECKUP_DATE",
          "widget": "variable",
          "title": "Todate",
          "description": "To date column name",
          "datatypes": [
            "timestamp",
            "date"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "useCurrentDateAsToDateCol",
          "value": "false",
          "widget": "array",
          "title": "Use Current Date As To Date",
          "description": "Current Date As ToDate",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "days",
          "value": "true",
          "widget": "array",
          "title": "Days",
          "description": "Days difference",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "hours",
          "value": "false",
          "widget": "array",
          "title": "Hours",
          "description": "Hours difference",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "minutes",
          "value": "false",
          "widget": "array",
          "title": "Minutes",
          "description": "Minutes difference",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "seconds",
          "value": "false",
          "widget": "array",
          "title": "Seconds",
          "description": "Seconds difference",
          "datatypes": [
            "boolean"
          ],
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "20",
      "name": "Select Columns",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "1566.5px",
      "y": "476.633px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"NAME\",\"PATIENT\",\"RACE\",\"ETHNICITY\",\"GENDER\",\"MARITAL\",\"HEALTHCARE_EXPENSES\",\"HEALTHCARE_COVERAGE\",\"INCOME\",\"CATEGORY\",\"ENCOUNTER_DESCRIPTION\",\"BASE_ENCOUNTER_COST\",\"TOTAL_CLAIM_COST\",\"PAYER_COVERAGE\",\"AGE\",\"PAYER_PAYMENT_RATE\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "21",
      "name": "Math Expression",
      "description": "Creates new columns using the specified expressions",
      "details": "<h2> Math Expression Details </h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the specified expression.<br>\n<br>\nNew columns can be computed using existing columns in the Dataframe.<br>\n<br>\nFollowing functions can be used in Expressions:<br>\n<br>\n<h4> Computations</h4>\n<ul>\n<li>\tComputation expression -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n</ul>\n<h4>Math Functions</h4>\n<ul>\n<li>\t abs :  Get the absolute value of an expression. Ex: abs(LIST_PRICE)</li>\n<li>\t pow :  Raises expr1 to the power of expr2. Ex: pow(LIST_PRICE, 2)</li>\n<li>\t cos :  Get the trigonometric cosine of an expression. Ex: cos(LIST_PRICE)</li>\n</ul>\nValid examples of Math functions - abs, acros, asin, atan, atan2, bin, cbrt, ceil, conv, cos, sosh, exp, expm1, factorial, floor, hex, hypot, log, log10, log1p, log2, pmod, pow, rint, round, shiftLeft, shiftRight, shiftRightUnsigned, signum, sin, sinh, sqrt, tan, tanh, toDegrees, toRadians, unhex (single choice)<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\nIf MathExpression node is configured to compute a new column [NET_AMT] based on expression [LIST_PRICE + TAX_AMT - DISCOUNT]<br>\nthen outgoing Dataframe would be created as below with new column added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    <br>\n------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeMathExpression",
      "x": "1449.25px",
      "y": "257.3px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCols",
          "value": "[\"AGE\",\"PAYER_PAYMENT_RATE\"]",
          "widget": "key_array",
          "title": "Output Column",
          "description": "Output Column Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "expressions",
          "value": "[\"DaysDiff/365\",\"(PAYER_COVERAGE/TOTAL_CLAIM_COST)*100\"]",
          "widget": "value_array",
          "title": "Math Expression",
          "description": "Define math expression.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "22",
      "name": "Coalesce",
      "description": "This node coalesces the DataFrame into specified number of Partitions",
      "details": "This node coalesces the DataFrame into specified number of Partitions.<br>\n<br>\nIt is specially helpful for the case when too many small files are being created. In such a scenario, the Coalesce node can be used to limit the number of output files produced.<br>",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCoalesce",
      "x": "1950.32px",
      "y": "473.267px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "numPartitions",
          "value": "1",
          "widget": "textfield",
          "title": "Number of Partitions",
          "description": "input for number of partitions",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "23",
      "name": "Save CSV",
      "description": "Saves the DataFrame into the specified location in CSV Format",
      "details": "This node saves incoming Dataframe into the specified location in CSV format.<br>",
      "examples": "path-folder1/folder2/filename<br>\n<br>\nthe file will be saved under the file name at the path provided<br>\nif folder is not present it will be created and save the file<br>\nif the file already exists selection in save mode determines what happens to the file,append-adds the file data to it overwrite-replaces the file altogether<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveCSV",
      "x": "1982px",
      "y": "638px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "path",
          "value": "data/HEALTHCARE/Healthcare-Payer-Payment-Rate-Classification/Payer-Data-Preparation/",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the CSV files",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "24",
      "name": "Case When Advanced",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhenMultiple",
      "x": "1736.67px",
      "y": "471.667px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol0",
          "value": "PAYER_PAYMENT_RATE_CLASS",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions0",
          "value": "[\"PAYER_PAYMENT_RATE>75.0\",\"PAYER_PAYMENT_RATE<25.0\"]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values0",
          "value": "[\"'75-100'\",\"'0-25'\"]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse0",
          "value": "'25-75'",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "caseWhen1",
          "value": "",
          "widget": "tab",
          "title": "CaseWhen1",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol1",
          "value": "",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions1",
          "value": "[]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values1",
          "value": "[]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse1",
          "value": "",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "caseWhen2",
          "value": "",
          "widget": "tab",
          "title": "CaseWhen2",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol2",
          "value": "",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions2",
          "value": "[]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values2",
          "value": "[]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse2",
          "value": "",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "caseWhen3",
          "value": "",
          "widget": "tab",
          "title": "CaseWhen3",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "outputCol3",
          "value": "",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "whenConditions3",
          "value": "[]",
          "widget": "key_array",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values3",
          "value": "[]",
          "widget": "value_array",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "finallyElse3",
          "value": "",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "scala"
    },
    {
      "id": "25",
      "name": "Print N Rows",
      "iconImage": "fa fa-tumblr-square",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "1937px",
      "y": "323px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Row Values",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "1",
      "target": "3",
      "id": 1
    },
    {
      "source": "2",
      "target": "4",
      "id": 2
    },
    {
      "source": "3",
      "target": "4",
      "id": 3
    },
    {
      "source": "4",
      "target": "5",
      "id": 4
    },
    {
      "source": "6",
      "target": "7",
      "id": 5
    },
    {
      "source": "7",
      "target": "8",
      "id": 6
    },
    {
      "source": "8",
      "target": "9",
      "id": 7
    },
    {
      "source": "5",
      "target": "9",
      "id": 8
    },
    {
      "source": "9",
      "target": "10",
      "id": 9
    },
    {
      "source": "11",
      "target": "12",
      "id": 10
    },
    {
      "source": "12",
      "target": "13",
      "id": 11
    },
    {
      "source": "13",
      "target": "14",
      "id": 12
    },
    {
      "source": "10",
      "target": "14",
      "id": 13
    },
    {
      "source": "15",
      "target": "17",
      "id": 14
    },
    {
      "source": "14",
      "target": "18",
      "id": 15
    },
    {
      "source": "18",
      "target": "15",
      "id": 16
    },
    {
      "source": "17",
      "target": "19",
      "id": 17
    },
    {
      "source": "19",
      "target": "21",
      "id": 18
    },
    {
      "source": "21",
      "target": "20",
      "id": 19
    },
    {
      "source": "20",
      "target": "16",
      "id": 20
    },
    {
      "source": "22",
      "target": "23",
      "id": 21
    },
    {
      "source": "16",
      "target": "24",
      "id": 22
    },
    {
      "source": "24",
      "target": "22",
      "id": 23
    },
    {
      "source": "24",
      "target": "25",
      "id": 24
    }
  ],
  "dataSetDetails": [],
  "engine": "scala"
}