{
  "name": "PySpark-Join-Flatten-Multiple-API-Json",
  "uuid": "93374d47-b040-4806-8b2c-8942a1593e19",
  "category": "Flattener",
  "description": "-",
  "parameters": "--var token_parameter=https://2889-2409-40e3-4069-c639-c387-93e-edfc-4036.ngrok-free.app/api/token --var json1=https://2889-2409-40e3-4069-c639-c387-93e-edfc-4036.ngrok-free.app/api/data1?token= --var json2=https://2889-2409-40e3-4069-c639-c387-93e-edfc-4036.ngrok-free.app/api/data2?token=",
  "nodes": [
    {
      "id": "1",
      "name": "API Client",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "details": "",
      "examples": "",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "259px",
      "y": "145px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import *\nimport pandas as pd\nfrom fire.workflowcontext import WorkflowContext\nimport requests\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, explode\nfrom pyspark.sql.types import ArrayType, StructType\n\n# Initialize a Spark session\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n  input_data = inDF.select(\"*\").toPandas()\n  token = input_data.token[0]\n  print(\"==============================\",token)\n  d1 = \"${json1}\"+token\n  response_data1 = requests.get(d1)#f'https://2889-2409-40e3-4069-c639-c387-93e-edfc-4036.ngrok-free.app/api/data1?token={token}')\n  print(\"111111111111111111\")\n  ndf = pd.DataFrame({\"jsondata\" : str(response_data1.json())}, index=[0])\n  print(222222222222)\n  print(ndf)\n\n  # Display the DataFrame\n  result = spark.createDataFrame(ndf)\n  return result",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"jsondata\"]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "3",
      "name": "Join On Common Columns",
      "description": "This node joins the incoming dataframes on 1 or more columns",
      "details": "",
      "examples": "",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingColumns",
      "x": "525px",
      "y": "234px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "joinCols",
          "value": "[\"patient_id\",\"patient_name\"]",
          "widget": "variables_common",
          "title": "Common Join Columns",
          "description": "Space separated list of columns on which to join",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "joinType",
          "value": "inner",
          "widget": "array",
          "title": "Join Type",
          "description": "Type of Join",
          "optionsArray": [
            "inner",
            "outer",
            "left_outer",
            "right_outer",
            "leftsemi"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "textarea_small",
          "title": "Where Clause",
          "description": "where condition after join function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"patient_id\",\"patient_name\",\"appointments_0_appointment_id\",\"appointments_0_date\",\"appointments_0_doctor_doctor_id\",\"appointments_0_doctor_doctor_name\",\"appointments_0_doctor_specialty\",\"appointments_0_notes\",\"medical_history_allergies_0\",\"medical_history_allergies_1\",\"medical_history_conditions_0\",\"medical_history_conditions_1\",\"medical_history_medications_0_dosage\",\"medical_history_medications_0_frequency\",\"medical_history_medications_0_med_id\",\"medical_history_medications_0_med_name\",\"medical_history_medications_1_dosage\",\"medical_history_medications_1_frequency\",\"medical_history_medications_1_med_id\",\"medical_history_medications_1_med_name\",\"medical_history_surgeries_0_date\",\"medical_history_surgeries_0_surgery_id\",\"medical_history_surgeries_0_surgery_name\",\"patient_details_age\",\"patient_details_contact_info_address\",\"patient_details_contact_info_email\",\"patient_details_contact_info_phone\",\"patient_details_emergency_contact_name\",\"patient_details_emergency_contact_phone\",\"patient_details_emergency_contact_relationship\",\"patient_details_gender\",\"claims_7892_amount_due\",\"claims_7892_amount_paid\",\"claims_7892_claim_date\",\"claims_7892_claim_status\",\"claims_7892_procedures_301_cost\",\"claims_7892_procedures_301_coverage\",\"claims_7892_procedures_301_date\",\"claims_7892_procedures_301_description\",\"claims_7892_procedures_301_patient_responsibility\",\"claims_7892_procedures_301_procedure_code\",\"claims_7892_procedures_301_services_1_cost\",\"claims_7892_procedures_301_services_1_coverage\",\"claims_7892_procedures_301_services_1_description\",\"claims_7892_procedures_301_services_1_patient_responsibility\",\"claims_7892_procedures_301_services_1_provider_provider_id\",\"claims_7892_procedures_301_services_1_provider_provider_name\",\"claims_7892_procedures_301_services_1_provider_specialty\",\"claims_7892_procedures_301_services_1_service_date\",\"claims_7892_procedures_301_services_2_cost\",\"claims_7892_procedures_301_services_2_coverage\",\"claims_7892_procedures_301_services_2_description\",\"claims_7892_procedures_301_services_2_patient_responsibility\",\"claims_7892_procedures_301_services_2_provider_provider_id\",\"claims_7892_procedures_301_services_2_provider_provider_name\",\"claims_7892_procedures_301_services_2_provider_specialty\",\"claims_7892_procedures_301_services_2_service_date\",\"claims_7892_procedures_302_cost\",\"claims_7892_procedures_302_coverage\",\"claims_7892_procedures_302_date\",\"claims_7892_procedures_302_description\",\"claims_7892_procedures_302_patient_responsibility\",\"claims_7892_procedures_302_procedure_code\",\"claims_7892_procedures_302_services_3_cost\",\"claims_7892_procedures_302_services_3_coverage\",\"claims_7892_procedures_302_services_3_description\",\"claims_7892_procedures_302_services_3_patient_responsibility\",\"claims_7892_procedures_302_services_3_provider_provider_id\",\"claims_7892_procedures_302_services_3_provider_provider_name\",\"claims_7892_procedures_302_services_3_provider_specialty\",\"claims_7892_procedures_302_services_3_service_date\",\"claims_7892_procedures_302_services_4_cost\",\"claims_7892_procedures_302_services_4_coverage\",\"claims_7892_procedures_302_services_4_description\",\"claims_7892_procedures_302_services_4_patient_responsibility\",\"claims_7892_procedures_302_services_4_provider_provider_id\",\"claims_7892_procedures_302_services_4_provider_provider_name\",\"claims_7892_procedures_302_services_4_provider_specialty\",\"claims_7892_procedures_302_services_4_service_date\",\"claims_7892_procedures_302_services_5_cost\",\"claims_7892_procedures_302_services_5_coverage\",\"claims_7892_procedures_302_services_5_description\",\"claims_7892_procedures_302_services_5_patient_responsibility\",\"claims_7892_procedures_302_services_5_provider_provider_id\",\"claims_7892_procedures_302_services_5_provider_provider_name\",\"claims_7892_procedures_302_services_5_provider_specialty\",\"claims_7892_procedures_302_services_5_service_date\",\"claims_7892_procedures_302_services_6_cost\",\"claims_7892_procedures_302_services_6_coverage\",\"claims_7892_procedures_302_services_6_description\",\"claims_7892_procedures_302_services_6_patient_responsibility\",\"claims_7892_procedures_302_services_6_provider_provider_id\",\"claims_7892_procedures_302_services_6_provider_provider_name\",\"claims_7892_procedures_302_services_6_provider_specialty\",\"claims_7892_procedures_302_services_6_service_date\",\"claims_7892_total_amount\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"LONG\",\"STRING\",\"LONG\",\"STRING\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"LONG\",\"STRING\",\"STRING\",\"LONG\",\"STRING\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "4",
      "name": "Print N Rows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "656px",
      "y": "241px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "title",
          "value": "Flatten Json Data",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "5",
      "name": "Access Token Reader",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "details": "",
      "examples": "",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "105px",
      "y": "211px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import *\nimport pandas as pd\nfrom fire.workflowcontext import WorkflowContext \n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n  import requests\n  tokn = \"${token_parameter}\"\n  print(tokn, \"Token\")\n  response = requests.get(tokn) #'https://2889-2409-40e3-4069-c639-c387-93e-edfc-4036.ngrok-free.app/api/token')\n  \n  tkn = pd.DataFrame(response.json(), index = [0])\n  result = spark.createDataFrame(tkn)\n  return result",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"token\"]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "6",
      "name": "Save To S3",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "Saves the DataFrame into the specified location in CSV Format",
      "details": "",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveCSV",
      "x": "858px",
      "y": "236px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "path",
          "value": "/home/sparkflows/fire-data/medical_json_to_csv_files",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the CSV files",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "8",
      "name": "API Client",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "details": "",
      "examples": "",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "257px",
      "y": "324px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import *\nimport pandas as pd\nfrom fire.workflowcontext import WorkflowContext\nimport requests\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, explode\nfrom pyspark.sql.types import ArrayType, StructType\n\n# Initialize a Spark session\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n  input_data = inDF.select(\"*\").toPandas()\n  token = input_data.token[0]\n  d1 = \"${json2}\"+token\n  response_data1 = requests.get(d1)#f'https://2889-2409-40e3-4069-c639-c387-93e-edfc-4036.ngrok-free.app/api/data1?token={token}')\n  ndf = pd.DataFrame({\"jsondata2\" : str(response_data1.json())}, index=[0])\n\n  # Display the DataFrame\n  result = spark.createDataFrame(ndf)\n  return result",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"jsondata2\"]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "9",
      "name": "Flatten",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "details": "",
      "examples": "",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "405px",
      "y": "153px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import *\nimport pandas as pd\nfrom fire.workflowcontext import WorkflowContext\nimport requests\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, explode\nfrom pyspark.sql.types import ArrayType, StructType\n\n# Initialize a Spark session\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n  input_data = inDF.select(\"*\").toPandas()\n  import json\n  data = json.loads(input_data.jsondata[0].replace(\"'\", '\"'))\n\n  # Function to recursively flatten the JSON structure\n  def flatten_json(y):\n      out = {}\n\n      def flatten(x, name=''):\n          if type(x) is dict:\n              for a in x:\n                  flatten(x[a], name + a + '_')\n          elif type(x) is list:\n              i = 0\n              for a in x:\n                  flatten(a, name + str(i) + '_')\n                  i += 1\n          else:\n              out[name[:-1]] = x\n\n      flatten(y)\n      return out\n\n  # Flatten the JSON data\n  flattened_data = flatten_json(data)\n\n  # Convert flattened data to DataFrame\n  df = pd.DataFrame([flattened_data])\n\n  # Display the DataFrame\n  result = spark.createDataFrame(df)\n  return result",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"appointments_0_appointment_id\",\"appointments_0_date\",\"appointments_0_doctor_doctor_id\",\"appointments_0_doctor_doctor_name\",\"appointments_0_doctor_specialty\",\"appointments_0_notes\",\"medical_history_allergies_0\",\"medical_history_allergies_1\",\"medical_history_conditions_0\",\"medical_history_conditions_1\",\"medical_history_medications_0_dosage\",\"medical_history_medications_0_frequency\",\"medical_history_medications_0_med_id\",\"medical_history_medications_0_med_name\",\"medical_history_medications_1_dosage\",\"medical_history_medications_1_frequency\",\"medical_history_medications_1_med_id\",\"medical_history_medications_1_med_name\",\"medical_history_surgeries_0_date\",\"medical_history_surgeries_0_surgery_id\",\"medical_history_surgeries_0_surgery_name\",\"patient_details_age\",\"patient_details_contact_info_address\",\"patient_details_contact_info_email\",\"patient_details_contact_info_phone\",\"patient_details_emergency_contact_name\",\"patient_details_emergency_contact_phone\",\"patient_details_emergency_contact_relationship\",\"patient_details_gender\",\"patient_id\",\"patient_name\"]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"LONG\",\"STRING\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"LONG\",\"STRING\",\"STRING\",\"LONG\",\"STRING\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"LONG\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "10",
      "name": "Flatten",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "details": "",
      "examples": "",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "409px",
      "y": "329px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import *\nimport pandas as pd\nfrom fire.workflowcontext import WorkflowContext\nimport requests\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, explode\nfrom pyspark.sql.types import ArrayType, StructType\n\n# Initialize a Spark session\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n  input_data = inDF.select(\"*\").toPandas()\n  import json\n  data = json.loads(input_data.jsondata2[0].replace(\"'\", '\"'))\n\n  # Function to recursively flatten the JSON structure\n  def flatten_json(y):\n      out = {}\n\n      def flatten(x, name=''):\n          if type(x) is dict:\n              for a in x:\n                  flatten(x[a], name + a + '_')\n          elif type(x) is list:\n              i = 0\n              for a in x:\n                  flatten(a, name + str(i) + '_')\n                  i += 1\n          else:\n              out[name[:-1]] = x\n\n      flatten(y)\n      return out\n\n  # Flatten the JSON data\n  flattened_data = flatten_json(data)\n\n  # Convert flattened data to DataFrame\n  df = pd.DataFrame([flattened_data])\n\n  # Display the DataFrame\n  result = spark.createDataFrame(df)\n  return result",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"claims_7892_amount_due\",\"claims_7892_amount_paid\",\"claims_7892_claim_date\",\"claims_7892_claim_status\",\"claims_7892_procedures_301_cost\",\"claims_7892_procedures_301_coverage\",\"claims_7892_procedures_301_date\",\"claims_7892_procedures_301_description\",\"claims_7892_procedures_301_patient_responsibility\",\"claims_7892_procedures_301_procedure_code\",\"claims_7892_procedures_301_services_1_cost\",\"claims_7892_procedures_301_services_1_coverage\",\"claims_7892_procedures_301_services_1_description\",\"claims_7892_procedures_301_services_1_patient_responsibility\",\"claims_7892_procedures_301_services_1_provider_provider_id\",\"claims_7892_procedures_301_services_1_provider_provider_name\",\"claims_7892_procedures_301_services_1_provider_specialty\",\"claims_7892_procedures_301_services_1_service_date\",\"claims_7892_procedures_301_services_2_cost\",\"claims_7892_procedures_301_services_2_coverage\",\"claims_7892_procedures_301_services_2_description\",\"claims_7892_procedures_301_services_2_patient_responsibility\",\"claims_7892_procedures_301_services_2_provider_provider_id\",\"claims_7892_procedures_301_services_2_provider_provider_name\",\"claims_7892_procedures_301_services_2_provider_specialty\",\"claims_7892_procedures_301_services_2_service_date\",\"claims_7892_procedures_302_cost\",\"claims_7892_procedures_302_coverage\",\"claims_7892_procedures_302_date\",\"claims_7892_procedures_302_description\",\"claims_7892_procedures_302_patient_responsibility\",\"claims_7892_procedures_302_procedure_code\",\"claims_7892_procedures_302_services_3_cost\",\"claims_7892_procedures_302_services_3_coverage\",\"claims_7892_procedures_302_services_3_description\",\"claims_7892_procedures_302_services_3_patient_responsibility\",\"claims_7892_procedures_302_services_3_provider_provider_id\",\"claims_7892_procedures_302_services_3_provider_provider_name\",\"claims_7892_procedures_302_services_3_provider_specialty\",\"claims_7892_procedures_302_services_3_service_date\",\"claims_7892_procedures_302_services_4_cost\",\"claims_7892_procedures_302_services_4_coverage\",\"claims_7892_procedures_302_services_4_description\",\"claims_7892_procedures_302_services_4_patient_responsibility\",\"claims_7892_procedures_302_services_4_provider_provider_id\",\"claims_7892_procedures_302_services_4_provider_provider_name\",\"claims_7892_procedures_302_services_4_provider_specialty\",\"claims_7892_procedures_302_services_4_service_date\",\"claims_7892_procedures_302_services_5_cost\",\"claims_7892_procedures_302_services_5_coverage\",\"claims_7892_procedures_302_services_5_description\",\"claims_7892_procedures_302_services_5_patient_responsibility\",\"claims_7892_procedures_302_services_5_provider_provider_id\",\"claims_7892_procedures_302_services_5_provider_provider_name\",\"claims_7892_procedures_302_services_5_provider_specialty\",\"claims_7892_procedures_302_services_5_service_date\",\"claims_7892_procedures_302_services_6_cost\",\"claims_7892_procedures_302_services_6_coverage\",\"claims_7892_procedures_302_services_6_description\",\"claims_7892_procedures_302_services_6_patient_responsibility\",\"claims_7892_procedures_302_services_6_provider_provider_id\",\"claims_7892_procedures_302_services_6_provider_provider_name\",\"claims_7892_procedures_302_services_6_provider_specialty\",\"claims_7892_procedures_302_services_6_service_date\",\"claims_7892_total_amount\",\"patient_id\",\"patient_name\"]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\",\"LONG\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": ""
        }
      ],
      "engine": "pyspark"
    }
  ],
  "edges": [
    {
      "source": "3",
      "target": "4",
      "id": 1
    },
    {
      "source": "5",
      "target": "1",
      "id": 2
    },
    {
      "source": "4",
      "target": "6",
      "id": 3
    },
    {
      "source": "5",
      "target": "8",
      "id": 4
    },
    {
      "source": "1",
      "target": "9",
      "id": 5
    },
    {
      "source": "8",
      "target": "10",
      "id": 6
    },
    {
      "source": "9",
      "target": "3",
      "id": 7
    },
    {
      "source": "10",
      "target": "3",
      "id": 8
    }
  ],
  "dataSetDetails": [],
  "engine": "pyspark"
}