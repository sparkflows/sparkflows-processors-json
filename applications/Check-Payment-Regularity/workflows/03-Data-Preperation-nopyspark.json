{
  "name": "03-Data-Preperation-nopyspark",
  "uuid": "94e25c16-c9c4-400b-8a65-0fd3149d2072",
  "category": "DataPreparation",
  "nodes": [
    {
      "id": "2",
      "name": "String To Date",
      "description": "This node converts string columns to date using the specified date/time format",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeMultiStringToDate",
      "x": "133px",
      "y": "89.9938px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputColNames",
          "value": "[\"date\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns",
          "datatypes": [
            "string"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputColFormats",
          "value": "[\"yyyy-MM-dd\"]",
          "widget": "variables_list_textfield",
          "title": "Input Column Formats",
          "description": "Input Column Formats. eg: yyyy-MM-dd yyyy-MM-dd HH:mm:ss",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"date\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"DATE\"]",
          "widget": "variables_list_array",
          "title": "New Data Types",
          "description": "New data types (DATE, TIMESTAMP)",
          "optionsArray": [
            "DATE",
            "TIMESTAMP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "25",
      "name": "Read CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "77px",
      "y": "257.994px",
      "hint": "Infer the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/BFSI/Check-Payment-Regularity/Cleaned-Data",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"customer\",\"merchant\",\"date\",\"amount\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Columns from CSV",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "properties",
          "value": "",
          "widget": "tab",
          "title": "Properties",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Properties Name",
          "description": "Extra options/properites available while executing in Read CSV.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Properties Value",
          "description": "Config Values for the Corresponding properites name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "26",
      "name": "Group By",
      "description": "Group By Node",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "429.119px",
      "y": "158.156px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "groupingCols",
          "value": "[\"customer\",\"merchant\",\"date\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateCols",
          "value": "[\"amount\",\"date\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "Aggregate",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateOperations",
          "value": "[\"sum\",\"min\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"sum_amount\",\"min_date\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "48",
      "name": "SQL",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "585.231px",
      "y": "165.369px",
      "hint": "Whenever the table is changed, go to InferSchema tab and Infer the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "WITH agg AS (\r\n    -- Step 2–3: group into arrays of structs\r\n    SELECT\r\n        customer,\r\n        merchant,\r\n        MIN(date) AS min_date,\r\n        MAX(date) AS max_date,\r\n        COLLECT_LIST(NAMED_STRUCT('date', date, 'sum_amount', sum_amount)) AS transactions,\r\n        COUNT(*) AS num_transactions\r\n    FROM fire_temp_table\r\n    GROUP BY customer, merchant\r\n),\r\n\r\ncalendar AS (\r\n    -- Step 4: build dense calendar using Spark's sequence()\r\n    SELECT\r\n        customer,\r\n        merchant,\r\n        EXPLODE(SEQUENCE(min_date, max_date, INTERVAL 1 DAY)) AS cal_date\r\n    FROM agg\r\n),\r\n\r\njoined AS (\r\n    -- Step 5: join daily transactions to calendar\r\n    SELECT\r\n        c.customer,\r\n        c.merchant,\r\n        c.cal_date,\r\n        COALESCE(d.sum_amount, 0.0) AS amount\r\n    FROM calendar c\r\n    LEFT JOIN fire_temp_table d\r\n      ON c.customer = d.customer\r\n     AND c.merchant = d.merchant\r\n     AND c.cal_date = d.date\r\n),\r\n\r\nfinal AS (\r\n    -- Step 6: re-aggregate into dense array\r\n    SELECT\r\n        customer,\r\n        merchant,\r\n        MIN(cal_date) AS min_date,\r\n        COLLECT_LIST(amount) AS transactions\r\n    FROM joined\r\n    GROUP BY customer, merchant\r\n    HAVING SUM(CASE WHEN amount > 0 THEN 1 ELSE 0 END) > 5\r\n)\r\n\r\nSELECT *\r\nFROM final;",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"customer\",\"merchant\",\"min_date\",\"transactions\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"DATE\",\"ARRAY\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"{\\\"transactions\\\":{\\\"containsNull\\\":false,\\\"elementType\\\":\\\"double\\\",\\\"type\\\":\\\"array\\\"}}\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "58",
      "name": "SQL",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "586.325px",
      "y": "595.388px",
      "hint": "Whenever the table is changed, go to InferSchema tab and Infer the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "SELECT * FROM fire_temp_table\r\nWHERE Customer = 'Brittney Perritt' AND Merchant = 'Bins'",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"customer\",\"merchant\",\"min_date\",\"transactions\",\"triangles\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"DATE\",\"ARRAY\",\"ARRAY\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"{\\\"transactions\\\":{\\\"containsNull\\\":true,\\\"elementType\\\":\\\"double\\\",\\\"type\\\":\\\"array\\\"}}\",\"{\\\"triangles\\\":{\\\"containsNull\\\":true,\\\"elementType\\\":\\\"float\\\",\\\"type\\\":\\\"array\\\"}}\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "59",
      "name": "Explode",
      "iconImage": "fa fa-tumblr-square",
      "description": "Explode the array of values into multiple rows with columnname_explode.",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExplode",
      "x": "736.125px",
      "y": "589.088px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"transactions\"]",
          "widget": "variables",
          "title": "Input Colums",
          "description": "Select the columns to be exploded.",
          "datatypes": [
            "array"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "60",
      "name": "Zip With Index",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node Generates a new column with unique Index/Value for each row in the Dataset",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeZipWithIndex",
      "x": "878.537px",
      "y": "570.537px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "indexColName",
          "value": "transactions_explode_indexed",
          "widget": "textfield",
          "title": "Index Column Name",
          "description": "Index column name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "61",
      "name": "Row Filter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "998.725px",
      "y": "585.719px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "conditionExpr",
          "value": "transactions_explode > 0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "62",
      "name": "Drop Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by dropping the specified columns",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropColumns",
      "x": "1130.27px",
      "y": "580.287px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropCols",
          "value": "[\"transactions\",\"triangles\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "The columns to be excluded from the output DataFrame",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "63",
      "name": "SQL",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "1385.33px",
      "y": "550.375px",
      "hint": "Whenever the table is changed, go to InferSchema tab and Infer the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "SELECT\r\n        date_add(min_date, transactions_explode_indexed) AS date,\r\n        transactions_explode\r\n    FROM fire_temp_table\r\n    WHERE transactions_explode > 0",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"date\",\"transactions_explode\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"DATE\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "64",
      "name": "Cast To Single Type",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by casting the specified input columns to a new data type",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCastColumnType",
      "x": "1249.71px",
      "y": "550.725px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"transactions_explode_indexed\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be cast to new data type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColType",
          "value": "INTEGER",
          "widget": "array",
          "title": "New Data Type",
          "description": "New data type for the selected columns (INTEGER, DOUBLE, STRING, LONG, SHORT)",
          "optionsArray": [
            "BOOLEAN",
            "BYTE",
            "DATE",
            "DECIMAL",
            "DOUBLE",
            "FLOAT",
            "INTEGER",
            "LONG",
            "SHORT",
            "STRING",
            "TIMESTAMP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replaceExistingCols",
          "value": "true",
          "widget": "array",
          "title": "Replace Existing Cols?",
          "description": "Whether to replace existing columns or create new ones?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "65",
      "name": "Print N Rows",
      "iconImage": "/images/icons/node-icon/print_n_rows.svg",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "1648.74px",
      "y": "519.55px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "transaction amount [$]",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "66",
      "name": "Columns Rename",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "1533.14px",
      "y": "531.15px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "currentColNames",
          "value": "[\"transactions_explode\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "newColNames",
          "value": "[\"Transaction\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "bulkColumnRename",
          "value": "",
          "widget": "tab",
          "title": "BulkColumnRename",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "bulkType",
          "value": "",
          "widget": "array_single",
          "title": "Type",
          "description": "Select Type",
          "optionsArray": [
            "add_prefix",
            "add_suffix",
            "remove_extra_charcter"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "prefix",
          "value": "",
          "widget": "textfield",
          "wdgtCommon": "bulkType",
          "title": "Prefix",
          "description": "Prefix Value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": "add_prefix"
        },
        {
          "name": "suffix",
          "value": "",
          "widget": "textfield",
          "wdgtCommon": "bulkType",
          "title": "Suffix",
          "description": "Suffix Value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": "add_suffix"
        },
        {
          "name": "remove_extra_charcter",
          "value": "",
          "widget": "textfield",
          "wdgtCommon": "bulkType",
          "title": "Extra Charcter",
          "description": "extra_charcter",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": "remove_extra_charcter"
        },
        {
          "name": "inputCols",
          "value": "[]",
          "widget": "variables",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "67",
      "name": "PySpark",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "177.244px",
      "y": "644.231px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import * \nfrom fire.workflowcontext import WorkflowContext \nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import udf\nimport pandas as pd\nimport numpy as np\n\ndef to_triangle_signal(xs):\n  \n    split = list(np.where(xs != 0)[0])\n    triangular = []\n\n    for i in range(len(split)):\n\n        split_id = split[i:i+2]\n        if len(split_id) == 2:\n\n            src_id = split_id[0]\n            src_vl = xs[src_id]\n\n            dst_id = split_id[1]\n            dst_vl = xs[dst_id]\n\n            mid_id = src_id + int((dst_id - src_id) / 2)\n            mid_vl = 0\n\n            a1 = (mid_vl - src_vl) / (mid_id - src_id)  # slope\n            a2 = (dst_vl - mid_vl) / (dst_id - mid_id)  # slope\n\n            for j in np.arange(src_id, dst_id, 1):\n                if j < mid_id:\n                    j_vl = src_vl + (j - src_id) * a1\n                else:\n                    j_vl = mid_vl + (j - mid_id) * a2\n                triangular.append(float(j_vl))\n\n    return triangular\n\n@udf('array<float>')\ndef to_triangle_signal_udf(xs):\n  return to_triangle_signal(np.asarray(xs))\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n    outDF = inDF.withColumn(\n      'triangles', \n      to_triangle_signal_udf(F.col('transactions'))\n    )\n    return outDF",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "68",
      "name": "PySpark",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "177.856px",
      "y": "792.869px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import * \nfrom fire.workflowcontext import WorkflowContext\nfrom datetime import timedelta\nimport matplotlib.pyplot as plt\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import udf\nimport pandas as pd\nfrom pyspark.sql import Window\nfrom pyspark.ml.linalg import Vectors, VectorUDT\nimport numpy as np\nfrom scipy import fft\nimport copy\n\nclass FourierWrapper:\n  \n    def __init__(self, spectrum, frequencies, sample_size):\n        import numpy as np\n        self.spectrum = spectrum\n        self.frequencies = frequencies\n        self.amplitudes = np.abs(spectrum)\n        self.sample_size = sample_size\n\n    def filter(self, threshold):\n        dominants = self.amplitudes >= threshold\n        return FourierWrapper(self.spectrum[dominants], self.frequencies[dominants], self.sample_size)\n\n    def to_df(self):\n        import pandas as pd\n        df = pd.DataFrame(\n          zip(self.spectrum.real, self.spectrum.imag, self.frequencies),\n          columns=['real', 'imag', 'freq']\n        )\n        df['size'] = self.sample_size\n        return df\n      \ndef fourier_transform(xs):\n    spectrum = np.fft.fft(xs)\n    frequencies = np.fft.fftfreq(len(xs), 1/len(xs))\n    return FourierWrapper(spectrum, frequencies, len(xs))\n\nstruct = ArrayType(StructType(\n  [\n    StructField('real', DoubleType(), True),\n    StructField('imag', DoubleType(), True),\n    StructField('freq', DoubleType(), True),\n    StructField('size', DoubleType(), True),\n  ]\n))\n\ndef filter_valid_frequencies(df):\n  # zero frequency represents the mean of our signal\n  max_p = 60\n  df = df[(df['freq'] == 0) | (np.abs(df['size'] / df['freq']) < max_p)]\n  return df\n\ndef detect_anomalies(amplitudes):\n\n    # to detect highly regular signals, it is safe to restrict space to top 2 frequencies only\n    # we have both imaginary and real number, so times 2 + the zero frequency\n    # we use our kernel density with the maximum distance between our top frequency with the rest\n    a = copy.deepcopy(amplitudes)\n    a.sort()\n    threshold = np.max(a[:-7])\n\n    # use density clustering to find anomalies\n    from sklearn.cluster import DBSCAN\n    clustered = DBSCAN(eps=threshold, min_samples=3).fit_predict([[x] for x in a])\n\n    # we need at least 3 points within a given distance to group frequencies together\n    # a frequency being further than 3 points within a distance will therefore be considered as outlier\n    unclustered = a[clustered == -1]\n    if np.size(unclustered) == 0:\n        return np.inf\n    else:\n        return np.min(unclustered)\n\n@udf(struct)\ndef run_spectral_analysis(xs):\n  \n  # extract all frequencies\n  fft = fourier_transform(xs)\n\n  # identify dominant frequencies\n  threshold = detect_anomalies(fft.amplitudes)\n  fft_filtered = fft.filter(threshold)\n  df = fft_filtered.to_df()\n\n  # only focus on frequencies above a given threshold\n  df = filter_valid_frequencies(df)\n\n  # the only frequency we have left is the zero frequency (i.e. average)\n  if df.shape[0] == 1:\n    return []\n\n  rs = []\n  for i, r in df.iterrows():\n    # converting numpy to primitives\n    rs.append([\n      r['real'].item(), \n      r['imag'].item(), \n      r['freq'].item(), \n      r['size'].item()\n    ])\n    \n  # return all regular signals\n  return rs\n\n@udf(VectorUDT())\ndef transactions_to_vector(days, shift, transactions):\n  appended = np.zeros(shift).tolist() + transactions\n  # we ensure all vectors are of same dimensions\n  if len(appended) < days:\n    appended = appended + np.zeros(days - len(appended)).tolist()\n  else:\n    appended = appended[:days]\n  return Vectors.dense(appended)\n\ndef frequencies_to_signal(days, shift, fft):\n  import numpy as np\n  sampling_rate = 1/days\n  x = np.arange(0 - shift, days - shift, 1)\n  transactions_ts_recombined = np.zeros((len(x),))\n  for i, f in enumerate(fft):\n    cos = f['real'] * np.cos(f['freq'] * 2 * np.pi * x * sampling_rate)\n    sin = f['imag'] * np.sin(f['freq'] * 2 * np.pi * x * sampling_rate)\n    transactions_ts_recombined += sampling_rate * (cos - sin)\n  return transactions_ts_recombined\n\n@udf(VectorUDT())\ndef frequencies_to_vector(days, shift, fft):\n  return Vectors.dense(frequencies_to_signal(days, shift, fft).tolist())\n\ndef recompose_signal(periodicity_df, days):\n  return (\n    periodicity_df\n      .withColumn('transactions', transactions_to_vector(F.lit(days), F.col('shift'), F.col('transactions')))\n      .withColumn('recomposed', frequencies_to_vector(F.lit(days), F.col('shift'), F.col('fft')))\n      .withColumnRenamed('first_date', 'date')\n      .select('customer', 'date', 'merchant', 'transactions', 'recomposed', 'shift')\n  )\n  \ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n  first_day = Window.partitionBy('customer').orderBy(F.col('min_date'))\n  periodicity_df = (\n  inDF\n    .withColumn('fft', run_spectral_analysis('triangles'))\n    .filter(F.size('fft') > 0)\n    .withColumn('date', F.first('min_date').over(first_day))\n    .withColumn('shift', F.datediff('min_date', 'date'))\n    .drop('triangles', 'min_date')\n    \n\t)\n  outDF = recompose_signal(periodicity_df, 365)\n  return outDF",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "69",
      "name": "SQL",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "641.587px",
      "y": "784.381px",
      "hint": "Whenever the table is changed, go to InferSchema tab and Infer the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "SELECT *\r\n    FROM fire_temp_table\r\n    WHERE customer = 'Brittney Perritt'\r\n      AND merchant = 'Bins'\r\n    LIMIT 1",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"customer\",\"merchant\",\"min_date\",\"transactions\",\"triangles\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"DATE\",\"ARRAY\",\"ARRAY\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"{\\\"transactions\\\":{\\\"containsNull\\\":false,\\\"elementType\\\":\\\"double\\\",\\\"type\\\":\\\"array\\\"}}\",\"{\\\"triangles\\\":{\\\"containsNull\\\":true,\\\"elementType\\\":\\\"float\\\",\\\"type\\\":\\\"array\\\"}}\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "70",
      "name": "Explode",
      "iconImage": "fa fa-tumblr-square",
      "description": "Explode the array of values into multiple rows with columnname_explode.",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExplode",
      "x": "819.587px",
      "y": "772.387px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"triangles\"]",
          "widget": "variables",
          "title": "Input Colums",
          "description": "Select the columns to be exploded.",
          "datatypes": [
            "array"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "71",
      "name": "Zip With Index",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node Generates a new column with unique Index/Value for each row in the Dataset",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeZipWithIndex",
      "x": "941.775px",
      "y": "760.575px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "indexColName",
          "value": "triangles_explode_index",
          "widget": "textfield",
          "title": "Index Column Name",
          "description": "Index column name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "72",
      "name": "Row Filter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame containing the rows that satisfy the given condition",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeRowFilter",
      "x": "1056.59px",
      "y": "760.387px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "conditionExpr",
          "value": "triangles_explode > 0",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Conditional Expression",
          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "74",
      "name": "Cast To Single Type",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by casting the specified input columns to a new data type",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCastColumnType",
      "x": "1243.88px",
      "y": "825.875px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"triangles_explode_index\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be cast to new data type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColType",
          "value": "INTEGER",
          "widget": "array",
          "title": "New Data Type",
          "description": "New data type for the selected columns (INTEGER, DOUBLE, STRING, LONG, SHORT)",
          "optionsArray": [
            "BOOLEAN",
            "BYTE",
            "DATE",
            "DECIMAL",
            "DOUBLE",
            "FLOAT",
            "INTEGER",
            "LONG",
            "SHORT",
            "STRING",
            "TIMESTAMP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replaceExistingCols",
          "value": "true",
          "widget": "array",
          "title": "Replace Existing Cols?",
          "description": "Whether to replace existing columns or create new ones?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "75",
      "name": "SQL",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node runs the given SQL on the incoming DataFrame",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeSQL",
      "x": "1355.19px",
      "y": "802px",
      "hint": "Whenever the table is changed, go to InferSchema tab and Infer the Schema",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTable",
          "value": "fire_temp_table",
          "widget": "textfield",
          "title": "Temp Table",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "SELECT\r\n        date_add(min_date, triangles_explode_index) AS date,\r\n        triangles_explode\r\n    FROM fire_temp_table\r\n    WHERE triangles_explode > 0",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"date\",\"triangles_explode\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"DATE\",\"FLOAT\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "76",
      "name": "Columns Rename",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "1468.52px",
      "y": "781.531px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "currentColNames",
          "value": "[\"triangles_explode\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "newColNames",
          "value": "[\"Transaction\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "bulkColumnRename",
          "value": "",
          "widget": "tab",
          "title": "BulkColumnRename",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "bulkType",
          "value": "",
          "widget": "array_single",
          "title": "Type",
          "description": "Select Type",
          "optionsArray": [
            "add_prefix",
            "add_suffix",
            "remove_extra_charcter"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "prefix",
          "value": "",
          "widget": "textfield",
          "wdgtCommon": "bulkType",
          "title": "Prefix",
          "description": "Prefix Value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": "add_prefix"
        },
        {
          "name": "suffix",
          "value": "",
          "widget": "textfield",
          "wdgtCommon": "bulkType",
          "title": "Suffix",
          "description": "Suffix Value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": "add_suffix"
        },
        {
          "name": "remove_extra_charcter",
          "value": "",
          "widget": "textfield",
          "wdgtCommon": "bulkType",
          "title": "Extra Charcter",
          "description": "extra_charcter",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": "remove_extra_charcter"
        },
        {
          "name": "inputCols",
          "value": "[]",
          "widget": "variables",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "77",
      "name": "Print N Rows",
      "iconImage": "/images/icons/node-icon/print_n_rows.svg",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "1616.14px",
      "y": "759.931px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "regularity of payments [$]",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "83",
      "name": "PySpark",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "314.494px",
      "y": "863.525px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import * \nfrom fire.workflowcontext import WorkflowContext\nfrom datetime import timedelta\nimport matplotlib.pyplot as plt\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import udf\nimport pandas as pd\nfrom pyspark.sql import Window\nfrom pyspark.ml.linalg import Vectors, VectorUDT\nimport numpy as np\nfrom scipy import fft\nimport copy\nfrom pyspark.ml.stat import Summarizer\n\ndef aggregate_signal(recomposed_signal_df):\n  return (\n    recomposed_signal_df\n      .groupBy('customer', 'date')\n      .agg(\n        Summarizer.sum(F.col('transactions')).alias('transactions'),\n        Summarizer.sum(F.col('recomposed')).alias('recomposed'),\n        F.sum(F.lit(1)).alias('count')\n      )\n  )\n\n\n  \ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n  outDF = aggregate_signal(inDF)\n  return outDF",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "84",
      "name": "Print N Rows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "715.719px",
      "y": "922.75px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "actual transactions",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "85",
      "name": "example_customer_ts2",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "441.612px",
      "y": "911.65px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import * \nfrom fire.workflowcontext import WorkflowContext \nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import udf\nimport pandas as pd\nimport numpy as np\nfrom datetime import timedelta\n\n\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n    customer_id = 'Brittney Perritt'\n    xs = inDF.filter(F.col('customer') == customer_id).limit(1).toPandas().iloc[0]\n\n    # actual transactions\n    xs_agg_ts = [[xs['date'] + timedelta(days=i), x] for i, x in enumerate(xs['transactions'])]\n    xs_agg_ts = pd.DataFrame(xs_agg_ts, columns=['date', 'transaction'])\n    outDF = spark.createDataFrame(xs_agg_ts)\n    return outDF",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "86",
      "name": "example_customer_ts2",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "462.619px",
      "y": "1035.94px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import * \nfrom fire.workflowcontext import WorkflowContext \nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import udf\nimport pandas as pd\nimport numpy as np\nfrom datetime import timedelta\n\n\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n    customer_id = 'Brittney Perritt'\n    xs = inDF.filter(F.col('customer') == customer_id).limit(1).toPandas().iloc[0]\n    # recomposed transactions\n    xs_agg_df = [[xs['date'] + timedelta(days=i), x] for i, x in enumerate(xs['recomposed'])]\n    xs_agg_df = pd.DataFrame(xs_agg_df, columns=['date', 'transaction'])\n    outDF = spark.createDataFrame(xs_agg_df)\n    return outDF",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "87",
      "name": "Print N Rows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "684.444px",
      "y": "1049.6px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "modeled regular payments",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "25",
      "target": "2",
      "id": 1
    },
    {
      "source": "2",
      "target": "26",
      "id": 2
    },
    {
      "source": "26",
      "target": "48",
      "id": 3
    },
    {
      "source": "67",
      "target": "68",
      "id": 4
    },
    {
      "source": "67",
      "target": "58",
      "id": 5
    },
    {
      "source": "58",
      "target": "59",
      "id": 6
    },
    {
      "source": "62",
      "target": "64",
      "id": 7
    },
    {
      "source": "64",
      "target": "63",
      "id": 8
    },
    {
      "source": "59",
      "target": "60",
      "id": 9
    },
    {
      "source": "61",
      "target": "62",
      "id": 10
    },
    {
      "source": "60",
      "target": "61",
      "id": 11
    },
    {
      "source": "63",
      "target": "66",
      "id": 12
    },
    {
      "source": "66",
      "target": "65",
      "id": 13
    },
    {
      "source": "48",
      "target": "67",
      "id": 14
    },
    {
      "source": "67",
      "target": "69",
      "id": 15
    },
    {
      "source": "69",
      "target": "70",
      "id": 16
    },
    {
      "source": "70",
      "target": "71",
      "id": 17
    },
    {
      "source": "71",
      "target": "72",
      "id": 18
    },
    {
      "source": "72",
      "target": "74",
      "id": 19
    },
    {
      "source": "74",
      "target": "75",
      "id": 20
    },
    {
      "source": "75",
      "target": "76",
      "id": 21
    },
    {
      "source": "76",
      "target": "77",
      "id": 22
    },
    {
      "source": "85",
      "target": "84",
      "id": 23
    },
    {
      "source": "86",
      "target": "87",
      "id": 24
    },
    {
      "source": "83",
      "target": "85",
      "id": 25
    },
    {
      "source": "83",
      "target": "86",
      "id": 26
    },
    {
      "source": "68",
      "target": "83",
      "id": 27
    }
  ],
  "dataSetDetails": [],
  "engine": "pyspark"
}