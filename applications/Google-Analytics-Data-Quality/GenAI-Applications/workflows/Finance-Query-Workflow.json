{
  "name": "Finance-Query-Workflow",
  "uuid": "f169e075-1a49-4923-aa67-db15b5f42117",
  "category": "-",
  "description": "-",
  "parameters": "--var destinationPath=/data/GENAI/GenAI-Applications/Finance-Doc-Query/Uploaded-File/",
  "nodes": [
    {
      "id": "2",
      "name": "Create Text Embedding",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node enables the creation of a embedding text data and output as dataframe",
      "details": "<h2> Text Embedder Node Details</h2>\n<br>\nThis node enables the creation of a embedding text data further used for indexing it into a vector database using the specified configuration. It supports multiple embedding providers including OpenAI, Bedrock, and HuggingFace.<br>\n<br>\n<h4> Parameters to be set:</h4>\n<br>\n### General:<br>\n- **Embedding Method**: Choose the embedding method from HuggingFace, OpenAI, or Bedrock.<br>\n- **Chunk Size**: Define the size of text chunks for processing large inputs (default: 1024).<br>\n- **Chunk Overlap**: Set the overlap size between consecutive chunks (default: 100).<br>\n- **Content Column**: Select the column that contains the text content (default: `content`).<br>\n- **File Name Column**: Select the column that contains file names (default: `fileName`).<br>\n- **Page Number Column**: Select the column that contains page numbers (default: `pageNumber`).<br>\n- **Base64 Image Column**: Select the column that contains Base64 encoded images (default: `base64Image`).<br>\n- **User Query**: Provide a user query string for search or processing.<br>\n- **Directory Path Column**: Set the column name for directory paths (default: `directoryPath`).<br>\n<br>\n### Service-Specific Configurations:<br>\n<br>\n#### OpenAI:<br>\n- **API Key**: Provide your OpenAI API key.<br>\n- **Embedding Model**: Specify the OpenAI embedding model.<br>\n- **Max Retries**: Set the maximum number of retries for API calls (default: 6).<br>\n- **Embedding Context Length**: Define the context length for embeddings (default: 8191).<br>\n<br>\n#### Bedrock:<br>\n- **Service Name**: Specify the Bedrock service name.<br>\n- **Region Name**: Provide the AWS region name.<br>\n- **AWS Access Key ID**: Provide your AWS Access Key ID.<br>\n- **AWS Secret Access Key**: Provide your AWS Secret Access Key.<br>\n- **Embedding Model**: Specify the Bedrock embedding model.<br>\n<br>\n#### HuggingFace:<br>\n- **Model Name**: Specify the HuggingFace embedding model (default: `all-MiniLM-L6-v2`).<br>",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.gai.NodeTextEmbedder",
      "x": "360.039px",
      "y": "497.07px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "createEmbedding",
          "value": "",
          "widget": "tab",
          "title": "Create Embedding",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "embeddingMethod",
          "value": "OpenAI",
          "widget": "array",
          "title": "Embedding Method",
          "description": "Select the embedding method.",
          "optionsArray": [
            "HuggingFace",
            "OpenAI",
            "Bedrock"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "llmConnection",
          "value": "openai-api-connection",
          "widget": "object_array",
          "title": "Select Connection",
          "description": "Select Connection",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "chunkSize",
          "value": "1024",
          "widget": "textfield",
          "title": "Chunk Size",
          "description": "Size of each text chunk.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "chunkOverlap",
          "value": "100",
          "widget": "textfield",
          "title": "Chunk Overlap",
          "description": "Overlap size between consecutive chunks.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "contentCol",
          "value": "",
          "widget": "variable",
          "title": "Vector Indexer",
          "description": "Column name for content.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "queryEmbedding",
          "value": "",
          "widget": "tab",
          "title": "Query Embedding",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "userQuery",
          "value": "Summary",
          "widget": "textarea_small",
          "title": "User Query",
          "description": "User provided query.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "huggingface",
          "value": "",
          "widget": "tab",
          "title": "Hugging Face",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "hfModelName",
          "value": "",
          "widget": "textfield",
          "title": "Hugging Face Model",
          "description": "Hugging Face embedding model.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "3",
      "name": " Multi LLM Query",
      "iconImage": "/images/icons/node-icon/Graph_group_by_column.svg",
      "description": "The Multi LLM Query node is designed to query multiple large language models (LLMs) from providers such as OpenAI, Bedrock, and Gemini, using a DataFrame as input. It processes user queries, text content, and/or base64-encoded images to generate responses based on the selected model and task, producing a structured DataFrame output.",
      "details": "<h2>Multi LLM Query Node Details</h2>\n<br>\nThe Multi LLM Query node is designed to query multiple large language models (LLMs) from providers such as OpenAI, Bedrock, and Gemini, using a DataFrame as input. It processes user queries, text content, and/or base64-encoded images to generate responses based on the selected connection and task, producing a structured DataFrame output.<br>\n<br>\n<h3>General:</h3>\n<br>\n<h4>Select Task:</h4>\nSpecifies the task to perform. Options include:<br>\n- summary: Generates a summary of the content in bullet points.<br>\n- translation: Translates the content to English.<br>\n- topic_extraction: Extracts key topics from the content.<br>\n- other: Allows for a custom task defined by the user.<br>\n<br>\n<h4>Prompt:</h4>\nAllows users to provide a custom prompt / instructions for the selected task.<br>\n<br>\n<h4>Content Column:</h4>\nSpecifies the DataFrame column containing the text content to be processed. Required for text or text+image modes.<br>\n<br>\n<h4>Select Connection:</h4>\nSpecifies the connection details for the selected LLM provider (e.g., API keys for OpenAI/Gemini, AWS credentials for Bedrock). Required to authenticate and access the respective model.<br>\n<br>\n<h4>Temperature:</h4>\nControls the randomness of the LLM's output. Default is 0.7. Higher values increase creativity, while lower values ensure more deterministic responses.<br>\n<br>\n<h4>Image Column:</h4>\nSpecifies the DataFrame column containing base64-encoded images. Required for image or text+image modes.<br>\n<br>\n<h4>Mode Selection:</h4>\nDetermines the input mode for the LLM. Options are:<br>\n- text: Processes text-only input from the content column or custom prompt.<br>\n- image: Processes base64-encoded images from the image column.<br>\n- text+image: Processes both text and base64-encoded images.<br>\n<br>\n<h4>Timeout (seconds):</h4>\nSpecifies the maximum time (in seconds) to wait for the model response. Visible when OpenAI or Gemini is selected.<br>\n<br>\n<h4>Thinking Budget:</h4>\nControls the computational budget (e.g., steps or tokens) for Gemini models. Only visible when Gemini is selected.<br>\n<br>\n<h3>Advanced:</h3>\n<br>\n<h4>Aggregate Response:</h4>\nSpecifies how to aggregate input data before processing. Options are:<br>\n- none: Processes each row individually, retaining fileName and pageNumber (if provided).<br>\n- all: Aggregates all rows into a single response.<br>\n- perfile: Aggregates rows by fileName, producing one response per file.<br>\n<br>\n<h4>Number of Partitions:</h4>\nSpecifies the number of Spark partitions for distributed processing. Default is 3.<br>\n<br>\n<h4>File Name Column:</h4>\nSpecifies the DataFrame column containing file names. Required for perfile aggregation mode.<br>\n<br>\n<h4>Page Number Column:</h4>\nSpecifies the DataFrame column containing page numbers (e.g., for PDFs). Optional, used for row-wise processing with none aggregation mode.<br>\n<br>\n<h3>Output:</h3>\nThe node outputs a DataFrame with columns based on the aggregation mode:<br>\n- none: Includes fileName (if provided), pageNumber (if provided), and response.<br>\n- perfile: Includes fileName and response.<br>\n- all: Includes only the response column.<br>\nThe response column contains the LLM-generated text or error messages if the API call fails.<br>",
      "examples": "<h2>Multi LLM Query Node Examples</h2>\n<br>\n<h3>Input:</h3>\nA DataFrame contains the following data:<br>\n- fileName: [\"doc1.pdf\", \"doc1.pdf\", \"doc2.pdf\"]<br>\n- pageNumber: [\"1\", \"2\", null]<br>\n- content: [\"Article about climate change...\", \"Climate change impacts...\", \"Renewable energy report...\"]<br>\n- imageBase64: [null, \"iVBORw0KGgoAAAANSUhEUg...\", null]<br>\n<br>\nThe Multi LLM Query node is configured as follows:<br>\n- Select Task: summary<br>\n- Prompt: \"Summarize the content in bullet points.\"<br>\n- Content Column: content<br>\n- Select Connection: Configured with valid OpenAI API key<br>\n- Temperature: 0.7<br>\n- Timeout (seconds): 90<br>\n- Image Column: imageBase64<br>\n- Mode Selection: text+image<br>\n- Aggregate Response: perfile<br>\n- Number of Partitions: 3<br>\n- File Name Column: fileName<br>\n- Page Number Column: pageNumber<br>\n<br>\n<h3>Output:</h3>\nThe node processes the DataFrame and produces a DataFrame with the following structure:<br>\n- fileName: doc1.pdf<br>\nresponse:<br>\n- Climate change effects on ecosystems<br>\n- Rising temperatures<br>\n<br>\n- fileName: doc2.pdf<br>\nresponse:<br>\n- Renewable energy advancements<br>\n- Solar and wind adoption<br>",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeMultiLLMQuery",
      "x": "725px",
      "y": "534px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "llmConnection",
          "value": "openai-api-connection",
          "widget": "object_array",
          "title": "Select Connection",
          "description": "Select Connection",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "temperature",
          "value": "0",
          "widget": "textfield",
          "title": "Temperature",
          "description": "Temperature setting for the model (default: 0).",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "contentCol",
          "value": "content",
          "widget": "variable",
          "title": "Content Column",
          "description": "Column name for the text content.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "imageCol",
          "value": "",
          "widget": "variable",
          "title": "Image Column",
          "description": "Column name for the base 64 image.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputMode",
          "value": "text",
          "widget": "array",
          "title": "Mode Selection",
          "description": "Select the model to use (text, image, text+image).",
          "optionsArray": [
            "text",
            "image",
            "text+image"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Prompt",
          "value": "",
          "widget": "tab",
          "title": "Prompt",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "task",
          "value": "other",
          "widget": "key_value_array",
          "title": "Select Prompt",
          "description": "Specify the task to perform: summary, translation, topic extraction, or other.",
          "optionsMap": {
            "summary": "Generate Summary in bullet points ",
            "translation": "Translate the following content to default language",
            "topic_extraction": "Extract key topics from the following content.",
            "other": ""
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "customPrompt",
          "value": "",
          "widget": "textareafield",
          "title": "Prompt",
          "description": "Custom prompt to override the default instructions.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "userQueryCol",
          "value": "userquery",
          "widget": "variable",
          "title": "User Query Column",
          "description": "Column name for user query, (if the query is in a column)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateMode",
          "value": "ALL",
          "widget": "enum",
          "title": "Aggregate Response",
          "optionsMap": {
            "NONE": "Do not aggregate rows",
            "ALL": "Aggregate all rows",
            "PERFILE": "Aggregate per file"
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "numPartitions",
          "value": "3",
          "widget": "textfield",
          "title": "Number of Partitions",
          "description": "Number of Partitions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileNameCol",
          "value": "",
          "widget": "variable",
          "title": "File Name Column",
          "description": "Select File Name Column",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pageNumberCol",
          "value": "",
          "widget": "variable",
          "title": "Page Number Column",
          "description": " Select Page Number column.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "timeout",
          "value": "180",
          "widget": "textfield",
          "title": "Timeout (seconds)",
          "description": "Maximum time to wait for Openai and Gemini API response",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "thinkingBudget",
          "value": "-1",
          "widget": "textfield",
          "title": "Thinking Budget",
          "description": "Configure the Gemini thinking budget by specifying the number of tokens to allocate for thinking. For Flash and Flash Lite models, values can range from 0 to 24,576 or -1 for dynamic thinking. For 2.5 Pro model, values must be between 1 and 24,576; setting 0 is not allowed.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "4",
      "name": "Print N Rows",
      "iconImage": "/images/icons/node-icon/print_n_rows.svg",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "937px",
      "y": "559px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "Row Values",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "5",
      "name": "Read Faiss DB",
      "iconImage": "fa fa-tumblr-square",
      "description": "Read Vector Embeddings, from faiss db",
      "details": "<h2>Read Faiss DB Node Details</h2><br>\nThe Read Faiss DB node retrieves vector embeddings from a FAISS vector database based on a user query or query embeddings provided in a DataFrame. It performs a similarity search to find the most relevant documents and returns the results as a DataFrame with columns for the user query and corresponding content. This node is designed for PySpark-based workflows, enabling efficient retrieval of vector-based data for similarity search applications.<br>\n<br>\n<h4>General:</h4><br>\n<br>\n<h5>Path Of FAISS Index Directory:</h5> Specifies the directory path (local or distributed filesystem) where the FAISS index is stored. This is required and must point to a valid directory containing the FAISS index.<br>\n<br>\n<h5>Top K:</h5> Specifies the number of top results to retrieve from the FAISS index based on similarity. Default is 3. Must be a positive integer.<br>\n<br>\n<h5>Name Of FAISS Index:</h5> Specifies the name of the FAISS index to query. This is required and must match an existing index in the specified directory.<br>\n<br>\n<h4>Output:</h4><br>\nThe node outputs a DataFrame with the following columns:<br>\n<ul>\n<li> userquery: The original query from the input DataFrame or derived from the query embeddings.</li>\n<li> content: The content of the top matching documents retrieved from the FAISS index, based on similarity to the query.</li>\n</ul>",
      "examples": "<h2>Example: Read Faiss DB Node</h2><br>\n<br>\n<h3>Input:</h3><br>\nA DataFrame contains the following data:<br>\n- userQuery: [\"What is climate change?\", \"AI advancements in 2025\"]<br>\n- embeddings: [[0.12, 0.45, ...], [0.23, 0.67, ...]] (1024-dimensional vectors)<br>\n<br>\nThe Read Faiss DB node is configured as follows:<br>\n<ul>\n<li> Path Of FAISS Index Directory: /data/faiss_indices/</li>\n<li> Top K: 3</li>\n<li> Name Of FAISS Index: faiss_index</li>\n</ul>\n<h3>Output:</h3><br>\nThe node queries the FAISS database and produces a DataFrame with the following structure:<br>\n<br>\nuserquery                    | content<br>\n-----------------------------|--------------------------------------<br>\nWhat is climate change?      | Climate change refers to long-term shifts in weather patterns...<br>\nAI advancements in 2025      | Recent AI advancements include improved neural networks...<br>\n<br>\n<h3>Explanation:</h3><br>\n- The node processes the DataFrame, using the userQuery and embeddings columns to perform a similarity search in the FAISS index named 'faiss_index' located in the '/data/faiss_indices/' directory.<br>\n- The Top K setting of 3 ensures that up to three matching documents are retrieved for each query based on similarity to the provided embeddings.<br>\n- The userquery column in the output DataFrame contains the original text queries from the input DataFrame for reference.<br>\n- The content column contains the text of the most relevant documents retrieved from the FAISS index.<br>\n- The Path Of FAISS Index Directory and Name Of FAISS Index settings ensure the node queries the correct index in the specified location.<br>\n- If the input DataFrame only provided text queries without embeddings, the node would rely on the FAISS service to generate embeddings internally (if supported by the configuration).<br>",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeReadFromFaissDB",
      "x": "533px",
      "y": "501px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "faissIndexDir",
          "value": "data/GENAI/GenAI-Applications/Finance-Doc-Query/Vectorstore/db_faiss",
          "widget": "textfield",
          "title": "Path Of FAISS Index Directory",
          "description": "Enter FAISS Index Directory path.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "topK",
          "value": "3",
          "widget": "textfield",
          "title": "Top K",
          "description": "Consider the top k(3) probable words at each step during text generation.",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "faissIndexName",
          "value": "faiss_index",
          "widget": "textfield",
          "title": "Name Of FAISS Index",
          "description": "Enter FAISS Index Name.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    }
  ],
  "edges": [
    {
      "source": "3",
      "target": "4",
      "id": 1
    },
    {
      "source": "2",
      "target": "5",
      "id": 2
    },
    {
      "source": "5",
      "target": "3",
      "id": 3
    }
  ],
  "dataSetDetails": [],
  "engine": "pyspark"
}