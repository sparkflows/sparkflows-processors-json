{
  "name": "Feature-Extraction-For-Text-Data",
  "uuid": "5b60a8cb-2d94-46c5-846a-c57b7ba94589",
  "category": "FeatureEngineering",
  "description": "Tokenizes and then performs TF/IDF on text content",
  "nodes": [
    {
      "id": "1",
      "name": "DatasetStructured",
      "description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset was defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",
      "details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",
      "examples": "",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "40.1406px",
      "y": "348.141px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "dataset",
          "value": "6be87dab-55ab-4738-9fa6-97d8de4bd5f3",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "2",
      "name": "Tokenizer",
      "description": "A tokenizer that converts the input string to lowercase and then splits it by white spaces.",
      "details": "<h2> Tokenizer Node Details</h2>\n<br>\nTokenization is essentially splitting a phrase, sentence, paragraph, or an entire text document into smaller units, such as individual words or terms. Each of these smaller units are called tokens. The Tokenizer node accepts an string input and breaks the string into an array of tokens.<br>\n                                                                        <br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> INPUT COLUMN : Select the required string column for whom tokenization has to be done . </li>\n<li> OUTPUT COLUMN : The name of the output tokenized column.</li>\n</ul>",
      "examples": "<h2> Tokenizer Node Example</h2>\n<br>\nAssume that we have a DataFrame with the column <b>strText<b>:<br>\n<br>\n          strText             | <br>\n----------------------------- |<br>\n Sparkflows is cool to learn. |<br>\n <br>\n If we set Tokenizer's <b>INPUT COLUMN</b> to strText and <b>OUTPUT COLUMN</b> to tokens, after transformation we should get the following DataFrame:<br>\n<br>\n                  tokens                       | <br>\n---------------------------------------------- |<br>\nWrappedArray(sparkflows, is, cool, to, learn.) |<br>",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeTokenizer",
      "x": "277.094px",
      "y": "350.125px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "inputCol",
          "value": "message",
          "widget": "variable",
          "title": "Input Column",
          "description": "Column containing text (such as sentence)",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "outputCol",
          "value": "words",
          "widget": "textfield",
          "title": "Output Column",
          "description": "Output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "3",
      "name": "PrintNRows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "930.391px",
      "y": "345.391px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "title",
          "value": "Output of Extracted Features",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "4",
      "name": "HashingTF",
      "description": "Maps a sequence of terms to term frequencies using the hashing trick.",
      "details": "<h2> Hashing TF Node Details</h2>\n<br>\nThe Hashing TF Node maps a sequence of terms to their term frequencies using the hashing trick. Currently we use Austin Appleby’s MurmurHash 3 algorithm (MurmurHash3_x86_32) to calculate the hash code value for the term object.<br>\n<br>\nHashing TF converts documents to vectors of fixed size. The default feature dimension is 262,144. The terms are mapped to indices using a Hash Function. The term frequencies are computed with respect to the mapped indices.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> INPUT COLUMN : Select the input token column from the incoming schema. </li>\n<li> OUTPUT COLUMN : Set a name of the output transformed column.</li>\n</ul>",
      "examples": "<h2> Hashing TF Node Example</h2>\n<br>\nConsider the below <b>Hashing TF</b> vector output for the <b>tokenizer</b> column.<br>\n<br>\n|-----------------------------------------------------------------------------|<br>\n|       Title         |       tokenizer         |           hashTF            |<br>\n|-----------------------------------------------------------------------------|<br>\n| Learning Sparkflows | (learning, sparkflows)  |   (1000,[72,990],[1.0,1.0]) |<br>",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeHashingTF",
      "x": "487.391px",
      "y": "350.391px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "inputCol",
          "value": "words",
          "widget": "variable",
          "title": "Input Column",
          "description": "Contains sets of terms. In text processing, a 'set of terms' might be a bag of words",
          "datatypes": [
            "array"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "outputCol",
          "value": "rawFeatures",
          "widget": "textfield",
          "title": "Output Column",
          "description": "Output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "6",
      "name": "IDF",
      "description": "Compute the Inverse Document Frequency (IDF) given a collection of documents.",
      "details": "<h2> IDF Node Details</h2>\n<br>\nThe IDF (Inverse Document Frequency) Node is a feature vectorization method widely used in text mining to reflect the importance of a term to a document in the corpus. IDF is a measure of how common any particular word or gram is in the given corpus that you are searching. It is an estimate of how rare that word is and thus its likely importance. So if a query contains an uncommon word, documents containing that rare word should be judged to be more important.<br>\n                                                                        <br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> INPUT COLUMN : Select the vector field in the input schema that contains the features to build the model from.</li>\n<li> OUTPUT COLUMN : A name for the output vector column.</li>\n<li> MINDOCFREQ : The minimum number of documents in which a term should appear. Default: 0</li>\n</ul>",
      "examples": "<h2> IDF Node Example</h2>\n<br>\nAssume that we have a DataFrame with the column <b>strText<b>:<br>\n<br>\n        strText      | <br>\n---------------------|<br>\n Sparkflows is cool  |<br>\n Learn Sparkflows    |<br>\n Sparkflows rocks!   |<br>\n <br>\nCreating a feature vectors from the <b>strText<b> column, and applying the IDF node we get the below output column <b>vecIDF</b><br>\n<br>\n                              vecIDF                                     | <br>\n------------------------------------------------------------------------ |<br>\n(1000,[209,372,990,995],[0.6931471805599453,0.0,0.0,0.6931471805599453]) |<br>\n(1000,[372,967,990],[0.0,0.6931471805599453,0.0])                        |<br>\n(1000,[372,962,990],[0.0,0.6931471805599453,0.0])                        |<br>",
      "type": "ml-transformer",
      "nodeClass": "fire.nodes.ml.NodeIDF",
      "x": "703.375px",
      "y": "346.391px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "inputCol",
          "value": "rawFeatures",
          "widget": "variable",
          "title": "Input Column",
          "description": "Input Column Name",
          "datatypes": [
            "vectorudt"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "outputCol",
          "value": "features",
          "widget": "textfield",
          "title": "Output Column",
          "description": "Output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "minDocFreq",
          "value": "0",
          "widget": "textfield",
          "title": "MinDocFreq",
          "description": "The minimum of documents in which a term should appear.",
          "datatypes": [
            "integer"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "scala"
    },
    {
      "id": "7",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "108px",
      "y": "19px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "bgColor",
          "value": "blue",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "width",
          "value": "694px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "height",
          "value": "251px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        },
        {
          "name": "comment",
          "value": "<h1>Perform TF / IDF on a String Column</h1><p><br></p><h2>workflow:</h2><p><br></p><ul><li>​Reads in a <strong>spam dataset</strong></li><li><strong>Tokenizes</strong> the message column</li><li>Performs <strong>TF/IDF</strong> on the tokens generated</li></ul><p><br></p><p>https://spark.apache.org/docs/latest/ml-features#tf-idf</p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "1",
      "target": "2",
      "id": 1
    },
    {
      "source": "2",
      "target": "4",
      "id": 2
    },
    {
      "source": "4",
      "target": "6",
      "id": 3
    },
    {
      "source": "6",
      "target": "3",
      "id": 4
    }
  ],
  "dataSetDetails": [
    {
      "id": 3054,
      "uuid": "6be87dab-55ab-4738-9fa6-97d8de4bd5f3",
      "header": true,
      "path": "data/DATA-SCIENCE/Spam/Spam.csv",
      "delimiter": ",",
      "datasetType": "CSV",
      "datasetSchema": "{\"colNames\":[\"label\",\"message\",\"id\"],\"colTypes\":[\"DOUBLE\",\"STRING\",\"DOUBLE\"],\"colFormats\":[\"\",\"\",\"\"],\"colMLTypes\":[\"NUMERIC\",\"TEXT\",\"NUMERIC\"]}"
    }
  ],
  "engine": "scala"
}