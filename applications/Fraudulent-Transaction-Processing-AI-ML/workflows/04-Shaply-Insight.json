{
  "name": "04-Shaply-Insight",
  "uuid": "17c121d8-b210-4f32-867b-ceda8ee8298f",
  "category": "GENAI",
  "description": "-",
  "parameters": " --var getStarted=true --var explorePatientData=false --var generateRca=true",
  "nodes": [
    {
      "id": "1",
      "name": "Read CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>InferSchema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the InferSchema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "33.2px",
      "y": "225.244px",
      "hint": "Infer the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/MANUFACTURING/Fraudulent-Transaction-Processing-AI-ML/Billing-Fraud/Shaply-Data/",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"Invoice_ID\",\"Vendor_ID\",\"PO_No\",\"Item\",\"Qty_Received\",\"Qty_Billed\",\"Hours_Logged\",\"Hours_Billed\",\"Contract_Unit_Price\",\"Unit_Price\",\"Invoice_Date\",\"Bank_Account\",\"Approved_By\",\"Delivery_Receipt_Flag\",\"Invoice_Amount\",\"qty_gap\",\"qty_gap_ratio\",\"hours_gap\",\"hours_gap_ratio\",\"price_gap\",\"price_ratio\",\"amount_minus_expected\",\"is_weekend_invoice\",\"invoice_day\",\"invoice_hour\",\"receipt_missing\",\"amount_per_unit\",\"vendor_day_invoice_count\",\"dup_combo_count\",\"bank_vendor_count\",\"approver_vendor_count\",\"item_vendor_count\",\"isolated_prediction\",\"Anomaly\",\"prediction\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Columns from CSV",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"DOUBLE\",\"INTEGER\",\"DOUBLE\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"BOOLEAN\",\"BOOLEAN\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "properties",
          "value": "",
          "widget": "tab",
          "title": "Properties",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Properties Name",
          "description": "Extra options/properites available while executing in Read CSV.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Properties Value",
          "description": "Config Values for the Corresponding properites name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "2",
      "name": "Concat Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "205.888px",
      "y": "222.925px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Invoice_ID\",\"Vendor_ID\",\"PO_No\",\"Item\",\"Qty_Received\",\"Qty_Billed\",\"Hours_Logged\",\"Hours_Billed\",\"Contract_Unit_Price\",\"Unit_Price\",\"Invoice_Date\",\"Bank_Account\",\"isolated_prediction\",\"item_vendor_count\",\"approver_vendor_count\",\"bank_vendor_count\",\"dup_combo_count\",\"vendor_day_invoice_count\",\"amount_per_unit\",\"receipt_missing\",\"invoice_hour\",\"invoice_day\",\"is_weekend_invoice\",\"amount_minus_expected\",\"price_ratio\",\"price_gap\",\"hours_gap_ratio\",\"hours_gap\",\"qty_gap_ratio\",\"qty_gap\",\"Invoice_Amount\",\"Delivery_Receipt_Flag\",\"Approved_By\",\"Anomaly\",\"prediction\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "Content",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "|",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "3",
      "name": "Interactive LLM Agent",
      "iconImage": "/images/icons/node-icon/Graph_group_by_column.svg",
      "description": "This node enables standalone or dataframe-optional LLM queries across multiple providers (OpenAI, Bedrock, Gemini). It is designed for sequential agent flows like 'Similar Company Finder' and supports saving structured responses.",
      "details": "<h2>Interactive LLM Agent Node Details</h2><br>\nThe Interactive LLM Agent node enables querying large language models (LLMs) such as OpenAI, Bedrock (Anthropic), and Gemini from Google, using either a standalone prompt or content from a DataFrame. It is designed for flexible agent workflows and provides safe input and output validation.<br>\n<br>\n<h4>General:</h4><br>\n<br>\n<h5>Custom Prompt:</h5><br>\nThis field lets you specify the user query or task description. If the node is used without a DataFrame, this prompt is the only content passed to the LLM.<br>\n<br>\n<h5>Metadata Columns:</h5><br>\nWhen a DataFrame is passed into the node, you can select one or more content columns whose text will be sent to the LLM. The prompt and content will be combined and sent to the model.<br>\n<br>\n<br>\n<h5>Select Connection:</h5><br>\nEach model provider requires specific connection credentials (e.g., API keys). These must be configured in the backend and are referenced here.<br>\n<br>\n<h5>Temperature, Max Tokens, and Retries:</h5><br>\n<ul><br>\n<li><b>Temperature</b> controls creativity: lower values yield more deterministic outputs.</li><br>\n<li><b>Max Tokens</b> sets the maximum length of the generated response.</li><br>\n<li><b>Retries</b> determine how many times to retry in case of failure.</li><br>\n</ul><br>\n<br>\n<h4>Output:</h4><br>\nThe output is a Spark DataFrame with a single column:<br>\n<ul><br>\n<li><b>response</b>: Contains the LLM-generated response, cleaned and validated.</li><br>\n</ul><br>\n<br>\nIf a DataFrame is passed in with metadata columns, their values are merged into the prompt. Otherwise, the prompt is used as-is.<br>",
      "examples": "<h2>Example: Interactive LLM Agent Node</h2><br>\n<br>\n<h3>Input:</h3><br>\nA DataFrame with the following data:<br>\n<table border=\"1\"><br>\n<tr><th>company_name</th><th>industry</th></tr><br>\n<tr><td>TechCorp</td><td>Software</td></tr><br>\n<tr><td>InnovateAI</td><td>Artificial Intelligence</td></tr><br>\n</table><br>\n<br>\n<h3>Configuration:</h3><br>\n<ul><br>\n<li><b>Custom Prompt:</b> \"Find companies similar to {company_name} in the {industry} industry.\"</li><br>\n<li><b>Metadata Columns:</b> [company_name, industry]</li><br>\n<li><b>Temperature:</b> 0.7</li><br>\n<li><b>Max Tokens:</b> 512</li><br>\n<li><b>Retries:</b> 2</li><br>\n</ul><br>\n<br>\n<h3>Output:</h3><br>\nA DataFrame with a single response column:<br>\n<table border=\"1\"><br>\n<tr><th>response</th></tr><br>\n<tr><td>TechCorp (Software): - CodeZap - SoftPeak - Nexlify<br/>InnovateAI (Artificial Intelligence): - AIWorks - NeuralNest - DeepMind</td></tr><br>\n</table><br>\n<br>\n<h3>Explanation:</h3><br>\n<ul><br>\n<li>The node reads values from metadata columns and constructs a prompt for each row.</li><br>\n<li>The content and task are passed to the OpenAI LLM.</li><br>\n<li>The response is generated, cleaned of Markdown wrappers (e.g., ```json)</li><br>\n<li>The output is returned in a DataFrame as a single response string (across all rows).</li><br>\n</ul><br>",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeInteractiveLLMAgent",
      "x": "349.662px",
      "y": "226.687px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "llmConnection",
          "value": "GPT_4.1",
          "widget": "object_array",
          "title": "Select Connection",
          "description": "Select Connection",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "customPrompt",
          "value": "You are given transaction anomaly detection results from an Isolation Forest model along with SHAP feature contributions that explain fraud predictions.  \n\n\nColumn: `isolated_prediction` (value < 6 = anomaly, ≥ 6 = good).  \n\n\n---\n\n\n### Your tasks:\n1. Identify **each anomaly line item** (isolated_prediction < 6) and strictly ignore good transactions.  \n2. For every anomaly, return the **Invoice ID** and **Vendor ID**.  \n3. Use SHAP feature insights to explain the fraud drivers in plain English:  \n   - If Qty_Billed > Qty_Received → Overbilling of materials.\n   - If Hours_Billed > Hours_Logged → Ghost/extra labor hours.  \n   - If Unit_Price > Contract_Unit_Price → Price inflation.  \n   - If Bank_Account linked to multiple vendors → Possible collusion.  \n   - If Approved_By repeated across suspicious invoices → Insider collusion.  \n   - If Hours_Gap or Amount_Minus_Expected high → Inflated hours or mismatched invoice amounts.  \n4. Based on point 1, 2, 3 and also try to research on your own if required, provide  **Root Cause Analysis \"rca\"** for each anomaly (e.g., use shap features - example - duplicate invoice, quantity mismatch, inflated logged hours, rate discrepancy, missing approvals, suspicious vendor concentration, odd-hour submission, abnormal invoice amount, weekend/holiday invoice, vendor-item anomaly, collusion risk).  \n5. Based on point 1, 2, 3 and also try to research on your own if required, provide **one concise Actionable insight \"actionable_insight\"** per anomaly (e.g., based on root cause results - example - enable duplicate check, restrict off-hour invoices, cross-verify bank accounts, enforce receipt validation, tighten contract controls, segregate new vendors, cap hours vs logged, SKU-level monitoring).  \n6. Keep the tone business-oriented and easy to read. \n7. Strictly make sure \"rca\" and \"actionable_insight\" is added to every single anomaly detected.\n\n\n---\n\n\n### Output Format:\nReturn a valid JSON object with a single key `\"items\"` containing an array of objects.  \n\n\n### JSON Structure (example for reference):\n```json\n{\n  \"items\": [\n    {\n      \"invoice_id\": \"INV1590\",\n      \"vendor_id\": \"V1014\",\n      \"rca\": \"xxxxx\",\n      \"actionable_insight\": \"xxxxx\"\n    },\n    {\n      \"invoice_id\": \"INV1595\",\n      \"vendor_id\": \"V1017\",\n      \"rca\": \"xxxxx\",\n      \"actionable_insight\": \"xxxxx\"\n    }\n  ]\n}",
          "widget": "textareafield",
          "title": "Prompt",
          "description": "Custom prompt to instruct the model.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "metadataCols",
          "value": "[\"Content\"]",
          "widget": "variables",
          "title": "Metadata Columns",
          "description": "Select one or more content columns to pass as input to the model.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "modelSelection",
          "value": "gemini",
          "widget": "textfield",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "googleApiKey",
          "value": "AIzaSyCyZlVU9YvdSOFRTO3FRZD0GZW9qVHdDgg",
          "widget": "textfield",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "geminiModel",
          "value": "gemini-2.5-flash",
          "widget": "textfield",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "maxTokens",
          "value": "65536",
          "widget": "textfield",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "4",
      "name": "Output Formatter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node formats output from Columns.",
      "details": "<h2> Output Formatter Node Details</h2>\nThe Output Formatter node formats data from a specified column in an input DataFrame and outputs it with a user-defined key. It is designed for use in PySpark-based data processing pipelines to extract and present data in a structured format, typically for downstream use or display. The node processes a single column from the input DataFrame, formats the content, and sends it as a JSON message with a specified key.<br>\n<br>\n<h4> General:</h4>\n<br>\nh5: Select Column:<br>\nSpecifies the column in the input DataFrame from which to extract data. This field is required and must correspond to a valid column name in the DataFrame.<br>\n<br>\nh5: Key:<br>\nDefines a key name for the formatted output. This field is required and is used to label the extracted column value in the output JSON message.<br>\n<br>\n<h4> Output:</h4>\nThe node does not modify the input DataFrame but instead generates a JSON-formatted message containing the following:<br>\n<ul>\n<li> id: The node’s ID.</li>\n<li> name: The node’s name (\"Output Formatter\").</li>\n<li> title: The display title (\"Output Formatter\").</li>\n<li> type: The node type (\"formatter\").</li>\n<li> resultType: Set to 3, indicating the output is a formatted message.</li>\n<li> visibility: Set to \"EXPANDED\" for display purposes.</li>\n<li> text: A nested structure containing:</li>\n<li> key: The user-specified key name.</li>\n<li> string: The value extracted from the selected column (from the first row of the DataFrame).</li>\n<li> format: Set to \"plaintext\" for the output format.</li>\n</ul>\nThe JSON message is sent to the workflow context for further processing or display. The input DataFrame is passed through unchanged as the node’s output schema.<br>",
      "examples": "<h2> Example: Output Formatter Node</h2>\n<br>\n<h3> Input:</h3>\nA DataFrame with the following structure, containing a single row of data:<br>\n<br>\n| summary_text                     |<br>\n|----------------------------------|<br>\n| Project meeting: Plan Q1 goals...|<br>\n<br>\nThe Output Formatter node is configured as follows:<br>\n<ul>\n<li> Select Column: summary_text</li>\n<li> Key: meeting_summary</li>\n</ul>\n<h3> Output:</h3>\nThe node processes the DataFrame and generates a JSON-formatted message sent to the workflow context, with the following structure:<br>\n<br>\n```json<br>\n{<br>\n\"id\": \"11\",<br>\n\"name\": \"Output Formatter\",<br>\n\"title\": \"Output Formatter\",<br>\n\"type\": \"formatter\",<br>\n\"resultType\": 3,<br>\n\"visibility\": \"EXPANDED\",<br>\n\"text\": {<br>\n\"key\": \"meeting_summary\",<br>\n\"string\": \"Project meeting: Plan Q1 goals...\",<br>\n\"format\": \"plaintext\"<br>\n}<br>\n}<br>\n```<br>\n<br>\nThe input DataFrame is passed through unchanged as the node’s output schema.<br>\n<br>\n<h3> Explanation:</h3>\n<ul>\n<li> The summary_text column is selected, and the value from its first row (\"Project meeting: Plan Q1 goals...\") is extracted.</li>\n<li> The key field is set to \"meeting_summary\", which is used to label the extracted value in the output JSON.</li>\n<li> The node formats the extracted value into a JSON message with a nested text object, specifying the key, string value, and format (\"plaintext\").</li>\n<li> The JSON message is sent to the workflow context for further processing or display.</li>\n<li> The original DataFrame is returned as the output schema without modification.</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.graph.NodeOutputFormatter",
      "x": "204.962px",
      "y": "490.969px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "column",
          "value": "response",
          "widget": "variable",
          "title": " Select Column",
          "description": "Select Column to format",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "key",
          "value": "genAiResponse",
          "widget": "textfield",
          "title": "Key",
          "description": "Specify a key Name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "5",
      "name": "Interactive LLM Agent",
      "iconImage": "/images/icons/node-icon/Graph_group_by_column.svg",
      "description": "This node enables standalone or dataframe-optional LLM queries across multiple providers (OpenAI, Bedrock, Gemini). It is designed for sequential agent flows like 'Similar Company Finder' and supports saving structured responses.",
      "details": "<h2>Interactive LLM Agent Node Details</h2><br>\nThe Interactive LLM Agent node enables querying large language models (LLMs) such as OpenAI, Bedrock (Anthropic), and Gemini from Google, using either a standalone prompt or content from a DataFrame. It is designed for flexible agent workflows and provides safe input and output validation.<br>\n<br>\n<h4>General:</h4><br>\n<br>\n<h5>Custom Prompt:</h5><br>\nThis field lets you specify the user query or task description. If the node is used without a DataFrame, this prompt is the only content passed to the LLM.<br>\n<br>\n<h5>Metadata Columns:</h5><br>\nWhen a DataFrame is passed into the node, you can select one or more content columns whose text will be sent to the LLM. The prompt and content will be combined and sent to the model.<br>\n<br>\n<br>\n<h5>Select Connection:</h5><br>\nEach model provider requires specific connection credentials (e.g., API keys). These must be configured in the backend and are referenced here.<br>\n<br>\n<h5>Temperature, Max Tokens, and Retries:</h5><br>\n<ul><br>\n<li><b>Temperature</b> controls creativity: lower values yield more deterministic outputs.</li><br>\n<li><b>Max Tokens</b> sets the maximum length of the generated response.</li><br>\n<li><b>Retries</b> determine how many times to retry in case of failure.</li><br>\n</ul><br>\n<br>\n<h4>Output:</h4><br>\nThe output is a Spark DataFrame with a single column:<br>\n<ul><br>\n<li><b>response</b>: Contains the LLM-generated response, cleaned and validated.</li><br>\n</ul><br>\n<br>\nIf a DataFrame is passed in with metadata columns, their values are merged into the prompt. Otherwise, the prompt is used as-is.<br>",
      "examples": "<h2>Example: Interactive LLM Agent Node</h2><br>\n<br>\n<h3>Input:</h3><br>\nA DataFrame with the following data:<br>\n<table border=\"1\"><br>\n<tr><th>company_name</th><th>industry</th></tr><br>\n<tr><td>TechCorp</td><td>Software</td></tr><br>\n<tr><td>InnovateAI</td><td>Artificial Intelligence</td></tr><br>\n</table><br>\n<br>\n<h3>Configuration:</h3><br>\n<ul><br>\n<li><b>Custom Prompt:</b> \"Find companies similar to {company_name} in the {industry} industry.\"</li><br>\n<li><b>Metadata Columns:</b> [company_name, industry]</li><br>\n<li><b>Temperature:</b> 0.7</li><br>\n<li><b>Max Tokens:</b> 512</li><br>\n<li><b>Retries:</b> 2</li><br>\n</ul><br>\n<br>\n<h3>Output:</h3><br>\nA DataFrame with a single response column:<br>\n<table border=\"1\"><br>\n<tr><th>response</th></tr><br>\n<tr><td>TechCorp (Software): - CodeZap - SoftPeak - Nexlify<br/>InnovateAI (Artificial Intelligence): - AIWorks - NeuralNest - DeepMind</td></tr><br>\n</table><br>\n<br>\n<h3>Explanation:</h3><br>\n<ul><br>\n<li>The node reads values from metadata columns and constructs a prompt for each row.</li><br>\n<li>The content and task are passed to the OpenAI LLM.</li><br>\n<li>The response is generated, cleaned of Markdown wrappers (e.g., ```json)</li><br>\n<li>The output is returned in a DataFrame as a single response string (across all rows).</li><br>\n</ul><br>",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeInteractiveLLMAgent",
      "x": "197.25px",
      "y": "366.281px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "llmConnection",
          "value": "gemini-flash2.5",
          "widget": "object_array",
          "title": "Select Connection",
          "description": "Select Connection",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "customPrompt",
          "value": "You are given transaction anomaly detection results from an Isolation Forest model.  \nColumn: `isolated_prediction` (value less than 6 = anomaly,  equal or more than 6 = good).  \n\n\nYour tasks are:  \n1. Identify the **top 5 vendors** with the **highest number of anomalies** (isolated_prediction < 6) and strictly ignore good transactions which are (isolated_prediction > 6).  \n2. For each vendor, perform a **Root Cause Analysis (RCA)** highlighting key reasons (e.g., duplicate invoices, odd hours, abnormal amounts, contract deviations).  \n3. Provide **3 actionable insights** per vendor on how to reduce anomalies or improve fraud prevention.  \n4. Present the output in a **neat, structured HTML table** with:  \n   - Vendor ID in **bold blue text**.  \n   - RCA column in **red text**.  \n   - Actionable Insights column in **green text with bullet points**.  \n   - Table styled with borders and alternating row colors.  \n5. Add one **Overall Recommendation** row at the bottom summarizing common mitigation strategies across all vendors.  \n6. Keep the tone concise, business-oriented, and suitable for risk & compliance teams.  \n\n\nMake sure to return **only the HTML table output** so it can be directly rendered in the app.  \n\n\nUse the following example as a reference for structure, formatting, and colors:\n\n\n```html\n<table border=\"1\" cellspacing=\"0\" cellpadding=\"6\" style=\"border-collapse:collapse; font-family:Arial; font-size:14px; width:100%;\">\n  <thead style=\"background:#f3f4f6;\">\n    <tr>\n      <th>Vendor ID</th>\n      <th>Root Cause Analysis (RCA)</th>\n      <th>Actionable Insights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr style=\"background:#ffffff;\">\n      <td><b style=\"color:#1d4ed8;\">VENDOR_102</b></td>\n      <td style=\"color:#dc2626;\">High anomaly count due to repeated duplicate invoices with identical amounts submitted on the same date.</td>\n      <td style=\"color:#16a34a;\">\n        <ul>\n          <li>Enable duplicate invoice checks before approval.</li>\n          <li>Set vendor-level spending thresholds with automated alerts.</li>\n          <li>Mandate secondary approval for invoices over 50K.</li>\n        </ul>\n      </td>\n    </tr>\n    <tr style=\"background:#f9fafb;\">\n      <td><b style=\"color:#1d4ed8;\">VENDOR_208</b></td>\n      <td style=\"color:#dc2626;\">Anomalies linked to invoices raised outside business hours (2–4 AM) and irregular unit pricing.</td>\n      <td style=\"color:#16a34a;\">\n        <ul>\n          <li>Restrict invoice submission to business hours.</li>\n          <li>Introduce unit-price validation rules against contract.</li>\n          <li>Investigate vendor system access logs for off-hour activity.</li>\n        </ul>\n      </td>\n    </tr>\n    <tr style=\"background:#ffffff;\">\n      <td><b style=\"color:#1d4ed8;\">VENDOR_310</b></td>\n      <td style=\"color:#dc2626;\">Outlier invoice amounts significantly higher than peer vendors for similar services.</td>\n      <td style=\"color:#16a34a;\">\n        <ul>\n          <li>Benchmark vendor pricing against industry averages.</li>\n          <li>Route invoices >2x median price for manual review.</li>\n          <li>Negotiate revised contract terms.</li>\n        </ul>\n      </td>\n    </tr>\n    <tr style=\"background:#f9fafb;\">\n      <td><b style=\"color:#1d4ed8;\">VENDOR_415</b></td>\n      <td style=\"color:#dc2626;\">Frequent anomalies due to missing approval details and inconsistent customer IDs.</td>\n      <td style=\"color:#16a34a;\">\n        <ul>\n          <li>Mandate complete metadata before invoice submission.</li>\n          <li>Audit internal mapping of customer IDs to vendor submissions.</li>\n          <li>Automate approval workflow integration.</li>\n        </ul>\n      </td>\n    </tr>\n    <tr style=\"background:#ffffff;\">\n      <td><b style=\"color:#1d4ed8;\">VENDOR_509</b></td>\n      <td style=\"color:#dc2626;\">Suspicious clustering of invoices just below approval thresholds (9,900 when 10,000 requires extra approval).</td>\n      <td style=\"color:#16a34a;\">\n        <ul>\n          <li>Introduce random checks for invoices near threshold values.</li>\n          <li>Change approval policy to cumulative vendor spend instead of per-invoice.</li>\n          <li>Escalate to compliance for further investigation.</li>\n        </ul>\n      </td>\n    </tr>\n    <tr style=\"background:#fef2f2;\">\n      <td colspan=\"3\" style=\"text-align:center; font-weight:bold; color:#7f1d1d;\">\n        Overall Recommendation: Strengthen duplicate checks, enforce threshold-based approvals, and introduce anomaly alerts in real-time monitoring.\n      </td>\n    </tr>\n  </tbody>\n</table>",
          "widget": "textareafield",
          "title": "Prompt",
          "description": "Custom prompt to instruct the model.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "metadataCols",
          "value": "[\"Content\"]",
          "widget": "variables",
          "title": "Metadata Columns",
          "description": "Select one or more content columns to pass as input to the model.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "modelSelection",
          "value": "gemini",
          "widget": "textfield",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "googleApiKey",
          "value": "AIzaSyCyZlVU9YvdSOFRTO3FRZD0GZW9qVHdDgg",
          "widget": "textfield",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "geminiModel",
          "value": "gemini-2.5-flash",
          "widget": "textfield",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "maxTokens",
          "value": "65536",
          "widget": "textfield",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "19",
      "name": "Concat Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "71.4562px",
      "y": "356.45px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Invoice_ID\",\"Vendor_ID\",\"PO_No\",\"Item\",\"Qty_Received\",\"Qty_Billed\",\"Hours_Logged\",\"Hours_Billed\",\"Contract_Unit_Price\",\"Unit_Price\",\"Invoice_Date\",\"Bank_Account\",\"isolated_prediction\",\"item_vendor_count\",\"approver_vendor_count\",\"bank_vendor_count\",\"dup_combo_count\",\"vendor_day_invoice_count\",\"amount_per_unit\",\"receipt_missing\",\"invoice_hour\",\"invoice_day\",\"is_weekend_invoice\",\"amount_minus_expected\",\"price_ratio\",\"price_gap\",\"hours_gap_ratio\",\"hours_gap\",\"qty_gap_ratio\",\"qty_gap\",\"Invoice_Amount\",\"Delivery_Receipt_Flag\",\"Approved_By\",\"Anomaly\",\"prediction\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "Content",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "|",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "24",
      "name": "Parse JSON Col",
      "iconImage": "/images/icons/node-icon/JSON.svg",
      "description": "Parses JSON content in a given column",
      "details": "<h2> Parse JSON Column Node</h2>\n<br>\n<h4> Overview:</h4>\n<br>\nThe Parse JSON Column node parses a JSON column into individual columns. It's useful for extracting specific fields from JSON data.<br>\n<br>\n<h4> Input:</h4>\n<br>\nJSON Column Name: The name of the column containing the JSON data.<br>\nVariables: A table to define the JSON fields to extract and their corresponding data types.<br>\n<h4> Output:</h4>\n<br>\nThe node creates new columns for each specified JSON field, extracting the relevant data from the JSON column.<br>",
      "examples": "Example:<br>\n<br>\nLet's assume we have a column named json_data containing JSON data like this:<br>\n<br>\nJSON<br>\n{<br>\n  \"name\": \"John Doe\",<br>\n  \"age\": 30,<br>\n  \"city\": \"New York\"<br>\n}<br>\n<br>\nConfigure the Node:<br>\n<br>\nJSON Column Name: json_data<br>\nVariables:<br>\nInput Col: json_data<br>\nJSON Field Name: name<br>\nJSON Field Type: string<br>\nInput Col: json_data<br>\nJSON Field Name: age<br>\nJSON Field Type: integer<br>\nInput Col: json_data<br>\nJSON Field Name: city<br>\nJSON Field Type: string<br>\nNode Execution:<br>\n<br>\nThe node will create three new columns: name, age, and city, extracting the corresponding values from the json_data column.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeParseJSONColumn",
      "x": "515.587px",
      "y": "231.562px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "jsonColName",
          "value": "",
          "widget": "variable",
          "title": "JSON Col Name",
          "description": "Specifies the input column containing the JSON data",
          "datatypes": [
            "string"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCol",
          "value": "[]",
          "widget": "variables_list_select",
          "title": "Input Col",
          "description": "Input Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "jsonFieldNames",
          "value": "[]",
          "widget": "variables_list_textfield",
          "title": "JSON Field names",
          "description": "JSON Field names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "jsonFieldTypes",
          "value": "[]",
          "widget": "variables_list_array",
          "title": "JSON Field Type",
          "description": "Data Type of the JSON field",
          "optionsArray": [
            "STRING",
            "INTEGER",
            "DOUBLE",
            "FLOAT",
            "LONG",
            "BOOLEAN",
            "BYTE",
            "SHORT",
            "STRUCT",
            "ARRAY",
            "MAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "advance",
          "value": "",
          "widget": "tab",
          "title": "Advance",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "stringJsonColNames",
          "value": "[\"response\"]",
          "widget": "variables_list_select",
          "title": "String Json ColNames",
          "description": "Specifies the input column containing the JSON data",
          "datatypes": [
            "string"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputJsonColNames",
          "value": "[\"response_struct\"]",
          "widget": "variables_list_textfield",
          "title": "Output ColNames",
          "description": "uses the schema from the column you provide and create the new output column.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputSchema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"response\",\"response_struct\"]",
          "widget": "schema_col_names",
          "title": "Output Column Name",
          "description": "Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRUCT\"]",
          "widget": "schema_col_types",
          "title": "Output Column Type",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"{\\\"response_struct\\\":{\\\"fields\\\":[{\\\"metadata\\\":{},\\\"name\\\":\\\"items\\\",\\\"nullable\\\":true,\\\"type\\\":{\\\"containsNull\\\":true,\\\"elementType\\\":{\\\"fields\\\":[{\\\"metadata\\\":{},\\\"name\\\":\\\"actionable_insight\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"},{\\\"metadata\\\":{},\\\"name\\\":\\\"invoice_id\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"},{\\\"metadata\\\":{},\\\"name\\\":\\\"rca\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"},{\\\"metadata\\\":{},\\\"name\\\":\\\"vendor_id\\\",\\\"nullable\\\":true,\\\"type\\\":\\\"string\\\"}],\\\"type\\\":\\\"struct\\\"},\\\"type\\\":\\\"array\\\"}}],\\\"type\\\":\\\"struct\\\"}}\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Format",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "25",
      "name": "Flatten",
      "iconImage": "fa fa-tumblr-square",
      "description": "",
      "details": "",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFlatten",
      "x": "625.794px",
      "y": "234.769px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "ids",
          "value": "[\"00\"]",
          "widget": "flatten_ids",
          "title": "Id",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values1",
          "value": "[\"response_struct.items\"]",
          "widget": "flatten_value1",
          "title": "Input Colums",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values2",
          "value": "[\"items\"]",
          "widget": "flatten_value2",
          "title": "OutputColumns",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values3",
          "value": "[\"array\"]",
          "widget": "flatten_value3",
          "title": "OutputColumnsType",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "26",
      "name": "Flatten",
      "iconImage": "fa fa-tumblr-square",
      "description": "",
      "details": "",
      "examples": "",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFlatten",
      "x": "843.756px",
      "y": "239.787px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "ids",
          "value": "[\"00\",\"01\",\"02\",\"03\"]",
          "widget": "flatten_ids",
          "title": "Id",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values1",
          "value": "[\"items_explode.actionable_insight\",\"items_explode.invoice_id\",\"items_explode.rca\",\"items_explode.vendor_id\"]",
          "widget": "flatten_value1",
          "title": "Input Colums",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values2",
          "value": "[\"actionable_insight\",\"invoice_id\",\"rca\",\"vendor_id\"]",
          "widget": "flatten_value2",
          "title": "OutputColumns",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values3",
          "value": "[\"string\",\"string\",\"string\",\"string\"]",
          "widget": "flatten_value3",
          "title": "OutputColumnsType",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "27",
      "name": "Explode",
      "iconImage": "fa fa-tumblr-square",
      "description": "Explode the array of values into multiple rows with columnname_explode.",
      "details": "<h2> Explode Node</h2>\n<br>\nThis node explodes a column containing arrays or maps into multiple rows, creating a new row for each element in the array or map. This is useful for flattening nested data structures.<br>",
      "examples": "<h2> Explode Node Example</h2>\n<br>\nGiven the following dataset:<br>\n<br>\nProductID\tProductName\tCategories<br>\nP1\tLaptop\t[\"Electronics\", \"Computers\"]<br>\nP2\tPhone\t[\"Electronics\", \"Mobile\"]<br>\n<br>\nIf we configure the Explode Node to explode the Categories column, the output would look like this:<br>\n<br>\nProductID\tProductName\tCategories<br>\nP1\tLaptop\tElectronics<br>\nP1\tLaptop\tComputers<br>\nP2\tPhone\tElectronics<br>\nP2\tPhone\tMobile<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExplode",
      "x": "728.763px",
      "y": "235.794px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"items\"]",
          "widget": "variables",
          "title": "Input Colums",
          "description": "Select the columns to be exploded.",
          "datatypes": [
            "array"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "28",
      "name": "Drop Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by dropping the specified columns",
      "details": "<h2>Drop Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame by dropping the selected columns.<br>\n<br>\nIt drops the selected columns from the outgoing dataframe. <br>\n<br>\nColumns that need to be dropped are to be selected in the 'Selected' list. Multiple columns can be selected in the list that needs to be dropped.<br>",
      "examples": "<h2>Drop Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe having following columns:<br>\n<br>\n<ul>\n<li> CUST_CD</li>\n<li> CUST_NAME</li>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>\n<h4>Drop Columns Node Configuration And Output</h4>\n<br>\n[DOB] and [ADDRESS] columns are selected to be dropped from the outgoing Dataframe. <br>\nOutgoing dataframe would contain only below two columns after dropping the selected columns:<br>\n<br>\n<ul>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropColumns",
      "x": "960.75px",
      "y": "237.775px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropCols",
          "value": "[\"response\",\"response_struct\",\"items\",\"items_explode\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "The columns to be excluded from the output DataFrame",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "29",
      "name": "Save CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "Saves the DataFrame into the specified location in CSV Format",
      "details": "This node saves incoming Dataframe into the specified location in CSV format.<br>",
      "examples": "path-folder1/folder2/filename<br>\n<br>\nthe file will be saved under the file name at the path provided<br>\nif folder is not present it will be created and save the file<br>\nif the file already exists selection in save mode determines what happens to the file,append-adds the file data to it overwrite-replaces the file altogether<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveCSV",
      "x": "1192.98px",
      "y": "244.969px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/MANUFACTURING/Fraudulent-Transaction-Processing-AI-ML/Billing-Fraud/shaply-insight/",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the CSV files",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "enableDownloadLink",
          "value": "false",
          "widget": "array_single",
          "title": "Enable Download Link",
          "description": "Generate download links for the saved CSV files",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileName",
          "value": "",
          "widget": "textfield",
          "wdgtCommon": "enableDownloadLink",
          "title": "File Name To Download",
          "description": "Enter the FileName",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": "true"
        },
        {
          "name": "saveAsOneFile",
          "value": "false",
          "widget": "array",
          "title": "Save as One File",
          "description": "Save the output as a single CSV file using coalesce",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "30",
      "name": "Select Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "1075.57px",
      "y": "237.594px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "[\"invoice_id\",\"vendor_id\",\"rca\",\"actionable_insight\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "31",
      "name": "Print N Rows",
      "iconImage": "/images/icons/node-icon/print_n_rows.svg",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "455.194px",
      "y": "89.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "LLM",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "n",
          "value": "10000",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "32",
      "name": "Print N Rows",
      "iconImage": "/images/icons/node-icon/print_n_rows.svg",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "1161.2px",
      "y": "113.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "Final Table",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "n",
          "value": "10000",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "33",
      "name": "Sticky Note",
      "iconImage": "fa fa-file-text",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "422px",
      "y": "397px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "bgColor",
          "value": "blue",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "width",
          "value": "526px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "height",
          "value": "107px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "comment",
          "value": "<p><span style=\"color: rgb(0, 0, 0);\">This workflow takes vendor invoice data, uses an LLM to generate root cause analyses and actionable recommendations for anomalies, then structures the output into a clean CSV report.</span></p>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "disabled": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "2",
      "target": "3",
      "id": 1
    },
    {
      "source": "5",
      "target": "4",
      "id": 2
    },
    {
      "source": "19",
      "target": "5",
      "id": 3
    },
    {
      "source": "24",
      "target": "25",
      "id": 4
    },
    {
      "source": "25",
      "target": "27",
      "id": 5
    },
    {
      "source": "27",
      "target": "26",
      "id": 6
    },
    {
      "source": "26",
      "target": "28",
      "id": 7
    },
    {
      "source": "28",
      "target": "30",
      "id": 8
    },
    {
      "source": "30",
      "target": "29",
      "id": 9
    },
    {
      "source": "1",
      "target": "2",
      "id": 10
    },
    {
      "source": "1",
      "target": "19",
      "id": 11
    },
    {
      "source": "3",
      "target": "31",
      "id": 12
    },
    {
      "source": "30",
      "target": "32",
      "id": 13
    },
    {
      "source": "3",
      "target": "24",
      "id": 14
    }
  ],
  "dataSetDetails": [],
  "engine": "pyspark"
}