{
  "name": "Generate ICF",
  "uuid": "f0590de9-5ef3-4232-ae1c-3ca7d276ac1a",
  "category": "-",
  "description": "-",
  "parameters": " --var textField1=CSP --var destinationPath1=/home/sparkflows/fire-data/Spotline/CSP/uploads/ --var textField=CSP --var refresh=true --var view4=false --var folderPath=/home/sparkflows/fire-data/Spotline/CSP/uploads/CSP06.pdf --var folderPath3='/home/sparkflows/fire-data/Spotline/CSP/uploads/CSP06.pdf' --var destinationPath=/home/sparkflows/fire-data/Spotline/CSP/uploads/ --var all=false --var toc='Synopsis','Introduction','Background','Evidence supporting our hypothesis for this study is presented below.','Objectives and Endpoints','Study Population','Study Intervention','Study Assessment and Procedures','Supporting Documentation and Operational Considerations' --var generateIcf=true --var generateIcf1=false --var selectExecution=1 --var refresh1=false --var folderPath2=/home/sparkflows/fire-data/Spotline/CSP/output/PLPS --var folderPath1=/home/sparkflows/fire-data/Spotline/CSP/output/ICF/ --var checkbox2=false --var view2=false --var download=false",
  "nodes": [
    {
      "id": "1",
      "name": "ICF Generator",
      "description": "This node runs any given PySpark code. The input dataframe is passed into the function myfn as a parameter.",
      "details": "",
      "examples": "",
      "type": "pyspark",
      "nodeClass": "fire.nodes.etl.NodePySpark",
      "x": "237.333px",
      "y": "79.3333px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "code",
          "value": "'''\nInput:\n  spark: spark session \n  workflowContext:  workflowcontext object \n  id: node number \n  inDF: input pyspark dataframe \n  cust_dict: Dictionary of the workflow variables passed from previous node \nOutput:\n  outDF: return pyspark dataframe i.e outDF \n ''' \n \nfrom pyspark.sql.types import * \nfrom pyspark.sql.functions import * \nfrom pyspark.sql import * \nfrom fire.workflowcontext import WorkflowContext\nfrom bs4 import BeautifulSoup\nimport pymupdf\nimport pandas as pd\nimport re\nfrom xhtml2pdf import pisa\nfrom io import BytesIO\n\ndef html_to_pdf(html_string, output_filename):\n    with BytesIO() as pdf_buffer:\n        pisa.CreatePDF(BytesIO(html_string.encode('utf-8')), dest=pdf_buffer)\n        pdf_buffer.seek(0)\n        with open(output_filename, 'wb') as output_file:\n            output_file.write(pdf_buffer.read())\n\n\ndef save_list_to_txt(file_path1, string_list):\n    with open(file_path1, 'w') as file:\n        for item in string_list:\n            file.write(item + ', \\n')\n\ndef extract_text_from_pdf(pdf_path):\n    # Open the PDF file\n    document = pymupdf.open(pdf_path)\n    text = \"\"\n    # Iterate over each page in the PDF\n    for page_num in range(document.page_count):\n        # Get a page\n        page = document[page_num]\n        # Extract text from the page\n        text += page.get_text()\n    # Close the PDF file\n    document.close()\n    return text\n  \ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict:dict):\n      # Path to your PDF file\n      # pdf_path = '/home/sparkflows/fire-data/Spotline/Clinical-Study-Protocols/Prot_000.pdf'\n    import glob\n    # mylist = [f for f in glob.glob(\"/home/sparkflows/fire-data/Spotline/CSP/uploads/*.pdf\")]\n    # pdf_path = \"${folderPath3}\"# mylist[0]\n      # Extract text\n    pdf_text = extract_text_from_pdf(\"${folderPath}\")\n    with open('/home/sparkflows/fire-data/Spotline/CSP/output/TOC_output/Table_of_content.txt', 'r', encoding='utf-8') as file:\n        html_content = file.read()\n    h2_pattern = r'<h2[^>]*>(.*?)</h2>'\n    h2_tags = re.findall(h2_pattern, html_content, re.DOTALL)\n    List1 = []\n    for h2 in h2_tags:\n        List1.append(h2.strip())    \n    input_string = \"${toc}\"\n    # print(List1, \"List1\")\n    extracted_text = re.findall(r\"'(.*?)'\", input_string)\n    select_topic = extracted_text\n    # ['TRIAL SUMMARY','TRIAL DESIGN','OBJECTIVE(S) & HYPOTHESIS(ES)','BACKGROUND & RATIONALE','METHODOLOGY','TRIAL FLOW CHART','TRIAL PROCEDURES','TRIAL GOVERNANCE AND OVERSIGHT','STATISTICAL ANALYSIS PLAN','LABELING, PACKAGING, STORAGE AND RETURN OF CLINICAL SUPPLIES','ADMINISTRATIVE AND REGULATORY DETAILS','LIST OF REFERENCES','APPENDICES','SIGNATURES'] \n    # [\"${selectBoxes}\"]\n    #'METHODOLOGY', 'STATISTICAL ANALYSIS PLAN']\n    \n    \n    # Extract the last line after the final full stop\n    last_line = pdf_text.split('.')[-1].strip().split('\\n')[-1].strip()\n    \n    # Create the list of lists by matching the selected topics\n    output = []\n    for topic in select_topic:\n        if topic in List1:\n            index = List1.index(topic)\n            # Ensure there's a next element in the list\n            if index + 1 < len(List1):\n                output.append([List1[index], List1[index + 1]])\n            else:\n                # For the last item, add the extracted last line instead of the full sentence\n                output.append([List1[index], last_line])\n    \n    def extract_all_text_between_headings(text, start_heading, end_heading):\n        # Regular expression to extract all text between headings\n        pattern = re.compile(\n            rf'{re.escape(start_heading)}(.*?){re.escape(end_heading)}',\n            re.DOTALL | re.IGNORECASE  # Case-insensitive matching\n        )\n        \n        # Find all matches\n        matches = pattern.findall(text)\n        # Clean up the matches (strip leading/trailing whitespace)\n        cleaned_matches = [match.strip() for match in matches]\n        \n        return cleaned_matches\n    \n    selected_text = []\n    # Define your headings\n    for i in output:\n        start_heading = i[0]\n        end_heading = i[1]\n        \n        # Extract all occurrences of text between headings\n        all_texts = extract_all_text_between_headings(pdf_text, start_heading, end_heading)\n        \n        def get_max_length_sentence(sentences):\n            \"\"\"\n            Returns the longest sentence (by character length) from a list of sentences.\n            Parameters:\n            sentences (list): A list of sentences (strings).\n            Returns:\n            str: The sentence with the maximum length. Returns None if the list is empty.\n            \"\"\"\n            if not sentences:  # Check if the list is empty\n                return None  # Return None if the list is empty\n            # Find the sentence with the maximum length manually\n            max_sentence = sentences[0]\n            for sentence in sentences[1:]:\n                if len(sentence) > len(max_sentence):\n                    max_sentence = sentence\n            return max_sentence\n        \n        longest_sentence = get_max_length_sentence(all_texts)\n        selected_text.append(longest_sentence)\n    GOOGLE_API_KEY='$Gemini_API'\n    import json\n    import requests\n    payload = {\n            \"contents\": [\n                {\n                    \"parts\": [\n                        {\"text\": f\"\"\"You are a very good principal investigator. Your work is to create Informed consent forms (ICF). Output must follow html format and make sure output must be more then 10000 words\n     Here is the pdf text:\n     {selected_text}\n     1. Study Overview and Objectives\n\tPrompt: Write a clear and concise summary of the study, including the purpose and objectives of the research. Highlight the study title, the investigational device or drug being tested, and the reason for conducting the study. Reference the specific details from the clinical study protocol document. Make sure to include any relevant background information from the protocol that justifies the study's need.\n\t2. Study Duration and Participant Commitment\n\tPrompt: Describe the expected duration of the study, including the total time commitment for the participant. Specify the different phases of the study and what is expected during each phase, referencing the detailed phases from the clinical study protocol. Include details about the number of visits, follow-ups, and any additional monitoring required.\n\t3. Participant Eligibility Criteria\n\tPrompt: Outline the inclusion and exclusion criteria for participation in the study. Use the detailed criteria provided in the clinical study protocol to ensure accuracy. Ensure that this section is clear and accessible, highlighting any conditions or medications that would make someone ineligible for the study.\n\t4. Study Procedures\n\tPrompt: Provide a detailed description of the study procedures that participants will undergo. Include information on tests, treatments, and any devices or drugs that will be used, as per the clinical study protocol. Ensure this section breaks down complex procedures into understandable steps for participants. For example, detail blood tests, use of investigational devices, and follow-up activities.\n\t5. Potential Risks and Discomforts\n\tPrompt: Describe the potential risks and discomforts that participants might experience during the study. This should be based on the clinical study protocol's risk section, ensuring that risks are communicated in layman's terms. Include any physical, psychological, or privacy-related risks that the study could pose.\n\t6. Potential Benefits\n\tPrompt: Explain the possible benefits to participants, including any direct benefits (e.g., potential health improvements) and indirect benefits (e.g., contributing to medical knowledge). Use information from the clinical study protocol to ensure this section accurately reflects the study's potential impact.\n\t7. Alternative Treatments\n\tPrompt: Include a section outlining any alternative treatments available to the participants outside of the study. This information should be drawn from the clinical study protocol's section on standard care or alternative options.\n\t8. Confidentiality and Data Protection\n\tPrompt: Describe how participant data will be protected and kept confidential throughout the study. Reference the specific data protection measures outlined in the clinical study protocol, and ensure that participants understand their rights regarding their data.\n\t9. Voluntary Participation and Withdrawal\n\tPrompt: Emphasize that participation in the study is voluntary and that participants can withdraw at any time without penalty. Use the language from the guidelines to ensure this is clearly communicated.\n\t10. Contact Information for Questions or Concerns\n\tPrompt: Provide contact information for the study team, including the primary investigator and any other relevant staff members. Include the details from the clinical study protocol document to ensure accuracy.\n\t11. Emergency Procedures and Compensation for Injury\n\tPrompt: Outline the steps that will be taken if a participant is injured during the study. This should be based on the compensation and emergency procedures outlined in the clinical study protocol. Be sure to include who will cover medical costs and how to contact the study team in case of emergency.\n\t12. Participant's Consent and Signature Page\n\tPrompt: Create a clear section for participants (or their legal representatives) to provide their consent. Ensure that there is space for signatures and dates, following the format used in the example ICF.\n     \"\"\"}\n                    ]\n                }\n            ],\n        }\n        \n    model1 = \"gemini-1.5-pro-exp-0801\"\n    model2 = \"gemini-1.5-flash\"\n    response = requests.post(f\"https://generativelanguage.googleapis.com/v1beta/models/{model2}:generateContent?key={GOOGLE_API_KEY}\", data=json.dumps(payload))\n    ahtml = response.json()[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"].replace(\"\\n\",\"\")\n    filenames = \"ICF_\"+\"${folderPath}\".split(\"/\")[-1] # .format(pd.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\"))\n    output_path = '/home/sparkflows/fire-data/Spotline/CSP/output/ICF/'+filenames\n    html_to_pdf(ahtml, output_path)\n    output_path1 = '/home/sparkflows/fire-data/Spotline/CSP/output/ICF_Txt_Output/ICF_Data.txt'\n    with open(output_path1, \"w\") as text_file:\n      text_file.write(ahtml)\n    workflowContext.outStr(3,\"Saved file at : \"+output_path1,\"Saved Summaries\")\n    return",
          "widget": "textarea_large",
          "type": "python",
          "title": "PySpark",
          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "Schema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Column Names",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    }
  ],
  "edges": [],
  "dataSetDetails": [],
  "engine": "pyspark"
}