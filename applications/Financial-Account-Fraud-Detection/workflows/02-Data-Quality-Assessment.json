{
  "name": "02-Data-Quality-Assessment",
  "uuid": "3757c70d-611b-4303-bcea-31b21ccc031a",
  "category": "DataQuality",
  "nodes": [
    {
      "id": "1",
      "name": "Dataset Structured",
      "description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset was defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",
      "details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",
      "examples": "<h2> Dataset Structured Node Example</h2>\n<br>\nScenario:<br>\n<br>\nLet's say you have multiple datasets available in your workflow and you want to select one of them as input for the next node. You can use the Dataset Structured node to choose the desired dataset.<br>\n<br>\nConfiguration:<br>\n<br>\n1. **Output Storage Level:** Select the desired storage level for the output DataFrame.<br>\n2. **Dataset:** Choose the dataset from the dropdown list.<br>\n<br>\nOutput:<br>\n<br>\nThe node will output the selected dataset as a DataFrame.<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "132.653px",
      "y": "268.653px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dataset",
          "value": "cd2bc81a-8064-47ee-898a-158ab6396523",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "2",
      "name": "ExpectColumnValuesToBeUnique",
      "description": "",
      "details": "<h2>Expect Column Values To Be Unique Details</h2>\n<br>\nExpect each column value to be unique.<br>\n<br>\nThis expectation detects duplicates. All duplicated values are counted as exceptions.<br>\n<br>\n<h4>Keyword Args</h4>\n<br>\nColumn Name: The column name<br>\nMostly (None or a float between 0 and 1): Return `success`: True if at least mostly fraction of values match the expectation.<br>",
      "examples": "<h2>Example</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    DEPT        |<br>\n--------------------------------------<br>\nE01       |    MARKETING   |<br>\nE02       |    MARKETING   |<br>\nE03       |    SALES       |<br>\nE04       |    ADMIN       |<br>\n<br>\n<h4>Configuration</h4>\n<br>\nColumn Name   | Mostly  |<br>\n-------------------------<br>\nEMP_CD        |         |<br>\nDEPT          | 0.75    |           <br>\n<br>\nThe above setup would result in a status of `success: true` as both conditions are satisfied.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ge.NodeExpectColumnValuesToBeUnique",
      "x": "298.431px",
      "y": "155.417px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "cols",
          "value": "[\"ACCT_ID_TOKEN\",\"AUTH_ID\"]",
          "widget": "variables_list_select",
          "title": "Column Name",
          "description": "The column name.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mostly",
          "value": "[\"\",\"\"]",
          "widget": "variables_list_textfield",
          "title": "Mostly",
          "description": "Mostly value is between 0 and 1, and evaluates it as a percentage and as long as mostly percent of rows evaluate to True, the expectation returns “success”: True.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "3",
      "name": "ExpectColumnValuesToNotBeNull",
      "description": "",
      "details": "<h2>Expect Column Values To Not Be Null Details</h2>\n<br>\nExpect the column values to not be null.<br>\n<br>\nTo be counted as an exception, values must be explicitly null or missing, such as an np.NaN in pandas. Empty strings don't count as null unless they have been coerced to a null type.<br>\n<br>\n<h4>Keyword Args</h4>\n<br>\nColumn Name: The column name<br>\nMostly (None or a float between 0 and 1): Return `success`: True if at least mostly fraction of values match the expectation.<br>",
      "examples": "<h2>Example</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |<br>\n--------------------------------------<br>\nE01       |    DAVID       |<br>\nE02       |                |<br>\nE03       |    MARK        |<br>\nE04       |    JACK        |<br>\n<br>\n<h4>Configuration</h4>\n<br>\nColumn Name   | Mostly  |<br>\n-------------------------<br>\nEMP_CD        |         |<br>\nEMP_NAME      | 0.8     |           <br>\n<br>\nThe above setup would result in a status of `success: false`, as even though the `EMP_CD` column value evaluates to be true it fails for the condition setup for the column `EMP_NAME`.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ge.NodeExpectColumnValuesToNotBeNull",
      "x": "440.653px",
      "y": "259.653px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "cols",
          "value": "[\"ACCT_AVL_CASH_BEFORE_AMT\",\"ACCT_AVL_MONEY_BEFORE_AMT\",\"ACCT_CL_AMT\",\"ACCT_CURR_BAL\",\"ACCT_PROD_CD\",\"APPRD_AUTHZN_CNT\",\"APPRD_CASH_AUTHZN_CNT\",\"AUTHZN_AMT\",\"AUTHZN_OUTSTD_AMT\",\"AUTHZN_OUTSTD_CASH_AMT\",\"AVG_DLY_AUTHZN_AMT\",\"CDHLDR_PRES_CD\",\"DISTANCE_FROM_HOME\",\"HOME_PHN_NUM_CHNG_DUR\",\"HOTEL_STAY_CAR_RENTL_DUR\",\"LAST_ADR_CHNG_DUR\",\"PLSTC_ISU_DUR\"]",
          "widget": "variables_list_select",
          "title": "Column Name",
          "description": "The column name.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mostly",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "variables_list_textfield",
          "title": "Mostly",
          "description": "Mostly value is between 0 and 1, and evaluates it as a percentage and as long as mostly percent of rows evaluate to True, the expectation returns “success”: True.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "4",
      "name": "ExpectColumnValuesToBeInSet",
      "description": "",
      "details": "<h2> Expect Column Values To Be In Set Details</h2>\n<br>\nThis feature allows users to validate that column values in a DataFrame are within a specified set of values. It helps ensure data quality by restricting column values to predefined acceptable options.<br>\n<br>\n<h4> Input</h4>\n<br>\nColumn Name: Select the column that needs to be validated. The column type should match the expected data type.<br>\nValues: Enter the set of values that are acceptable for the selected column.<br>\nMostly: Specifies the minimum percentage (0.0 - 1.0) of rows that must meet the condition for it to pass validation.<br>\n<h4> Output</h4>\n<br>\nA DataFrame with validation results, indicating whether each row's value in the specified column is within the acceptable set.<br>\nThe validation status can be used to filter or further process data based on quality checks.<br>",
      "examples": "Example: If a column named \"Status\" in the DataFrame is expected to contain only \"Approved,\" \"Pending,\" or \"Rejected,\" set the Values field to [\"Approved\", \"Pending\", \"Rejected\"]. This configuration ensures that any other value in the \"Status\" column will be flagged for review.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ge.NodeExpectColumnValuesToBeInSet",
      "x": "605.653px",
      "y": "128.653px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "cols",
          "value": "[\"APPRD_CASH_AUTHZN_CNT\",\"CDHLDR_PRES_CD\",\"HOTEL_STAY_CAR_RENTL_DUR\",\"POS_COND_CD\",\"POS_ENTRY_MTHD_CD\"]",
          "widget": "variables_list_select",
          "title": "Column Name",
          "description": "The column name.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values",
          "value": "[\"0;1\",\"0;1;2;3;4;5\",\"0;1\",\"0;1;2;6;8;52\",\"1;2;81;90\"]",
          "widget": "variables_list_textfield",
          "title": "values",
          "description": "A set of objects seperated by semicolon used for comparison..",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mostly",
          "value": "[\"\",\"\",\"\",\"\",\"\"]",
          "widget": "variables_list_textfield",
          "title": "Mostly",
          "description": "Mostly value is between 0 and 1, and evaluates it as a percentage and as long as mostly percent of rows evaluate to True, the expectation returns “success”: True.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "6",
      "name": "Create CSV from GE Results",
      "description": "",
      "details": "<h2> Create CSV from GE Results Node</h2>\n<br>\n<h4> Overview:</h4>\n<br>\nThis node writes the output of a GE pipeline to a CSV file. It offers flexibility in configuring the output file's path, save mode, and whether to include a header row.<br>\n<br>\n<h4> Input:</h4>\n<br>\nPath: The desired path for the output CSV file.<br>\nSave Mode: Determines how to handle existing files:<br>\nAppend: Appends new data to the end of an existing file.<br>\nOverwrite: Overwrites the file with the new data.<br>\nErrorIfExists: Throws an error if the file already exists.<br>\nHeader: Specifies whether to include a header row with column names.<br>\n<br>\n<h4> Output:</h4>\n<br>\nThe node writes the output DataFrame to the specified CSV file.<br>",
      "examples": "Example:<br>\n<br>\nLet's say you have a DataFrame containing customer data and want to save it as a CSV file.<br>\n<br>\nConfigure the Node:<br>\n<br>\nPath: /path/to/output.csv<br>\nSave Mode: Append<br>\nHeader: True<br>\nNode Execution:<br>\n<br>\nThe DataFrame will be written to the specified CSV file, appending new data if the file already exists. The output file will include a header row with column names.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ge.NodeCreateCsvFromGeResults",
      "x": "713.778px",
      "y": "250.778px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "csvPath",
          "value": "data/BFSI/Financial-Account-Fraud-Detection/Quality",
          "widget": "textfield",
          "title": "Path",
          "description": "Path to save consolidated Great Expectation results as a CSV",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "false",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "7",
      "name": "Print N Rows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "856.778px",
      "y": "133.778px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "title",
          "value": "Row Values",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "displayDataType",
          "value": "true",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "8",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "13px",
      "y": "7px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "bgColor",
          "value": "blue",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "width",
          "value": "377.222222px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "height",
          "value": "123.222222px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "comment",
          "value": "<p><strong>Data Quality</strong></p><ol><li><strong>Unique Column Check</strong></li><li><strong>Not Null Column Check</strong></li><li><strong>Categorical columns' set value check</strong></li></ol>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "1",
      "target": "2",
      "id": 1
    },
    {
      "source": "2",
      "target": "3",
      "id": 2
    },
    {
      "source": "3",
      "target": "4",
      "id": 3
    },
    {
      "source": "4",
      "target": "6",
      "id": 4
    },
    {
      "source": "6",
      "target": "7",
      "id": 5
    }
  ],
  "dataSetDetails": [
    {
      "id": 2226,
      "uuid": "cd2bc81a-8064-47ee-898a-158ab6396523",
      "header": true,
      "path": "data/BFSI/Financial-Account-Fraud-Detection/Raw-Data",
      "delimiter": ",",
      "datasetType": "CSV",
      "datasetSchema": "{\"colNames\":[\"AUTH_ID\",\"ACCT_ID_TOKEN\",\"ACCT_PROD_CD\",\"ACCT_AVL_CASH_BEFORE_AMT\",\"ACCT_AVL_MONEY_BEFORE_AMT\",\"ACCT_CL_AMT\",\"ACCT_CURR_BAL\",\"APPRD_AUTHZN_CNT\",\"APPRD_CASH_AUTHZN_CNT\",\"AUTHZN_AMT\",\"AUTHZN_OUTSTD_AMT\",\"AVG_DLY_AUTHZN_AMT\",\"AUTHZN_OUTSTD_CASH_AMT\",\"CDHLDR_PRES_CD\",\"HOTEL_STAY_CAR_RENTL_DUR\",\"LAST_ADR_CHNG_DUR\",\"HOME_PHN_NUM_CHNG_DUR\",\"PLSTC_ISU_DUR\",\"POS_COND_CD\",\"POS_ENTRY_MTHD_CD\",\"DISTANCE_FROM_HOME\",\"FRD_IND\"],\"colTypes\":[\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"INTEGER\"],\"colFormats\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"colMLTypes\":[\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\"]}"
    }
  ],
  "engine": "pyspark"
}