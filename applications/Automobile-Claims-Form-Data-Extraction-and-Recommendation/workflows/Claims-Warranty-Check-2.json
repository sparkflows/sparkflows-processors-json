{
  "name": "Claims-Warranty-Check-2",
  "uuid": "79f345f1-ffdd-4de7-8f0a-8b60f9ce1266",
  "category": "-",
  "parameters": " --var getStarted=true --var destinationPath=/home/sparkflows/fire-data/data/GENAI/Automobile-Claims-Warranty/Claims/Claim_Form_1_John_Doe.pdf --var GenAIReport=true",
  "nodes": [
    {
      "id": "1",
      "name": "Document To Text",
      "iconImage": "/images/icons/node-icon/PDF.svg",
      "description": "The DocumentToText node extracts text content from documents, including PDF, TXT, DOCX, and image files, located in a specified file path or directory. It processes either a single file or an entire directory, producing a structured DataFrame with columns for the extracted text, file name, page numbers, and optionally, base64-encoded data for PDFs and images.",
      "details": "<h2>DocumentToText Node Details</h2><br>\nThe DocumentToText node extracts text content from documents, including PDF, TXT, DOCX, and image files, located in a specified file path or directory. It processes either a single file or an entire directory, producing a structured DataFrame with columns for the extracted text, file name, page numbers, and optionally, base64-encoded data for PDFs and images.<br>\n<br>\n<br>\n<h4>General:</h4><br>\n<br>\n<h5>Directory/File Path:</h5> Specifies the path to a single document file or a directory containing multiple documents. This field is required and must be accessible to the PySpark engine.<br>\n<br>\n<h5>Document Type:</h5> Selects the types of documents to process. Options include:<br>\n<br>\n<ul>\n<li> pdf: Processes PDF files, extracting text and optionally converting pages to base64-encoded images.</li>\n<li> txt: Processes plain text files, extracting text only.</li>\n<li> docx: Processes Microsoft Word documents, extracting text only.</li>\n<li> image: Processes image files (e.g., PNG, JPEG) for text extraction via OCR, with optional base64 encoding.</li>\n</ul>\nIf left empty, the node processes all supported file types (PDF, TXT, DOCX, and images) in the specified path.<br>\n<br>\n<br>\n<h5>Select Image Column:</h5> Specifies a column containing paths to image files when processing images. This is optional and only required if image paths are provided in a DataFrame column rather than the directory path.<br>\n<br>\n<h5>Image Encoding:</h5> Determines whether to include a column with base64-encoded data for PDFs and images. Options are:<br>\n<ul>\n<li> true: Adds a column with base64-encoded representations of PDF pages and image files.</li>\n<li> false: Does not include base64-encoded data (default).</li>\n</ul>\nNote: TXT and DOCX files are not converted to base64 encodings, even if this option is enabled.<br>\n<br>\n<br>\n<h4>Recursive Processing:</h4><br>\n<h5>Recursive:</h5> Controls whether the node processes documents in subdirectories. Options are:<br>\n<ul>\n<li> true: Recursively processes all documents in the specified directory and its subdirectories.</li>\n<li> false: Processes only documents directly in the specified directory (default).</li>\n</ul>\n<br>\n<h4>Output Storage:</h4><br>\n<h5>Save Images Directory Path:</h5> Specifies a directory path to save extracted images (for PDFs and image files) when Image Encoding is enabled. This is optional and relevant for storing extracted image data.<br>\n<br>\n<h4>Output:</h4><br>\nThe node outputs a DataFrame with the following default columns:<br>\n<br>\n<ul>\n<li> fileName: The name of the source file.</li>\n<li> content: The extracted text content from the document.</li>\n<li> pageNumber:> The page number of the extracted content (for multi-page documents like PDFs; single-page documents like TXT, DOCX, and images use page number 1).</li>\n<li> If Image Encoding is set to true, a base64ImageData column is included for PDFs and images, containing base64-encoded representations of the pages or images. TXT and DOCX files will have null in this column.</li>\n</ul>",
      "examples": "<h2> Example: DocumentToText Node</h2>\n<br>\n<h3> Input:</h3>\nA directory /data/documents/ contains the following files:<br>\n- report.pdf (a 2-page PDF document)<br>\n- notes.txt (a plain text file)<br>\n- proposal.docx (a Microsoft Word document)<br>\n- chart.png (an image file with text)<br>\n<br>\nThe DocumentToText node is configured as follows:<br>\n<ul>\n<li> Directory/File Path: /data/documents/</li>\n<li> Document Type: [\"pdf\", \"txt\", \"docx\", \"image\"] (process all supported types)</li>\n<li> Select Image Column: Empty (no specific image column; uses file path for images)</li>\n<li> Image Encoding: true (includes base64-encoded data for PDFs and images)</li>\n<li> Recursive: false (processes only files in the specified directory)</li>\n<li> Save Images Directory Path: /data/output/images/</li>\n</ul>\n<h3> Output:</h3>\nThe node processes the files and produces a DataFrame with the following structure:<br>\n<br>\nfileName       | content                              | pageNumber | base64ImageData<br>\n---------------|--------------------------------------|------------|----------------------------------<br>\nreport.pdf     | This is page 1 of the report...      | 1          | iVBORw0KGgoAAAANSUhEUg...<br>\nreport.pdf     | This is page 2 of the report...      | 2          | iVBORw0KGgoAAAANSUhEUg...<br>\nnotes.txt      | Meeting notes: discuss project...    | 1          | null<br>\nproposal.docx  | Proposal for new project...          | 1          | null<br>\nchart.png      | Sales: Q1 2025...                    | 1          | iVBORw0KGgoAAAANSUhEUg...<br>\n<br>\n<h3> Explanation:</h3>\n- The report.pdf file is processed, extracting text from both pages, resulting in two rows (one per page). With Image Encoding set to true, each page is also converted to a base64-encoded image in the base64ImageData column.<br>\n- The notes.txt file is processed as a single-page document, with its text extracted into the content column. No base64 encoding is applied, so base64ImageData is null.<br>\n- The proposal.docx file is processed, extracting its text content into a single row. No base64 encoding is applied, so base64ImageData is null.<br>\n- The chart.png file is processed using OCR to extract text, and its base64-encoded image data is included in the base64ImageData column.<br>\n- Extracted images from the PDF and PNG files are saved to /data/output/images/.<br>\n- Since Recursive is set to false, only files directly in /data/documents/ are processed.<br>",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeDocumentToText",
      "x": "179.2px",
      "y": "129.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "filePath",
          "value": "/home/sparkflows/fire-data/data/GENAI/Automobile-Claims-Warranty/Claims",
          "widget": "textfield",
          "title": "Directory/File Path",
          "description": "Select a Pdf/Text/Docx File or Directory",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileType",
          "value": "pdf",
          "widget": "array",
          "title": "Document Type",
          "description": "Choose a Document Type.If Empty all four types of files will be processed.",
          "optionsArray": [
            "pdf",
            "txt",
            "docx",
            "image"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "recursive",
          "value": "false",
          "widget": "array",
          "title": "Recursive",
          "description": "Recursively process the documents in the given Directory",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "imgPathCols",
          "value": "[]",
          "widget": "variables",
          "title": "Select Image Column",
          "description": "",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "isImage",
          "value": "false",
          "widget": "array",
          "title": "Image Encoding",
          "description": "Adds a column for base64 encoded pages",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "saveImageDir",
          "value": "",
          "widget": "textfield",
          "title": "Save Images Directory Path",
          "description": "The file path to save the output",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "columns",
          "value": "",
          "widget": "tab",
          "title": "Rename Output Cols",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileNameCol",
          "value": "fileName",
          "widget": "textfield",
          "title": "File Name Column",
          "description": "Rename File Name Column. Defaults to fileName",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "contentCol",
          "value": "content",
          "widget": "textfield",
          "title": "Content Column",
          "description": "Rename Content Column. Defaults to content",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pageNumberCol",
          "value": "pageNumber",
          "widget": "textfield",
          "title": "Page Number Column",
          "description": "Rename Page Number Column. Defaults to pageNumber",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "base64ImageCol",
          "value": "base64ImageCol",
          "widget": "textfield",
          "title": "Base64 Image Column",
          "description": "Rename Image Column. Defaults to base64ImageCol",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "2",
      "name": " Multi LLM Query",
      "iconImage": "/images/icons/node-icon/Graph_group_by_column.svg",
      "description": "The Multi LLM Query node is designed to query multiple large language models (LLMs) from providers such as OpenAI, Bedrock, and Gemini, using a DataFrame as input. It processes user queries, text content, and/or base64-encoded images to generate responses based on the selected model and task, producing a structured DataFrame output.",
      "details": "<h2>Multi LLM Query Node Details</h2>\n<br>\nThe Multi LLM Query node is designed to query multiple large language models (LLMs) from providers such as OpenAI, Bedrock, and Gemini, using a DataFrame as input. It processes user queries, text content, and/or base64-encoded images to generate responses based on the selected model and task, producing a structured DataFrame output.<br>\n<br>\n<h3>General:</h3>\n<br>\n<h4>Select Task:</h4>\nSpecifies the task to perform. Options include:<br>\n- summary: Generates a summary of the content in bullet points.<br>\n- translation: Translates the content to English.<br>\n- topic_extraction: Extracts key topics from the content.<br>\n- other: Allows for a custom task defined by the user.<br>\n<br>\n<h4>Prompt:</h4>\nAllows users to provide a custom prompt / instructions for the selected task.<br>\n<br>\n<h4>Content Column:</h4>\nSpecifies the DataFrame column containing the text content to be processed. Required for text or text+image modes.<br>\n<br>\n<h4>Model Selection:</h4>\nSelects the LLM provider to use. Options are:<br>\n- openai: Uses OpenAI models (e.g., gpt-4o).<br>\n- bedrock: Uses AWS Bedrock models (e.g., Claude models).<br>\n- gemini: Uses Google Gemini models (e.g., gemini-1.5-flash-latest).<br>\n<br>\n<h4>Select Connection:</h4>\nSpecifies the connection details for the selected LLM provider (e.g., API keys for OpenAI/Gemini, AWS credentials for Bedrock). Required to authenticate and access the chosen model.<br>\n<br>\n<h4>Temperature:</h4>\nControls the randomness of the LLM's output. Default is 0.7. Higher values increase creativity, while lower values ensure more deterministic responses.<br>\n<br>\n<h4>Image Column:</h4>\nSpecifies the DataFrame column containing base64-encoded images. Required for image or text+image modes.<br>\n<br>\n<h4>Mode Selection:</h4>\nDetermines the input mode for the LLM. Options are:<br>\n- text: Processes text-only input from the content column or custom prompt.<br>\n- image: Processes base64-encoded images from the image column.<br>\n- text+image: Processes both text and base64-encoded images.<br>\n<br>\n<h3>Advanced:</h3>\n<br>\n<h4>Aggregate Response:</h4>\nSpecifies how to aggregate input data before processing. Options are:<br>\n- none: Processes each row individually, retaining fileName and pageNumber (if provided).<br>\n- all: Aggregates all rows into a single response.<br>\n- perfile: Aggregates rows by fileName, producing one response per file.<br>\n<br>\n<h4>Number of Partitions:</h4>\nSpecifies the number of Spark partitions for distributed processing. Default is 3.<br>\n<br>\n<h4>File Name Column:</h4>\nSpecifies the DataFrame column containing file names. Required for perfile aggregation mode.<br>\n<br>\n<h4>Page Number Column:</h4>\nSpecifies the DataFrame column containing page numbers (e.g., for PDFs). Optional, used for row-wise processing with none aggregation mode.<br>\n<br>\n<h3>Output:</h3>\nThe node outputs a DataFrame with columns based on the aggregation mode:<br>\n- none: Includes fileName (if provided), pageNumber (if provided), and response.<br>\n- perfile: Includes fileName and response.<br>\n- all: Includes only the response column.<br>\nThe response column contains the LLM-generated text or error messages if the API call fails.<br>",
      "examples": "<h2>Multi LLM Query Node Examples</h2>\n<br>\n<h3>Input:</h3>\nA DataFrame contains the following data:<br>\n- fileName: [\"doc1.pdf\", \"doc1.pdf\", \"doc2.pdf\"]<br>\n- pageNumber: [\"1\", \"2\", null]<br>\n- content: [\"Article about climate change...\", \"Climate change impacts...\", \"Renewable energy report...\"]<br>\n- imageBase64: [null, \"iVBORw0KGgoAAAANSUhEUg...\", null]<br>\n<br>\nThe Multi LLM Query node is configured as follows:<br>\n- Select Task: summary<br>\n- Prompt: \"Summarize the content in bullet points.\"<br>\n- Content Column: content<br>\n- Model Selection: openai<br>\n- Select Connection: Configured with valid OpenAI API key<br>\n- Temperature: 0.7<br>\n- Image Column: imageBase64<br>\n- Mode Selection: text+image<br>\n- Aggregate Response: perfile<br>\n- Number of Partitions: 3<br>\n- File Name Column: fileName<br>\n- Page Number Column: pageNumber<br>\n<br>\n<h3>Output:</h3>\nThe node processes the DataFrame and produces a DataFrame with the following structure:<br>\n- fileName: doc1.pdf<br>\nresponse: - Climate change effects on ecosystems<br>\n- Rising temperatures<br>\n- fileName: doc2.pdf<br>\nresponse: - Renewable energy advancements<br>\n- Solar and wind adoption<br>",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeMultiLLMQuery",
      "x": "315.569px",
      "y": "136.575px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "llmConnection",
          "value": "gemini-api-connection",
          "widget": "object_array",
          "title": "Select Connection",
          "description": "Select Connection",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "temperature",
          "value": "0",
          "widget": "textfield",
          "title": "Temperature",
          "description": "Temperature setting for the model (default: 0).",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "contentCol",
          "value": "content",
          "widget": "variable",
          "title": "Content Column",
          "description": "Column name for the text content.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "imageCol",
          "value": "",
          "widget": "variable",
          "title": "Image Column",
          "description": "Column name for the base 64 image.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputMode",
          "value": "text",
          "widget": "array",
          "title": "Mode Selection",
          "description": "Select the model to use (text, image, text+image).",
          "optionsArray": [
            "text",
            "image",
            "text+image"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Prompt",
          "value": "",
          "widget": "tab",
          "title": "Prompt",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "task",
          "value": "other",
          "widget": "key_value_array",
          "title": "Select Prompt",
          "description": "Specify the task to perform: summary, translation, topic extraction, or other.",
          "optionsMap": {
            "summary": "Generate Summary in bullet points ",
            "translation": "Translate the following content to default language",
            "topic_extraction": "Extract key topics from the following content.",
            "other": ""
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "customPrompt",
          "value": "i have provided a folder which contains automobile claims ,use this and give out a data frame which the information :\nCustomer_ID,Full_Name,Policy_Number,Phone_Number,Email,Address,Make_&_Model,Year,License_Plate,VIN,Service_Description,Services_Availed,Specific_Notes,Insurer,Date_of_Claim,Type_of_Claim,Estimated_Damage,Repair_Shop\nreplace ,with :\n\nformat,only give the values do not include the header. values will be in the same order use",
          "widget": "textareafield",
          "title": "Prompt",
          "description": "Custom prompt to override the default instructions.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "userQueryCol",
          "value": "",
          "widget": "variable",
          "title": "User Query Column",
          "description": "Column name for user query, (if the query is in a column)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateMode",
          "value": "ALL",
          "widget": "enum",
          "title": "Aggregate Response",
          "optionsMap": {
            "NONE": "Do not aggregate rows",
            "ALL": "Aggregate all rows",
            "PERFILE": "Aggregate per file"
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "numPartitions",
          "value": "3",
          "widget": "textfield",
          "title": "Number of Partitions",
          "description": "Number of Partitions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileNameCol",
          "value": "fileName",
          "widget": "variable",
          "title": "File Name Column",
          "description": "Select File Name Column",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pageNumberCol",
          "value": "",
          "widget": "variable",
          "title": "Page Number Column",
          "description": " Select Page Number column.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "14",
      "name": "Read CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "It reads in CSV files and creates a DataFrame from it.",
      "details": "<h2>Read CSV Details</h2>\n<br>\nThis node reads CSV files and creates a DataFrame from them. It can read either a single file or a directory containing multiple files. The user can configure the below fields to parse the file.<br>\n<br>\nThe user can choose the <b>Output storage level</b> from the drop down. The options in the dropdown can be one of the following:<br>\n<ul>\n<li> <b>MEMORY_ONLY</b>          Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they are needed. This is the default level.</li>\n<li> <b>MEMORY_AND_DISK</b>       Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that do not fit on disk, and read them from there when they are needed.</li>\n<li> <b>MEMORY_ONLY_SER</b>        Store RDD as serialized Java objects (one byte array per partition). This is generally more space-efficient than deserialized objects, especially when using a fast serializer, but more CPU-intensive to read.</li>\n<li> <b>MEMORY_AND_DISK_SER</b>    Similar to MEMORY_ONLY_SER, but spill partitions that do not fit in memory to disk instead of recomputing them on the fly each time they're needed.</li>\n<li> <b>DISK_ONLY</b>              Store the RDD partitions only on disk.</li>\n<li> <b>MEMORY_ONLY_2, MEMORY_AND_DISK_2 others </b> . Same as the levels above, but replicate each partition on two cluster nodes.</li>\n<li> <b>OFF_HEAP</b>               Similar to MEMORY_ONLY_SER, but store the data in off-heap memory. This requires off-heap memory to be enabled.</li>\n</ul>\nThe user needs to provide a data file <b>Path</b> to read the data from. This is a required field.<br>\n<br>\nThe user can choose the <b>Separator</b> used in the data file to parse it. The default separator is <b>( , )</b> comma.<br>\n<br>\nIn the <b>Header</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> if the data file has a header.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Drop special character in column name</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> If you want to remove the special characters from column names.</li>\n<li> <b>false</b> Otherwise.</li>\n</ul>\nIn the <b>Mode</b> field, one can choose from the below options in the dropdown:<br>\n<ul>\n<li> <b>PERMISSIVE</b> When the parser meets a corrupt field in a record, it sets the value of the field to NULL and continues to the next record.</li>\n<li> <b>DROPMALFORMED</b> ignores the whole corrupted record.</li>\n<li> <b>FAILFAST</b> throws an exception when it meets corrupted records.</li>\n</ul>\nIn the <b>Enforce Schema</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> The specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored.</li>\n<li> <b>false</b> The schema will be validated against all headers in CSV files when the header option is set to <b>false</b>.</li>\n</ul>\nIn the <b>Whether to add input file as a column in DataFrame</b> field, one can choose:<br>\n<ul>\n<li> <b>true</b> There will be a new column added to the DataFrame at the end, which can be seen in the schema columns. One can enter the name of this column.</li>\n<li> <b>false</b> This functionality is disabled, and the DataFrame consists of only the columns read from the data file.</li>\n</ul>\nIn the <b>ENCODING</b> field, one can specify the encoding type to be used for reading the files. By default, it is set as <b>UTF-8</b>.<br>\n<br>\nThe <b>QUOTE</b> field sets a single character used for escaping quoted values where the separator can be part of the value. The default value for this is <b>( \" )</b>, a double quote.<br>\n<br>\nThe <b>ESCAPE</b> field sets a single character used for escaping quotes inside an already quoted value. The default value for this is <b>( \\ )</b>, a backslash.\t<br>\n<br>\nAfter the above options are set, one can click on <b>InferSchema</b> to see the final columns.<br>\nUsers can still add or delete columns using <b>+</b> button next to the InferSchema and <b>-</b> button next to the column names.<br>",
      "examples": "<h2> Read CSV Node Example</h2>\n<br>\nGiven a CSV file with the following data:<br>\n<br>\nSupplierID,SupplierName,Region,YearsInBusiness,LeadTime,PriceIndex,OrderFulfillmentTime,OverallCost,OrderCancellations,CustomerRating<br>\nS1,Supplier A,Region 1,10,5,1.2,3,100,2,4<br>\nS2,Supplier B,Region 2,15,7,1.1,4,120,1,5<br>\nIf you configure the Read CSV node as follows:<br>\n<br>\nPath: /path/to/your/file.csv<br>\nSeparator: ,<br>\nHeader: true<br>\nThe output would be a DataFrame with the following schema:<br>\n<br>\nColumn Name\tData Type<br>\nSupplierID\tString<br>\nSupplierName\tString<br>\nRegion\tString<br>\nYearsInBusiness\tInteger<br>\nLeadTime\tInteger<br>\nPriceIndex\tDouble<br>\nOrderFulfillmentTime\tInteger<br>\nOverallCost\tInteger<br>\nOrderCancellations\tInteger<br>\nCustomerRating\tInteger<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",
      "x": "255.587px",
      "y": "573.587px",
      "hint": "Infer the schema when a new file is selected or the file content has changed",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "/home/sparkflows/fire-data/data/GENAI/Automobile-Claims-Warranty/Maste-Data/insurance_claims_master_raw.csv",
          "widget": "textfield",
          "title": "Path",
          "description": "Path of the file/directory",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "separator",
          "value": ",",
          "widget": "textfield",
          "title": "Separator",
          "description": "CSV Separator",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Whether the file has a header row",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropSpecialCharacterInColumnName",
          "value": "false",
          "widget": "array",
          "title": "Drop Special Character In ColumnName",
          "description": "Whether to drop the Special Characters and Spaces in Column Name.",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "mode",
          "value": "PERMISSIVE",
          "widget": "array",
          "title": "Mode",
          "description": "Mode for dealing with corrupt records during parsing.",
          "optionsArray": [
            "PERMISSIVE",
            "DROPMALFORMED",
            "FAILFAST"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "enforceSchema",
          "value": "false",
          "widget": "array",
          "title": "Enforce Schema",
          "description": "If it is set to true, the specified or inferred schema will be forcibly applied to datasource files, and headers in CSV files will be ignored. If the option is set to false, the schema will be validated against all headers in CSV files in the case when the header option is set to true.",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "addInputFileName",
          "value": "false",
          "widget": "array",
          "title": "Whether to Add Input File Name as Column in the Dataframe",
          "description": "Add the new field:input_file_name",
          "optionsArray": [
            "false",
            "true"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"claimant_id\",\"insurer_name\",\"vehicle_model\",\"vehicle_vin\",\"vehicle_purchase_date\",\"policy_expiry\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Columns from CSV",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "properties",
          "value": "",
          "widget": "tab",
          "title": "Properties",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsKeys",
          "value": "[]",
          "widget": "key_array",
          "title": "Properties Name",
          "description": "Extra options/properites available while executing in Read CSV.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "extraOptionsValues",
          "value": "[]",
          "widget": "value_array",
          "title": "Properties Value",
          "description": "Config Values for the Corresponding properites name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "15",
      "name": "Concat Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "447.187px",
      "y": "592.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"claimant_id\",\"insurer_name\",\"vehicle_model\",\"vehicle_vin\",\"vehicle_purchase_date\",\"policy_expiry\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "master_data",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "|",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "17",
      "name": "Columns Rename",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "559.194px",
      "y": "568.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "currentColNames",
          "value": "[\"claimant_id\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "newColNames",
          "value": "[\"Customer_id\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "19",
      "name": "Select Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "647.4px",
      "y": "569.388px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "[\"Customer_id\",\"master_data\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "21",
      "name": "Concat Columns",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "945.569px",
      "y": "704.575px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Customer_ID\",\"Claim_data\",\"MasterData\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "LLM_data",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": ":",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "22",
      "name": " Multi LLM Query",
      "iconImage": "/images/icons/node-icon/Graph_group_by_column.svg",
      "description": "The Multi LLM Query node is designed to query multiple large language models (LLMs) from providers such as OpenAI, Bedrock, and Gemini, using a DataFrame as input. It processes user queries, text content, and/or base64-encoded images to generate responses based on the selected model and task, producing a structured DataFrame output.",
      "details": "<h2>Multi LLM Query Node Details</h2>\n<br>\nThe Multi LLM Query node is designed to query multiple large language models (LLMs) from providers such as OpenAI, Bedrock, and Gemini, using a DataFrame as input. It processes user queries, text content, and/or base64-encoded images to generate responses based on the selected model and task, producing a structured DataFrame output.<br>\n<br>\n<h3>General:</h3>\n<br>\n<h4>Select Task:</h4>\nSpecifies the task to perform. Options include:<br>\n- summary: Generates a summary of the content in bullet points.<br>\n- translation: Translates the content to English.<br>\n- topic_extraction: Extracts key topics from the content.<br>\n- other: Allows for a custom task defined by the user.<br>\n<br>\n<h4>Prompt:</h4>\nAllows users to provide a custom prompt / instructions for the selected task.<br>\n<br>\n<h4>Content Column:</h4>\nSpecifies the DataFrame column containing the text content to be processed. Required for text or text+image modes.<br>\n<br>\n<h4>Model Selection:</h4>\nSelects the LLM provider to use. Options are:<br>\n- openai: Uses OpenAI models (e.g., gpt-4o).<br>\n- bedrock: Uses AWS Bedrock models (e.g., Claude models).<br>\n- gemini: Uses Google Gemini models (e.g., gemini-1.5-flash-latest).<br>\n<br>\n<h4>Select Connection:</h4>\nSpecifies the connection details for the selected LLM provider (e.g., API keys for OpenAI/Gemini, AWS credentials for Bedrock). Required to authenticate and access the chosen model.<br>\n<br>\n<h4>Temperature:</h4>\nControls the randomness of the LLM's output. Default is 0.7. Higher values increase creativity, while lower values ensure more deterministic responses.<br>\n<br>\n<h4>Image Column:</h4>\nSpecifies the DataFrame column containing base64-encoded images. Required for image or text+image modes.<br>\n<br>\n<h4>Mode Selection:</h4>\nDetermines the input mode for the LLM. Options are:<br>\n- text: Processes text-only input from the content column or custom prompt.<br>\n- image: Processes base64-encoded images from the image column.<br>\n- text+image: Processes both text and base64-encoded images.<br>\n<br>\n<h3>Advanced:</h3>\n<br>\n<h4>Aggregate Response:</h4>\nSpecifies how to aggregate input data before processing. Options are:<br>\n- none: Processes each row individually, retaining fileName and pageNumber (if provided).<br>\n- all: Aggregates all rows into a single response.<br>\n- perfile: Aggregates rows by fileName, producing one response per file.<br>\n<br>\n<h4>Number of Partitions:</h4>\nSpecifies the number of Spark partitions for distributed processing. Default is 3.<br>\n<br>\n<h4>File Name Column:</h4>\nSpecifies the DataFrame column containing file names. Required for perfile aggregation mode.<br>\n<br>\n<h4>Page Number Column:</h4>\nSpecifies the DataFrame column containing page numbers (e.g., for PDFs). Optional, used for row-wise processing with none aggregation mode.<br>\n<br>\n<h3>Output:</h3>\nThe node outputs a DataFrame with columns based on the aggregation mode:<br>\n- none: Includes fileName (if provided), pageNumber (if provided), and response.<br>\n- perfile: Includes fileName and response.<br>\n- all: Includes only the response column.<br>\nThe response column contains the LLM-generated text or error messages if the API call fails.<br>",
      "examples": "<h2>Multi LLM Query Node Examples</h2>\n<br>\n<h3>Input:</h3>\nA DataFrame contains the following data:<br>\n- fileName: [\"doc1.pdf\", \"doc1.pdf\", \"doc2.pdf\"]<br>\n- pageNumber: [\"1\", \"2\", null]<br>\n- content: [\"Article about climate change...\", \"Climate change impacts...\", \"Renewable energy report...\"]<br>\n- imageBase64: [null, \"iVBORw0KGgoAAAANSUhEUg...\", null]<br>\n<br>\nThe Multi LLM Query node is configured as follows:<br>\n- Select Task: summary<br>\n- Prompt: \"Summarize the content in bullet points.\"<br>\n- Content Column: content<br>\n- Model Selection: openai<br>\n- Select Connection: Configured with valid OpenAI API key<br>\n- Temperature: 0.7<br>\n- Image Column: imageBase64<br>\n- Mode Selection: text+image<br>\n- Aggregate Response: perfile<br>\n- Number of Partitions: 3<br>\n- File Name Column: fileName<br>\n- Page Number Column: pageNumber<br>\n<br>\n<h3>Output:</h3>\nThe node processes the DataFrame and produces a DataFrame with the following structure:<br>\n- fileName: doc1.pdf<br>\nresponse: - Climate change effects on ecosystems<br>\n- Rising temperatures<br>\n- fileName: doc2.pdf<br>\nresponse: - Renewable energy advancements<br>\n- Solar and wind adoption<br>",
      "type": "pyspark",
      "nodeClass": "fire.nodes.gai.NodeMultiLLMQuery",
      "x": "1116.39px",
      "y": "702.394px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "llmConnection",
          "value": "openai-api-connection",
          "widget": "object_array",
          "title": "Select Connection",
          "description": "Select Connection",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "temperature",
          "value": "0",
          "widget": "textfield",
          "title": "Temperature",
          "description": "Temperature setting for the model (default: 0).",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "contentCol",
          "value": "LLM_data",
          "widget": "variable",
          "title": "Content Column",
          "description": "Column name for the text content.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "imageCol",
          "value": "",
          "widget": "variable",
          "title": "Image Column",
          "description": "Column name for the base 64 image.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputMode",
          "value": "text",
          "widget": "array",
          "title": "Mode Selection",
          "description": "Select the model to use (text, image, text+image).",
          "optionsArray": [
            "text",
            "image",
            "text+image"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Prompt",
          "value": "",
          "widget": "tab",
          "title": "Prompt",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "task",
          "value": "other",
          "widget": "key_value_array",
          "title": "Select Prompt",
          "description": "Specify the task to perform: summary, translation, topic extraction, or other.",
          "optionsMap": {
            "summary": "Generate Summary in bullet points ",
            "translation": "Translate the following content to default language",
            "topic_extraction": "Extract key topics from the following content.",
            "other": ""
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "customPrompt",
          "value": "I am giving you  data for 2 tables,\nclaims table containing data of claims made\nmaster data containing  data with company\n\nthe data is as follows \nCustomer_id:master_data:Claim_data\n\nin this claims data :\n\n\nCustomer_ID|Full_Name|Policy_Number|Phone_Number|Email|Address|Make_&_Model|Year|License_Plate|VIN|Service_Description|Services_Availed|Specific_Notes|Insurer|Date_of_Claim|Type_of_Claim|Estimated_Damage|Repair_Shop\n\n\nand master data :\n\nclaimant_id|insurer_name|vehicle_model|vehicle_vin|vehicle_purchase_date|policy_expiry\n\ndates are in yyyy-mm-dd format\ncorrect all date formats to yyyy-mm-dd\nanalyze and give a response stating whether\nwarranty is active or expired(make the column name warranty claim and it should have value approved or denied)\n reason for warranty claim approval/denial based on warranty active\n Action/Recommendation. for customer \n\ndo not include phone number,address and email\ninclude other relevant information also and give proper recommendation based on the service claimed\n\n\ngive the response in html formatted table with proper borders,spacing and alignments so that it is readable\nremove excess text from the end",
          "widget": "textareafield",
          "title": "Prompt",
          "description": "Custom prompt to override the default instructions.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "userQueryCol",
          "value": "",
          "widget": "variable",
          "title": "User Query Column",
          "description": "Column name for user query, (if the query is in a column)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateMode",
          "value": "ALL",
          "widget": "enum",
          "title": "Aggregate Response",
          "optionsMap": {
            "NONE": "Do not aggregate rows",
            "ALL": "Aggregate all rows",
            "PERFILE": "Aggregate per file"
          },
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "numPartitions",
          "value": "3",
          "widget": "textfield",
          "title": "Number of Partitions",
          "description": "Number of Partitions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "fileNameCol",
          "value": "",
          "widget": "variable",
          "title": "File Name Column",
          "description": "Select File Name Column",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "pageNumberCol",
          "value": "",
          "widget": "variable",
          "title": "Page Number Column",
          "description": " Select Page Number column.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "24",
      "name": "Output Formatter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node formats output from Columns.",
      "details": "<h2> Output Formatter Node Details</h2>\nThe Output Formatter node formats data from a specified column in an input DataFrame and outputs it with a user-defined key. It is designed for use in PySpark-based data processing pipelines to extract and present data in a structured format, typically for downstream use or display. The node processes a single column from the input DataFrame, formats the content, and sends it as a JSON message with a specified key.<br>\n<br>\n<h4> General:</h4>\n<br>\nh5: Select Column:<br>\nSpecifies the column in the input DataFrame from which to extract data. This field is required and must correspond to a valid column name in the DataFrame.<br>\n<br>\nh5: Key:<br>\nDefines a key name for the formatted output. This field is required and is used to label the extracted column value in the output JSON message.<br>\n<br>\n<h4> Output:</h4>\nThe node does not modify the input DataFrame but instead generates a JSON-formatted message containing the following:<br>\n<ul>\n<li> id: The node’s ID.</li>\n<li> name: The node’s name (\"Output Formatter\").</li>\n<li> title: The display title (\"Output Formatter\").</li>\n<li> type: The node type (\"formatter\").</li>\n<li> resultType: Set to 3, indicating the output is a formatted message.</li>\n<li> visibility: Set to \"EXPANDED\" for display purposes.</li>\n<li> text: A nested structure containing:</li>\n<li> key: The user-specified key name.</li>\n<li> string: The value extracted from the selected column (from the first row of the DataFrame).</li>\n<li> format: Set to \"plaintext\" for the output format.</li>\n</ul>\nThe JSON message is sent to the workflow context for further processing or display. The input DataFrame is passed through unchanged as the node’s output schema.<br>",
      "examples": "<h2> Example: Output Formatter Node</h2>\n<br>\n<h3> Input:</h3>\nA DataFrame with the following structure, containing a single row of data:<br>\n<br>\n| summary_text                     |<br>\n|----------------------------------|<br>\n| Project meeting: Plan Q1 goals...|<br>\n<br>\nThe Output Formatter node is configured as follows:<br>\n<ul>\n<li> Select Column: summary_text</li>\n<li> Key: meeting_summary</li>\n</ul>\n<h3> Output:</h3>\nThe node processes the DataFrame and generates a JSON-formatted message sent to the workflow context, with the following structure:<br>\n<br>\n```json<br>\n{<br>\n\"id\": \"11\",<br>\n\"name\": \"Output Formatter\",<br>\n\"title\": \"Output Formatter\",<br>\n\"type\": \"formatter\",<br>\n\"resultType\": 3,<br>\n\"visibility\": \"EXPANDED\",<br>\n\"text\": {<br>\n\"key\": \"meeting_summary\",<br>\n\"string\": \"Project meeting: Plan Q1 goals...\",<br>\n\"format\": \"plaintext\"<br>\n}<br>\n}<br>\n```<br>\n<br>\nThe input DataFrame is passed through unchanged as the node’s output schema.<br>\n<br>\n<h3> Explanation:</h3>\n<ul>\n<li> The summary_text column is selected, and the value from its first row (\"Project meeting: Plan Q1 goals...\") is extracted.</li>\n<li> The key field is set to \"meeting_summary\", which is used to label the extracted value in the output JSON.</li>\n<li> The node formats the extracted value into a JSON message with a nested text object, specifying the key, string value, and format (\"plaintext\").</li>\n<li> The JSON message is sent to the workflow context for further processing or display.</li>\n<li> The original DataFrame is returned as the output schema without modification.</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.graph.NodeOutputFormatter",
      "x": "1259.59px",
      "y": "586.587px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "column",
          "value": "response",
          "widget": "variable",
          "title": " Select Column",
          "description": "Select Column to format",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "key",
          "value": "genAiResponse",
          "widget": "textfield",
          "title": "Key",
          "description": "Specify a key Name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "25",
      "name": "Field Splitter",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node splits the string of the specified input column using the specified delimiter",
      "details": "Splits the string of the specified input column using the specified delimiter. The new column names are specified by the user.<br>\n<br>\nThe new dataframe would have the new columns added to it.<br>",
      "examples": "If a String Column stores values in [PRD_CD]:[PRD_NAME] format and incoming Dataframe has a value as CD01:DrillMachine <br>\nthen using : as Separator to split data into two Columns (Col1, Col2) would result in followings:<br>\n<br>\n<ul>\n<li> Col1 : CD01</li>\n<li> Col2 : DrillMachine</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeFieldSplitter",
      "x": "450.187px",
      "y": "300.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCol",
          "value": "response",
          "widget": "variable",
          "title": "Input Column",
          "description": "Input column name",
          "datatypes": [
            "string"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "Customer_ID,Full_Name,Policy_Number,Phone_Number,Email,Address,Make_&_Model,Year,License_Plate,VIN,Service_Description,Services_Availed,Specific_Notes,Insurer,Date_of_Claim,Type_of_Claim,Estimated_Damage,Repair_Shop",
          "widget": "textarea_small",
          "title": "Output Columns",
          "description": "New column names separated by comma (eg: col1,co2,col3)",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": ":",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to split the input column value (default: space)",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "onError",
          "value": "die",
          "widget": "array",
          "title": "On Error",
          "description": "",
          "optionsArray": [
            "die",
            "ignore"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "26",
      "name": "Drop Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by dropping the specified columns",
      "details": "<h2>Drop Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame by dropping the selected columns.<br>\n<br>\nIt drops the selected columns from the outgoing dataframe. <br>\n<br>\nColumns that need to be dropped are to be selected in the 'Selected' list. Multiple columns can be selected in the list that needs to be dropped.<br>",
      "examples": "<h2>Drop Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe having following columns:<br>\n<br>\n<ul>\n<li> CUST_CD</li>\n<li> CUST_NAME</li>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>\n<h4>Drop Columns Node Configuration And Output</h4>\n<br>\n[DOB] and [ADDRESS] columns are selected to be dropped from the outgoing Dataframe. <br>\nOutgoing dataframe would contain only below two columns after dropping the selected columns:<br>\n<br>\n<ul>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeDropColumns",
      "x": "549.194px",
      "y": "336.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dropCols",
          "value": "[\"file_path\",\"response\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "The columns to be excluded from the output DataFrame",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "27",
      "name": "Concat Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "681.194px",
      "y": "332.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"Customer_ID\",\"Full_Name\",\"Policy_Number\",\"Phone_Number\",\"Email\",\"Address\",\"Make_&_Model\",\"Year\",\"License_Plate\",\"VIN\",\"Service_Description\",\"Services_Availed\",\"Specific_Notes\",\"Insurer\",\"Date_of_Claim\",\"Type_of_Claim\",\"Estimated_Damage\",\"Repair_Shop\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "Claim_data",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "|",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "28",
      "name": "Select Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "810.337px",
      "y": "380.369px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "[\"Customer_ID\",\"Claim_data\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "30",
      "name": "Join On Common Column",
      "iconImage": "fa fa-stumbleupon",
      "description": "This node joins the incoming dataframes using one common column between them.",
      "details": "<h2>Join On Common Column Node Details</h2>\n<br>\nThis node joins the incoming dataframes using one common column between the two dataframes. <br>\n<br>\nSelect the Common Join Column to be used in the Join.<br>\n<br>\nJoining modes supported by this node is as follows:<br>\n<ul>\n<li> inner : The joined table will have records that have matching values in both tables.</li>\n<li> outer : The joined table contains either all the records from both the tables or fills in NULL values for missing matches on either side.</li>\n<li> left_outer  : Even if there are no matches in the right table it returns all the rows from the left table.</li>\n<li> right_outer : Even if there are no matches in the left table it returns all the rows from the right table.</li>\n<li> leftsemi : This gives only those rows in the left table that have a matching row in the right table.</li>\n<li> leftanti : This join returns rows in the left table that have no matching rows in the right table.</li>\n</ul>",
      "examples": "<h2>Join On Common Column Example</h2>\n<br>\n<h4> Incoming Datasets</h4>\n<br>\n1st Incoming Dataframe table1 has the following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO       <br>\n-------------------------------------------<br>\nE01       |    DAVID       |    10         <br>\nE02       |    JOHN        |    20      <br>\nE03       |    MARTIN      |    30  <br>\nE04       |    TONY        |    40  <br>\n<br>\n2nd Incoming Dataframe table2 has the following rows:<br>\n<br>\nDEPT_NO    |      DEPT_NAME   |    LOC       <br>\n-------------------------------------------<br>\n10         |      HR          |    IND  <br>\n20         |      SALES       |    AUS  <br>\n30         |      MARKETING   |    UK         <br>\n50         |      RESEARCH    |    NZ      <br>\n<br>\nThe common join column is DEPT_NO<br>\n<br>\n<h4> When the Joining condition is `inner` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |      DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |      HR         |    IND<br>\nE02       |    JOHN        |    20        |      SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |      MARKETING  |    UK<br>\n<br>\n<h4> When the Joining condition `outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |    <br>\n          |                |              |   RESEARCH   |    NZ<br>\n<br>\n<h4> When the Joining condition is `left_outer` we have</h4>\n<h4> Final Output</h4>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\nE04       |    TONY        |    40        |              |    <br>\n<br>\n<h4> When the Joining condition `right_outer` we have</h4>\n<h4> Final Output</h4>\n          <br>\nEMP_CD    |    EMP_NAME    |    DEPT_NO   |   DEPT_NAME  |    LOC           <br>\n--------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    10        |   HR         |    IND<br>\nE02       |    JOHN        |    20        |   SALES      |    AUS<br>\nE03       |    MARTIN      |    30        |   MARKETING  |    UK<br>\n          |                |    50        |   RESEARCH   |    NZ<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingColumn",
      "x": "936.394px",
      "y": "477.394px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "joinCol",
          "value": "Customer_ID",
          "widget": "variable_common",
          "title": "Common Join Column",
          "description": "column on which to join",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "joinType",
          "value": "inner",
          "widget": "array",
          "title": "JoinType",
          "description": "type of join",
          "optionsArray": [
            "inner",
            "outer",
            "leftouter",
            "rightouter",
            "leftsemi",
            "leftanti"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"Customer_ID\",\"Claim_data\",\"MasterData\"]",
          "widget": "schema_col_names",
          "title": "Output Column Names",
          "description": "Name of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"STRING\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Output Column Types",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Output Column Formats",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "31",
      "name": "Concat Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",
      "details": "<h2>Concat Columns Node Details</h2>\n<br>\nIt adds a new column to the dataframe created by concatenating multiple columns and separated by the specified separator. <br>\n<br>\n<h4>Input</h4>\n<ul>\n<li>   COLUMNS :- Select columns that need to be concatenated. Multiple columns can be selected for concatenation.</li>\n<li>   CONCATENATED COLUMN NAME :- Enter name of the column to list the concatenated values in the outgoing Dataframe.</li>\n<li>\t  SEPARATOR :- Enter a Separator value to separate values from different columns in the output. It can be a multi-character value. Common Separator values used are as follows:</li>\n</ul>\n  b. *<br>\n  c. -<br>\n  d. :<br>\n  e. [Blank Space]<br>\n<br>\n<h4>Output</h4>\n<ul>\n<li>   New concatenated column would be added to the Outgoing Dataframe listing the concatenated values.</li>\n</ul>",
      "examples": "<h2>Concat Columns Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Concat Columns Node Configuration and Output </h4>\n<br>\nConcat Columns Node is configured to concatenate two columns [CUST_CD] and [CUST_NAME] from the incoming Dataframe into a new column [CUST_IDENTIFIER] using separator [-].<br>\nOutput Dataframe would be created as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY         |    CUST_IDENTIFIER<br>\n----------------------------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00  |    C01-MATT<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00  |    C02-LISA<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00   |    C03-ROBIN<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00  |    C04-MARCUS<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeConcatColumns",
      "x": "420.187px",
      "y": "457.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"claimant_id\",\"insurer_name\",\"vehicle_model\",\"vehicle_vin\",\"vehicle_purchase_date\",\"policy_expiry\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be concatenated",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "MasterData",
          "widget": "textfield",
          "title": "Concatenated Column Name",
          "description": "Column name for the concatenated columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sep",
          "value": "|",
          "widget": "textfield",
          "title": "Separator",
          "description": "Separator to be used when concatenating the columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "32",
      "name": "Columns Rename",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by renaming existing columns with the new name",
      "details": "This node creates a new DataFrame by renaming existing columns with the new name.<br>\n<br>\nFor the columns to be renamed, provide the new column name. The output dataframe would have the specified columns renamed to the new ones.<br>",
      "examples": "If incoming Dataframe has a column as [CUST NAME] that needs to be renamed to [CUST_NAME] then below details need to be provided in the node:<br>\n<br>\n<ul>\n<li> CURRENT COLUMN NAMES : CUST NAME</li>\n<li> COLUMNS NEW NAME : CUST_NAME</li>\n</ul>\nThis would result in output Dataframe having renameed column [CUST_NAME]. A seprate row needs to be added for each Column Rename requirement.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnsRename",
      "x": "516.194px",
      "y": "459.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "currentColNames",
          "value": "[\"claimant_id\"]",
          "widget": "variables_list_select",
          "title": "Current Column Names",
          "description": "Current Column Names",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "newColNames",
          "value": "[\"Customer_ID\"]",
          "widget": "variables_list_textfield",
          "title": "Columns New Name",
          "description": "New name for existing columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "33",
      "name": "Select Columns",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame that contains only the selected columns",
      "details": "<h2>Select Columns Node Details</h2>\n<br>\nThis node creates a new DataFrame containing only the selected columns.<br>\n<br>\nIt selects columns that need to be passed to the outgoing Dataframe. <br>\n<br>\nColumns that need to be included in the outgoing Dataframe are to be selected in the 'Selected' list. Multiple columns can be selected in the list.<br>",
      "examples": "<h2>Select Columns Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered an Incoming Dataframe with following rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE    |    DATE_OF_JOINING    |    SALARY<br>\n-------------------------------------------------------------------------------------<br>\nC01        |    MATT         |    50     |    12-02-2002         |    USD 200000.00<br>\nC02        |    LISA         |    45     |    15-11-2020         |    GBP 100000.00<br>\nC03        |    ROBIN        |    30     |    10-10-2015         |    EUR 15000.00<br>\nC04        |    MARCUS       |    35     |    01-01-2021         |    AUD 350000.00<br>\n<br>\n<h4>Select Columns Node Configuration And Output</h4>\n<br>\n[CUST_CD], [CUST_NAME] and [SALARY] columns from the incoming Dataframe are selected to be part of the outgoing Dataframe.<br>\nOutgoing Dataframe would be created as below containing only the selected columns:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    SALARY<br>\n-------------------------------------------------<br>\nC01        |    MATT         |    USD 200000.00<br>\nC02        |    LISA         |    GBP 100000.00<br>\nC03        |    ROBIN        |    EUR 15000.00<br>\nC04        |    MARCUS       |    AUD 350000.00<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeColumnFilter",
      "x": "646.4px",
      "y": "466.388px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "[\"Customer_ID\",\"MasterData\"]",
          "widget": "variables",
          "title": "Columns",
          "description": "Columns to be included in the output DataFrame",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "1",
      "target": "2",
      "id": 1
    },
    {
      "source": "15",
      "target": "17",
      "id": 2
    },
    {
      "source": "17",
      "target": "19",
      "id": 3
    },
    {
      "source": "21",
      "target": "22",
      "id": 4
    },
    {
      "source": "22",
      "target": "24",
      "id": 5
    },
    {
      "source": "2",
      "target": "25",
      "id": 6
    },
    {
      "source": "25",
      "target": "26",
      "id": 7
    },
    {
      "source": "26",
      "target": "27",
      "id": 8
    },
    {
      "source": "27",
      "target": "28",
      "id": 9
    },
    {
      "source": "28",
      "target": "30",
      "id": 10
    },
    {
      "source": "14",
      "target": "31",
      "id": 11
    },
    {
      "source": "31",
      "target": "32",
      "id": 12
    },
    {
      "source": "14",
      "target": "15",
      "id": 13
    },
    {
      "source": "32",
      "target": "33",
      "id": 14
    },
    {
      "source": "33",
      "target": "30",
      "id": 15
    },
    {
      "source": "30",
      "target": "21",
      "id": 16
    }
  ],
  "dataSetDetails": [],
  "engine": "pyspark"
}