{
  "name": "01-Data-Processing",
  "uuid": "132be50d-6acc-47cc-afec-b1c3ff3b9573",
  "category": "Data Processing",
  "parameters": " --var exploreDataset=false --var payment_terms='Monthly','Quarterly','Annually' --var product_category='Software','Hardware','Service' --var product_subcategory='Basic','Standard','Premium' --var customer_category='Enterprise','SMB','Startup' --var exploreDataset1=false --var exploreDataset2=true --var back1=false",
  "nodes": [
    {
      "id": "1",
      "name": "Dataset Structured",
      "description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset was defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",
      "details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",
      "examples": "<h2> Dataset Structured Node Example</h2>\n<br>\nScenario:<br>\n<br>\nLet's say you have multiple datasets available in your workflow and you want to select one of them as input for the next node. You can use the Dataset Structured node to choose the desired dataset.<br>\n<br>\nConfiguration:<br>\n<br>\n1. **Output Storage Level:** Select the desired storage level for the output DataFrame.<br>\n2. **Dataset:** Choose the dataset from the dropdown list.<br>\n<br>\nOutput:<br>\n<br>\nThe node will output the selected dataset as a DataFrame.<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "348.375px",
      "y": "236.4px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dataset",
          "value": "6c70424d-0fc1-46b7-a898-41ea932e0f42",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "2",
      "name": "Dataset Structured",
      "description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset was defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",
      "details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",
      "examples": "<h2> Dataset Structured Node Example</h2>\n<br>\nScenario:<br>\n<br>\nLet's say you have multiple datasets available in your workflow and you want to select one of them as input for the next node. You can use the Dataset Structured node to choose the desired dataset.<br>\n<br>\nConfiguration:<br>\n<br>\n1. **Output Storage Level:** Select the desired storage level for the output DataFrame.<br>\n2. **Dataset:** Choose the dataset from the dropdown list.<br>\n<br>\nOutput:<br>\n<br>\nThe node will output the selected dataset as a DataFrame.<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "340.588px",
      "y": "363.6px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dataset",
          "value": "f9fd182e-c722-4c0e-bcee-7728060a8680",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "3",
      "name": "Dataset Structured",
      "description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset was defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",
      "details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",
      "examples": "<h2> Dataset Structured Node Example</h2>\n<br>\nScenario:<br>\n<br>\nLet's say you have multiple datasets available in your workflow and you want to select one of them as input for the next node. You can use the Dataset Structured node to choose the desired dataset.<br>\n<br>\nConfiguration:<br>\n<br>\n1. **Output Storage Level:** Select the desired storage level for the output DataFrame.<br>\n2. **Dataset:** Choose the dataset from the dropdown list.<br>\n<br>\nOutput:<br>\n<br>\nThe node will output the selected dataset as a DataFrame.<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "52.3875px",
      "y": "30.3875px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dataset",
          "value": "180a3e82-2623-46c5-976a-6e87f53354aa",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "4",
      "name": "Dataset Structured",
      "description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset was defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",
      "details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",
      "examples": "<h2> Dataset Structured Node Example</h2>\n<br>\nScenario:<br>\n<br>\nLet's say you have multiple datasets available in your workflow and you want to select one of them as input for the next node. You can use the Dataset Structured node to choose the desired dataset.<br>\n<br>\nConfiguration:<br>\n<br>\n1. **Output Storage Level:** Select the desired storage level for the output DataFrame.<br>\n2. **Dataset:** Choose the dataset from the dropdown list.<br>\n<br>\nOutput:<br>\n<br>\nThe node will output the selected dataset as a DataFrame.<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "221.188px",
      "y": "220.2px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dataset",
          "value": "fc78d13a-cb8d-47f3-b31b-f376e1ef8fcb",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "5",
      "name": "Dataset Structured",
      "description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset was defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",
      "details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",
      "examples": "<h2> Dataset Structured Node Example</h2>\n<br>\nScenario:<br>\n<br>\nLet's say you have multiple datasets available in your workflow and you want to select one of them as input for the next node. You can use the Dataset Structured node to choose the desired dataset.<br>\n<br>\nConfiguration:<br>\n<br>\n1. **Output Storage Level:** Select the desired storage level for the output DataFrame.<br>\n2. **Dataset:** Choose the dataset from the dropdown list.<br>\n<br>\nOutput:<br>\n<br>\nThe node will output the selected dataset as a DataFrame.<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "56.5875px",
      "y": "156.6px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "dataset",
          "value": "75390274-1fae-45cc-8fc4-127610bfe70f",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "8",
      "name": "Join Using SQL",
      "description": "This node registers the incoming DataFrames as temporary tables and executes the SQL provided",
      "details": "<h2>Join Using SQL Details</h2>\n<br>\n<ul>\n<li> This node receives two or more input data frames and creates the corresponding temporary tables.</li>\n<li> Allows the user to write a SQL query to join these temporary tables.</li>\n<li> The resulting output dataframe contains the output of the SQL execution.</li>\n</ul>",
      "examples": "<h2>Join Using SQL Examples</h2>\n<br>\n<h4> Two-table joins</h4>\n<br>\nThe following example shows a two-table join:<br>\nSELECT order_num, lname, fname FROM tempTable1, tempTable2<br>\nWHERE tempTable1.customer_num = tempTable2.customer_num<br>\n<br>\n<h4> Multi-table joins</h4>\n<br>\nThe following multiple-table join yields the company name of the customer who ordered an item as well as its stock number and manufacturer code:<br>\nSELECT DISTINCT company, stock_num, manu_code<br>\nFROM tempTable1 c, tempTable2 o, tempTable3 i<br>\nWHERE c.customer_num = o.customer_num<br>\nAND o.order_num = i.order_num;<br>\n<br>\n<h4> LEFT OUTER joins</h4>\n<br>\nThe below table join yields data of all customers irrespective of whether or not they have placed any orders:<br>\nSELECT c.ID, c.NAME, o.AMOUNT, o.DATE<br>\nFROM tempTable1 c<br>\nLEFT OUTER JOIN tempTable2 o<br>\nON (c.ID = o.CUSTOMER_ID)<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingSQL",
      "x": "337.575px",
      "y": "108.562px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTables",
          "value": "[\"tempTable1\",\"tempTable2\"]",
          "widget": "array_of_values",
          "title": "Temp Table Names",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "select t1.*, t2.* from tempTable1 as t1 join tempTable2 as t2 on t1.subscription_id = t2.product_id",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"customer_id\",\"subscription_id\",\"payment_terms\",\"invoice_amount\",\"payment_frequency\",\"subscription_start_date\",\"renewal_flag\",\"subscription_end_date\",\"product_id\",\"product_category\",\"product_subcategory\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "9",
      "name": "Join Using SQL",
      "description": "This node registers the incoming DataFrames as temporary tables and executes the SQL provided",
      "details": "<h2>Join Using SQL Details</h2>\n<br>\n<ul>\n<li> This node receives two or more input data frames and creates the corresponding temporary tables.</li>\n<li> Allows the user to write a SQL query to join these temporary tables.</li>\n<li> The resulting output dataframe contains the output of the SQL execution.</li>\n</ul>",
      "examples": "<h2>Join Using SQL Examples</h2>\n<br>\n<h4> Two-table joins</h4>\n<br>\nThe following example shows a two-table join:<br>\nSELECT order_num, lname, fname FROM tempTable1, tempTable2<br>\nWHERE tempTable1.customer_num = tempTable2.customer_num<br>\n<br>\n<h4> Multi-table joins</h4>\n<br>\nThe following multiple-table join yields the company name of the customer who ordered an item as well as its stock number and manufacturer code:<br>\nSELECT DISTINCT company, stock_num, manu_code<br>\nFROM tempTable1 c, tempTable2 o, tempTable3 i<br>\nWHERE c.customer_num = o.customer_num<br>\nAND o.order_num = i.order_num;<br>\n<br>\n<h4> LEFT OUTER joins</h4>\n<br>\nThe below table join yields data of all customers irrespective of whether or not they have placed any orders:<br>\nSELECT c.ID, c.NAME, o.AMOUNT, o.DATE<br>\nFROM tempTable1 c<br>\nLEFT OUTER JOIN tempTable2 o<br>\nON (c.ID = o.CUSTOMER_ID)<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingSQL",
      "x": "183.8px",
      "y": "99.8px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTables",
          "value": "[\"tempTable1\",\"tempTable2\"]",
          "widget": "array_of_values",
          "title": "Temp Table Names",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "select t1.*, t2.subscription_start_date, t2.renewal_flag, t2.subscription_end_date from tempTable1 as t1 join tempTable2 as t2 on t1.customer_id = t2.customer_id and t1.subscription_id = t2.subscription_id",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"customer_id\",\"subscription_id\",\"payment_terms\",\"invoice_amount\",\"payment_frequency\",\"subscription_start_date\",\"renewal_flag\",\"subscription_end_date\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "10",
      "name": "Join Using SQL",
      "description": "This node registers the incoming DataFrames as temporary tables and executes the SQL provided",
      "details": "<h2>Join Using SQL Details</h2>\n<br>\n<ul>\n<li> This node receives two or more input data frames and creates the corresponding temporary tables.</li>\n<li> Allows the user to write a SQL query to join these temporary tables.</li>\n<li> The resulting output dataframe contains the output of the SQL execution.</li>\n</ul>",
      "examples": "<h2>Join Using SQL Examples</h2>\n<br>\n<h4> Two-table joins</h4>\n<br>\nThe following example shows a two-table join:<br>\nSELECT order_num, lname, fname FROM tempTable1, tempTable2<br>\nWHERE tempTable1.customer_num = tempTable2.customer_num<br>\n<br>\n<h4> Multi-table joins</h4>\n<br>\nThe following multiple-table join yields the company name of the customer who ordered an item as well as its stock number and manufacturer code:<br>\nSELECT DISTINCT company, stock_num, manu_code<br>\nFROM tempTable1 c, tempTable2 o, tempTable3 i<br>\nWHERE c.customer_num = o.customer_num<br>\nAND o.order_num = i.order_num;<br>\n<br>\n<h4> LEFT OUTER joins</h4>\n<br>\nThe below table join yields data of all customers irrespective of whether or not they have placed any orders:<br>\nSELECT c.ID, c.NAME, o.AMOUNT, o.DATE<br>\nFROM tempTable1 c<br>\nLEFT OUTER JOIN tempTable2 o<br>\nON (c.ID = o.CUSTOMER_ID)<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingSQL",
      "x": "466.8px",
      "y": "173.8px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTables",
          "value": "[\"tempTable1\",\"tempTable2\"]",
          "widget": "array_of_values",
          "title": "Temp Table Names",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "select t1.*, t2.customer_category, t2.risk_score from tempTable1 as t1 join tempTable2 as t2 on t1.customer_id = t2.customer_id",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"customer_id\",\"subscription_id\",\"payment_terms\",\"invoice_amount\",\"payment_frequency\",\"subscription_start_date\",\"renewal_flag\",\"subscription_end_date\",\"product_id\",\"product_category\",\"product_subcategory\",\"customer_category\",\"risk_score\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "11",
      "name": "Group By",
      "description": "Group By Node",
      "details": "<h2>Group By Details</h2>\n<br>\n<h3>Aggregation Settings</h3>\nThis node groups row values based on categorical columns selected by the user and then calculates aggregate statistics of the grouped columns. <br>\nThe Grouping Columns allows the user to select which columns to group rows by, and the Variables List allows the user to select which aggregate statistics will be generated. <br>\n<br>\n<h3>Filter Settings</h3>\nThe Filter Settings allow the user to provide additional clauses before and after the data is aggregated.<br>\nThe Where Clause allows the user to filter the data before it is aggregated, and the Having Clause allows the user to filter the data after it has been aggregated. <br>\nBoth the Where and Having Clauses are similar in use to those that exist in many forms of SQL.<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    LOCATION    |    DEPT         |    SALARY<br>\n-----------------------------------------------------------------------------<br>\nE01       |    DAVID       |    NEW YORK    |    HR           |    10000<br>\nE02       |    JOHN        |    NEW JERSEY  |    SALES        |    11000<br>\nE03       |    MARTIN      |    NEW YORK    |    MARKETING    |    12000<br>\nE04       |    TONY        |    NEW JERSEY  |    MARKETING    |    13000<br>\nE05       |    ROSS        |    NEW YORK    |    FRONT DESK   |    10000<br>\nE06       |    LISA        |    NEW JERSEY  |    FRONT DESK   |    11000<br>\nE07       |    PAUL        |    NEW YORK    |    MAINTENANCE  |    12000<br>\nE08       |    MARK        |    NEW JERSEY  |    MAINTENANCE  |    13000<br>\n<br>\nif GroupBy node is configured as below:<br>\n<br>\nGROUPING COLUMNS      :    DEPT<br>\n<br>\nAGGREGATE COLUMNS    |    AGGREGATE OPERATION<br>\n-------------------------------------------------<br>\nEMP_CD               |    COUNT<br>\nSALARY               |    SUM<br>\n<br>\nthen outgoing Dataframe would be created as below after performing specified aggregation<br>\nCount of Employees and Summation of Salary all Employees is computed for each [DEPT]:<br>\n<br>\nDEPT           |    count_emp_cd    |    sum_salary<br>\n----------------------------------------------------------<br>\nFRONT DESK     |    2               |    21000<br>\nMARKETING      |    2               |    25000<br>\nHR             |    1               |    10000<br>\nSALES          |    1               |    11000<br>\nMAINTENANCE    |    2               |    25000<br>\n<br>\nif [WHERE CLAUSE] is entered as [DEPT = 'HR'] then outgoing Dataframe would consists of data only from HR department.<br>\n<br>\nif [HAVING CLAUSE] is entered as [COUNT(*) > 1] then outgoing Dataframe would consists of data for Department where count of Employees is more than 1.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeGroupBy",
      "x": "466.188px",
      "y": "354.188px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Aggregation Setting",
          "value": "",
          "widget": "tab",
          "title": "Aggregation Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "groupingCols",
          "value": "[\"subscription_id\"]",
          "widget": "variables",
          "title": "Grouping Columns",
          "description": "Grouping Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateCols",
          "value": "[\"feedback_score\"]",
          "widget": "variables_list_select",
          "title": "Aggregate Columns",
          "description": "Aggregate Columns",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "Aggregate",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "aggregateOperations",
          "value": "[\"avg\"]",
          "widget": "variables_list_array",
          "title": "Aggregate Operation",
          "description": "Aggregate Operation",
          "optionsArray": [
            "sum",
            "avg",
            "min",
            "max",
            "count",
            "count_distinct"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"avg_feedback_score\"]",
          "widget": "variables_list_textfield",
          "title": "Output Column Names",
          "description": "Output Column Names, default value is aggregateOperation_aggregateCol.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Filter Setting",
          "value": "",
          "widget": "tab",
          "title": "Filter Setting",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "whereClause",
          "value": "",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Where Clause",
          "description": "where condition before group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "havingClause",
          "value": "",
          "widget": "code_editor",
          "type": "sparksql",
          "title": "Having Clause",
          "description": "having condition after group by function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "12",
      "name": "Join Using SQL",
      "description": "This node registers the incoming DataFrames as temporary tables and executes the SQL provided",
      "details": "<h2>Join Using SQL Details</h2>\n<br>\n<ul>\n<li> This node receives two or more input data frames and creates the corresponding temporary tables.</li>\n<li> Allows the user to write a SQL query to join these temporary tables.</li>\n<li> The resulting output dataframe contains the output of the SQL execution.</li>\n</ul>",
      "examples": "<h2>Join Using SQL Examples</h2>\n<br>\n<h4> Two-table joins</h4>\n<br>\nThe following example shows a two-table join:<br>\nSELECT order_num, lname, fname FROM tempTable1, tempTable2<br>\nWHERE tempTable1.customer_num = tempTable2.customer_num<br>\n<br>\n<h4> Multi-table joins</h4>\n<br>\nThe following multiple-table join yields the company name of the customer who ordered an item as well as its stock number and manufacturer code:<br>\nSELECT DISTINCT company, stock_num, manu_code<br>\nFROM tempTable1 c, tempTable2 o, tempTable3 i<br>\nWHERE c.customer_num = o.customer_num<br>\nAND o.order_num = i.order_num;<br>\n<br>\n<h4> LEFT OUTER joins</h4>\n<br>\nThe below table join yields data of all customers irrespective of whether or not they have placed any orders:<br>\nSELECT c.ID, c.NAME, o.AMOUNT, o.DATE<br>\nFROM tempTable1 c<br>\nLEFT OUTER JOIN tempTable2 o<br>\nON (c.ID = o.CUSTOMER_ID)<br>",
      "type": "join",
      "nodeClass": "fire.nodes.etl.NodeJoinUsingSQL",
      "x": "568.8px",
      "y": "271.8px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "tempTables",
          "value": "[\"tempTable1\",\"tempTable2\"]",
          "widget": "array_of_values",
          "title": "Temp Table Names",
          "description": "Temp Table Name to be used",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "sql",
          "value": "select t1.*, t2.avg_feedback_score from tempTable1 as t1 left join tempTable2 as t2 on t1.subscription_id = t2.subscription_id",
          "widget": "code_editor",
          "type": "sql_mysql",
          "title": "SQL",
          "description": "SQL to be run",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "schema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[\"customer_id\",\"subscription_id\",\"payment_terms\",\"invoice_amount\",\"payment_frequency\",\"subscription_start_date\",\"renewal_flag\",\"subscription_end_date\",\"product_id\",\"product_category\",\"product_subcategory\",\"customer_category\",\"risk_score\",\"avg_feedback_score\"]",
          "widget": "schema_col_names",
          "title": "Column Names for the CSV",
          "description": "New Output Columns of the SQL",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"DOUBLE\"]",
          "widget": "schema_col_types",
          "title": "Column Types for the CSV",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",
          "widget": "schema_col_formats",
          "title": "Column Formats for the CSV",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "13",
      "name": "Imputing With Mean Value",
      "description": "Imputing the continuous variables by mean.",
      "details": "This node imputes the missing values in the specified columns by mean of the values in the column.<br>",
      "examples": "Incoming Dataframe has following rows and [AGE] column has missing value / [NULL] for some rows:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |\t\t\t<br>\nCD04       |    MATT         |\t\t\t<br>\n<br>\nIf imputingwithmeanvalue node is configured to Impute [AGE] with mean value then missing values in [AGE] column would be replaced with 35 which is the mean of [AGE] column.<br>\nOutgoing Dataframe would result as below:<br>\n<br>\nCUST_CD    |    CUST_NAME    |    AGE<br>\n-----------------------------------------<br>\nCD01       |    DAVID        |    30<br>\nCD02       |    MARY         |    40<br>\nCD03       |    PAUL         |    35\t\t\t<br>\nCD04       |    MATT         |    35<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ml.NodeReplaceMissingValueWithMean",
      "x": "691.797px",
      "y": "287.797px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"avg_feedback_score\"]",
          "widget": "variables",
          "title": "Column Names",
          "description": "Columns type should be continuous",
          "datatypes": [
            "integer",
            "long",
            "double",
            "float"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "14",
      "name": "Save CSV",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "Saves the DataFrame into the specified location in CSV Format",
      "details": "This node saves incoming Dataframe into the specified location in CSV format.<br>",
      "examples": "path-folder1/folder2/filename<br>\n<br>\nthe file will be saved under the file name at the path provided<br>\nif folder is not present it will be created and save the file<br>\nif the file already exists selection in save mode determines what happens to the file,append-adds the file data to it overwrite-replaces the file altogether<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.save.NodeSaveCSV",
      "x": "1137.59px",
      "y": "518.594px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "path",
          "value": "data/SALES/Subscription-Renewal-Prediction/Processed-Data/",
          "widget": "textfield",
          "title": "Path",
          "description": "Path where to save the CSV files",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "encoding",
          "value": "UTF-8",
          "widget": "textfield",
          "title": "Encoding",
          "description": "Decodes the CSV files by the given encoding type",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "quote",
          "value": "\"",
          "widget": "textfield",
          "title": "Quote",
          "description": "Sets a single character used for escaping quoted values where the separator can be part of the value",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "escape",
          "value": "\\",
          "widget": "textfield",
          "title": "Escape",
          "description": "Sets a single character used for escaping quotes inside an already quoted value.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "15",
      "name": "Math Functions",
      "description": "Create new columns or replaces the existing ones by using the specified function",
      "details": "<h2>Math functions Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe using specified math functions.<br>\n<br>\nOne can choose a column from the dropdown in the field `inputCols`, and then choose one of the function (log, sqrt, pow, exp, round) to apply to the column chosen.<br>\n<br>\nChoose whether you want to replace(true) the existing column or create a new column(false) by choosing the value for the field `replaceExistingCols` .<br>\n<br>\nThen the output dataframe will be created with the new column.<br>\n<br>\n<h4>Examples:</h4>\n<ul>\n<li>\t log :  To get the natural logarithm (base e). Ex: log(LIST_PRICE)</li>\n<li>\t sqrt :  To get the positive square root. Ex: sqrt(LIST_PRICE)</li>\n<li>\t pow :  Raises expr1 to the power of expr2. Ex: pow(LIST_PRICE, 2)</li>\n<li>\t exp :  Returns e to the power of expr. Ex: exp(LIST_PRICE)</li>\n<li>  round: Rounds the column value to the nearest intege. Ex: round(LIST_PRICE,2)</li>\n</ul>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\nIf MathFuntion node is configured to compute a new column [SQRT_AMT] based on function SQRT of `TAX_AMT` column<br>\nthen outgoing Dataframe would be created as below with new column added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    SQRT_AMT<br>\n------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    10.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    14.14<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    3.16<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeMathFunctionsMultiple",
      "x": "626px",
      "y": "621px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "inputCols",
          "value": "[\"invoice_amount_new\"]",
          "widget": "variables_list_select",
          "title": "Columns",
          "description": "Columns",
          "datatypes": [
            "double",
            "integer",
            "float",
            "long"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "functions",
          "value": "[\"log\"]",
          "widget": "variables_list_array",
          "title": "Function",
          "description": "Math Function to apply",
          "optionsArray": [
            "log",
            "sqrt",
            "pow",
            "exp",
            "round",
            "abs"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "replaceExistingCols",
          "value": "[\"true\"]",
          "widget": "variables_list_array",
          "title": "Replace Existing Cols",
          "description": "Replace Existing Columns (true, false)",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "scales",
          "value": "[\"\"]",
          "widget": "variables_list_textfield",
          "title": "Scale",
          "description": "Scale to be used when applying the Math Function",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "16",
      "name": "Math Expression",
      "description": "Creates new columns using the specified expressions",
      "details": "<h2> Math Expression Details </h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the specified expression.<br>\n<br>\nNew columns can be computed using existing columns in the Dataframe.<br>\n<br>\nFollowing functions can be used in Expressions:<br>\n<br>\n<h4> Computations</h4>\n<ul>\n<li>\tComputation expression -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n</ul>\n<h4>Math Functions</h4>\n<ul>\n<li>\t abs :  Get the absolute value of an expression. Ex: abs(LIST_PRICE)</li>\n<li>\t pow :  Raises expr1 to the power of expr2. Ex: pow(LIST_PRICE, 2)</li>\n<li>\t cos :  Get the trigonometric cosine of an expression. Ex: cos(LIST_PRICE)</li>\n</ul>\nValid examples of Math functions - abs, acros, asin, atan, atan2, bin, cbrt, ceil, conv, cos, sosh, exp, expm1, factorial, floor, hex, hypot, log, log10, log1p, log2, pmod, pow, rint, round, shiftLeft, shiftRight, shiftRightUnsigned, signum, sin, sinh, sqrt, tan, tanh, toDegrees, toRadians, unhex (single choice)<br>",
      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\nIf MathExpression node is configured to compute a new column [NET_AMT] based on expression [LIST_PRICE + TAX_AMT - DISCOUNT]<br>\nthen outgoing Dataframe would be created as below with new column added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    <br>\n------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeMathExpression",
      "x": "575px",
      "y": "471px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "[\"invoice_amount_new\"]",
          "widget": "key_array",
          "type": "sparksql",
          "title": "Output Column",
          "description": "Output Column Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "expressions",
          "value": "[\"invoice_amount + 1\"]",
          "widget": "value_array",
          "type": "sparksql",
          "title": "Math Expression",
          "description": "Define math expression.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": true,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "18",
      "name": "Expressions",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by adding new columns to the incoming Dataframe as per the Expression computation",
      "details": "<h2>Expressions Node Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the expressions computated.<br>\n<br>\nIt computes expressions to calculate the value of a metric column based on mathematical or logical operations performed on other metric columns.<br>\n<br>\nNew column can also be computed using existing columns in the Dataframe.<br>\n<br>\n<h3>Following functions can be used in Expressions:</h3>\n<br>\n<h3> Mathematical Computations</h3>\n<br>\n<ul>\n<li>\tMaths Operations -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n<li>\tMaths Operations -> Example : DISCOUNT / LIST_PRICE</li>\n<li>\tMaths Operations -> Example : (DISCOUNT / LIST_PRICE) * 100</li>\n</ul>\n<h3>String Functions</h3>\n<br>\n<ul>\n<li>\tConcatenation     -> Example : CONCAT(PRD_CD,':',PRD_NAME)</li>\n<li>\tSubstring     -> Example : SUBSTR(PRD_NAME,1,3)</li>\n<li>\tReplace\t\t \t-> Example : REPLACE(PRD_NAME,'M','$')</li>\n<li>\tRight\t\t \t-> Example : RIGHT(PRD_NAME, 5)</li>\n<li>\tLeft\t\t \t-> Example : LEFT(PRD_NAME, 5)</li>\n<li>\tRight Trim\t \t-> Example : RTRIM(PRD_NAME)</li>\n<li>\tIntial Caps\t \t-> Example : INITCAP(LOWER(PRD_NAME))</li>\n<li>\tLength\t\t \t-> Example : LENGTH(PRD_NAME)</li>\n<li>\tSplit\t\t \t-> Example : SPLIT(PRD_NAME, ' ')</li>\n</ul>\n<h3>Number Format Functions</h3>\n<br>\n<ul>\n<li>\tFormat Number\t-> Example : FORMAT_NUMBER(LIST_PRICE, '#,###,###,###.00')</li>\n</ul>\n<h3>Date and Timestamp Functions</h3>\n<br>\n<h4>Fetch Current Date and Time</h4>\n<br>\n<ul>\n<li>\tCurrent Date value\t\t\t\t          -> Example : CURRENT_DATE</li>\n<li>\tCurrent Date Time value\t\t\t\t      -> Example : CURRENT_TIMESTAMP</li>\n</ul>\n<h4>Format Date-Time values</h4>\n<ul>\n<li>\tDate Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy')</li>\n<li>\tDate-Time Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy hh:mm:ss')</li>\n</ul>\n<h4>String to Date-Time conversion</h4>\n<ul>\n<li>\tConvert a String to Date\t      \t\t-> Example : TO_DATE('12-DEC-21', 'dd-MMM-yy')</li>\n<li>\tConvert a String to Datetime\t\t\t\t\t\t            \t-> TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS')</li>\n</ul>\n<h4>Date-Time addition and substraction</h4>\n<ul>\n<li>\tAdd/Substract Years to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 12)</li>\n<li>\tAdd/Substract Months to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 3)</li>\n<li>\tAdd/Substract Days to a Date\t\t    -> Example : DATE_ADD(CURRENT_DATE, -1)</li>\n<li>\tAdd/Substract Hours to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours</li>\n<li>\tAdd/Substract Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Minutes</li>\n<li>\tAdd/Substract Seconds to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Seconds</li>\n<li>\tAdd/Substract Hours and Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours + Interval 2 Minutes</li>\n<li>\tSubstract Hours and Minutes from a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') - Interval 2 Hours - Interval 2 Minutes</li>\n</ul>\n<h4>Fetch Next Day and Last Day of Month</h4>\n<ul>\n<li>\tLast Day of a Month   \t\t\t\t      -> Example : LAST_DAY(CURRENT_DATE)</li>\n<li>\tNext Day value\t\t   \t\t\t\t        -> Example : NEXT_DAY(CURRENT_DATE, 'Sunday')</li>\n<li>\tFirst Day of Year/Month\t\t\t\t      -> Example : DATE_TRUNC('MONTH', CURRENT_DATE)</li>\n<li>\tYear/Month/Quarter/DayOfMonth value\t-> Example : YEAR(CURRENT_DATE)/MONTH(CURRENT_DATE)/QUARTER(CURRENT_DATE)/DAYOFMONTH(CURRENT_DATE)/DAYOFWEEK(CURRENT_DATE)</li>\n<li>\tDay/Week count of the Year\t\t\t    -> Example : DAYOFWEEK(CURRENT_DATE)/WEEKOFYEAR(CURRENT_DATE)</li>\n</ul>\n<h4>Date Difference functions</h4>\n<ul>\n<li>\tDate Diff between two Dates\t\t\t    -> Example : DATEDIFF(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Months between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Years between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy')) / 12</li>\n</ul>\n<h3>Regex Functions</h3>\n<br>\n<ul>\n<li>\tReplace using Regex\t\t-> Example : REGEXP_REPLACE(PRD_NAME, 'E', '#')</li>\n</ul>",
      "examples": "<h2>Expressions Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\n<h4>Expressions Node Configuration</h4>\n<br>\nExpressions node is configured to compute new columns as below:<br>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nNET_AMT                  |    LIST_PRICE + TAX_AMT - DISCOUNT<br>\nPRD_DETAILS              |    CONCAT(PRD_CD,':',PRD_NAME)<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutgoing Dataframe would be created as below with new columns added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    |    PRD_DETAILS<br>\n--------------------------------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0     |    P01:DRILL MACHINE<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0     |    P02:WEIGHING MACHINE<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0      |    P03:HAMMER<br>\n<br>\n<h4>Computing Current Date value using Expression:</h4>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nCURRENT_DATE_VAL         |    CURRENT_DATE<br>\nCURRENT_DATETIME_VAL     |    CURRENT_TIMESTAMP<br>\n<br>\nOutput would contain below value<br>\n<br>\nCURRENT_DATE_VAL         |    CURRENT_DATETIME_VAL<br>\n-----------------------------------------------------------------<br>\n2022-09-07               |    2022-09-07 10:05:12.432<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExpressions",
      "x": "752px",
      "y": "462px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Expressions",
          "value": "",
          "widget": "tab",
          "title": "Expressions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "[\"feedback_impact\"]",
          "widget": "key_array",
          "type": "sparksql",
          "title": "Column Name",
          "description": "Output Column Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": true,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "expressions",
          "value": "[\"avg_feedback_score *  invoice_amount / 100\"]",
          "widget": "value_array",
          "type": "sparksql",
          "title": "Expression",
          "description": "Expression to create new columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputSchema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Output Column Name",
          "description": "Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Output Column Type",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Output Column Format",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "19",
      "name": "Expressions",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by adding new columns to the incoming Dataframe as per the Expression computation",
      "details": "<h2>Expressions Node Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the expressions computated.<br>\n<br>\nIt computes expressions to calculate the value of a metric column based on mathematical or logical operations performed on other metric columns.<br>\n<br>\nNew column can also be computed using existing columns in the Dataframe.<br>\n<br>\n<h3>Following functions can be used in Expressions:</h3>\n<br>\n<h3> Mathematical Computations</h3>\n<br>\n<ul>\n<li>\tMaths Operations -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n<li>\tMaths Operations -> Example : DISCOUNT / LIST_PRICE</li>\n<li>\tMaths Operations -> Example : (DISCOUNT / LIST_PRICE) * 100</li>\n</ul>\n<h3>String Functions</h3>\n<br>\n<ul>\n<li>\tConcatenation     -> Example : CONCAT(PRD_CD,':',PRD_NAME)</li>\n<li>\tSubstring     -> Example : SUBSTR(PRD_NAME,1,3)</li>\n<li>\tReplace\t\t \t-> Example : REPLACE(PRD_NAME,'M','$')</li>\n<li>\tRight\t\t \t-> Example : RIGHT(PRD_NAME, 5)</li>\n<li>\tLeft\t\t \t-> Example : LEFT(PRD_NAME, 5)</li>\n<li>\tRight Trim\t \t-> Example : RTRIM(PRD_NAME)</li>\n<li>\tIntial Caps\t \t-> Example : INITCAP(LOWER(PRD_NAME))</li>\n<li>\tLength\t\t \t-> Example : LENGTH(PRD_NAME)</li>\n<li>\tSplit\t\t \t-> Example : SPLIT(PRD_NAME, ' ')</li>\n</ul>\n<h3>Number Format Functions</h3>\n<br>\n<ul>\n<li>\tFormat Number\t-> Example : FORMAT_NUMBER(LIST_PRICE, '#,###,###,###.00')</li>\n</ul>\n<h3>Date and Timestamp Functions</h3>\n<br>\n<h4>Fetch Current Date and Time</h4>\n<br>\n<ul>\n<li>\tCurrent Date value\t\t\t\t          -> Example : CURRENT_DATE</li>\n<li>\tCurrent Date Time value\t\t\t\t      -> Example : CURRENT_TIMESTAMP</li>\n</ul>\n<h4>Format Date-Time values</h4>\n<ul>\n<li>\tDate Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy')</li>\n<li>\tDate-Time Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy hh:mm:ss')</li>\n</ul>\n<h4>String to Date-Time conversion</h4>\n<ul>\n<li>\tConvert a String to Date\t      \t\t-> Example : TO_DATE('12-DEC-21', 'dd-MMM-yy')</li>\n<li>\tConvert a String to Datetime\t\t\t\t\t\t            \t-> TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS')</li>\n</ul>\n<h4>Date-Time addition and substraction</h4>\n<ul>\n<li>\tAdd/Substract Years to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 12)</li>\n<li>\tAdd/Substract Months to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 3)</li>\n<li>\tAdd/Substract Days to a Date\t\t    -> Example : DATE_ADD(CURRENT_DATE, -1)</li>\n<li>\tAdd/Substract Hours to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours</li>\n<li>\tAdd/Substract Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Minutes</li>\n<li>\tAdd/Substract Seconds to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Seconds</li>\n<li>\tAdd/Substract Hours and Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours + Interval 2 Minutes</li>\n<li>\tSubstract Hours and Minutes from a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') - Interval 2 Hours - Interval 2 Minutes</li>\n</ul>\n<h4>Fetch Next Day and Last Day of Month</h4>\n<ul>\n<li>\tLast Day of a Month   \t\t\t\t      -> Example : LAST_DAY(CURRENT_DATE)</li>\n<li>\tNext Day value\t\t   \t\t\t\t        -> Example : NEXT_DAY(CURRENT_DATE, 'Sunday')</li>\n<li>\tFirst Day of Year/Month\t\t\t\t      -> Example : DATE_TRUNC('MONTH', CURRENT_DATE)</li>\n<li>\tYear/Month/Quarter/DayOfMonth value\t-> Example : YEAR(CURRENT_DATE)/MONTH(CURRENT_DATE)/QUARTER(CURRENT_DATE)/DAYOFMONTH(CURRENT_DATE)/DAYOFWEEK(CURRENT_DATE)</li>\n<li>\tDay/Week count of the Year\t\t\t    -> Example : DAYOFWEEK(CURRENT_DATE)/WEEKOFYEAR(CURRENT_DATE)</li>\n</ul>\n<h4>Date Difference functions</h4>\n<ul>\n<li>\tDate Diff between two Dates\t\t\t    -> Example : DATEDIFF(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Months between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Years between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy')) / 12</li>\n</ul>\n<h3>Regex Functions</h3>\n<br>\n<ul>\n<li>\tReplace using Regex\t\t-> Example : REGEXP_REPLACE(PRD_NAME, 'E', '#')</li>\n</ul>",
      "examples": "<h2>Expressions Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\n<h4>Expressions Node Configuration</h4>\n<br>\nExpressions node is configured to compute new columns as below:<br>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nNET_AMT                  |    LIST_PRICE + TAX_AMT - DISCOUNT<br>\nPRD_DETAILS              |    CONCAT(PRD_CD,':',PRD_NAME)<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutgoing Dataframe would be created as below with new columns added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    |    PRD_DETAILS<br>\n--------------------------------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0     |    P01:DRILL MACHINE<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0     |    P02:WEIGHING MACHINE<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0      |    P03:HAMMER<br>\n<br>\n<h4>Computing Current Date value using Expression:</h4>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nCURRENT_DATE_VAL         |    CURRENT_DATE<br>\nCURRENT_DATETIME_VAL     |    CURRENT_TIMESTAMP<br>\n<br>\nOutput would contain below value<br>\n<br>\nCURRENT_DATE_VAL         |    CURRENT_DATETIME_VAL<br>\n-----------------------------------------------------------------<br>\n2022-09-07               |    2022-09-07 10:05:12.432<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExpressions",
      "x": "794px",
      "y": "624px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Expressions",
          "value": "",
          "widget": "tab",
          "title": "Expressions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "[\"risk_adjusted_score\"]",
          "widget": "key_array",
          "type": "sparksql",
          "title": "Column Name",
          "description": "Output Column Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": true,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "expressions",
          "value": "[\"risk_score *  invoice_amount\"]",
          "widget": "value_array",
          "type": "sparksql",
          "title": "Expression",
          "description": "Expression to create new columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputSchema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Output Column Name",
          "description": "Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Output Column Type",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Output Column Format",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "20",
      "name": "Expressions",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new DataFrame by adding new columns to the incoming Dataframe as per the Expression computation",
      "details": "<h2>Expressions Node Details</h2>\n<br>\nThis node creates a new DataFrame by adding new columns to the incoming Dataframe as per the expressions computated.<br>\n<br>\nIt computes expressions to calculate the value of a metric column based on mathematical or logical operations performed on other metric columns.<br>\n<br>\nNew column can also be computed using existing columns in the Dataframe.<br>\n<br>\n<h3>Following functions can be used in Expressions:</h3>\n<br>\n<h3> Mathematical Computations</h3>\n<br>\n<ul>\n<li>\tMaths Operations -> Example : LIST_PRICE + TAX_AMT - DISCOUNT</li>\n<li>\tMaths Operations -> Example : DISCOUNT / LIST_PRICE</li>\n<li>\tMaths Operations -> Example : (DISCOUNT / LIST_PRICE) * 100</li>\n</ul>\n<h3>String Functions</h3>\n<br>\n<ul>\n<li>\tConcatenation     -> Example : CONCAT(PRD_CD,':',PRD_NAME)</li>\n<li>\tSubstring     -> Example : SUBSTR(PRD_NAME,1,3)</li>\n<li>\tReplace\t\t \t-> Example : REPLACE(PRD_NAME,'M','$')</li>\n<li>\tRight\t\t \t-> Example : RIGHT(PRD_NAME, 5)</li>\n<li>\tLeft\t\t \t-> Example : LEFT(PRD_NAME, 5)</li>\n<li>\tRight Trim\t \t-> Example : RTRIM(PRD_NAME)</li>\n<li>\tIntial Caps\t \t-> Example : INITCAP(LOWER(PRD_NAME))</li>\n<li>\tLength\t\t \t-> Example : LENGTH(PRD_NAME)</li>\n<li>\tSplit\t\t \t-> Example : SPLIT(PRD_NAME, ' ')</li>\n</ul>\n<h3>Number Format Functions</h3>\n<br>\n<ul>\n<li>\tFormat Number\t-> Example : FORMAT_NUMBER(LIST_PRICE, '#,###,###,###.00')</li>\n</ul>\n<h3>Date and Timestamp Functions</h3>\n<br>\n<h4>Fetch Current Date and Time</h4>\n<br>\n<ul>\n<li>\tCurrent Date value\t\t\t\t          -> Example : CURRENT_DATE</li>\n<li>\tCurrent Date Time value\t\t\t\t      -> Example : CURRENT_TIMESTAMP</li>\n</ul>\n<h4>Format Date-Time values</h4>\n<ul>\n<li>\tDate Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy')</li>\n<li>\tDate-Time Format\t\t\t\t\t\t            \t-> Example : DATE_FORMAT(CURRENT_DATE, 'MMM dd, yyyy hh:mm:ss')</li>\n</ul>\n<h4>String to Date-Time conversion</h4>\n<ul>\n<li>\tConvert a String to Date\t      \t\t-> Example : TO_DATE('12-DEC-21', 'dd-MMM-yy')</li>\n<li>\tConvert a String to Datetime\t\t\t\t\t\t            \t-> TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS')</li>\n</ul>\n<h4>Date-Time addition and substraction</h4>\n<ul>\n<li>\tAdd/Substract Years to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 12)</li>\n<li>\tAdd/Substract Months to a Date\t\t  -> Example : ADD_MONTHS(CURRENT_DATE, 3)</li>\n<li>\tAdd/Substract Days to a Date\t\t    -> Example : DATE_ADD(CURRENT_DATE, -1)</li>\n<li>\tAdd/Substract Hours to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours</li>\n<li>\tAdd/Substract Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Minutes</li>\n<li>\tAdd/Substract Seconds to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Seconds</li>\n<li>\tAdd/Substract Hours and Minutes to a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') + Interval 2 Hours + Interval 2 Minutes</li>\n<li>\tSubstract Hours and Minutes from a Date\t\t  -> Example : TO_TIMESTAMP('12-DEC-21 15:55:45:789', 'dd-MMM-yy HH:mm:ss:SSS') - Interval 2 Hours - Interval 2 Minutes</li>\n</ul>\n<h4>Fetch Next Day and Last Day of Month</h4>\n<ul>\n<li>\tLast Day of a Month   \t\t\t\t      -> Example : LAST_DAY(CURRENT_DATE)</li>\n<li>\tNext Day value\t\t   \t\t\t\t        -> Example : NEXT_DAY(CURRENT_DATE, 'Sunday')</li>\n<li>\tFirst Day of Year/Month\t\t\t\t      -> Example : DATE_TRUNC('MONTH', CURRENT_DATE)</li>\n<li>\tYear/Month/Quarter/DayOfMonth value\t-> Example : YEAR(CURRENT_DATE)/MONTH(CURRENT_DATE)/QUARTER(CURRENT_DATE)/DAYOFMONTH(CURRENT_DATE)/DAYOFWEEK(CURRENT_DATE)</li>\n<li>\tDay/Week count of the Year\t\t\t    -> Example : DAYOFWEEK(CURRENT_DATE)/WEEKOFYEAR(CURRENT_DATE)</li>\n</ul>\n<h4>Date Difference functions</h4>\n<ul>\n<li>\tDate Diff between two Dates\t\t\t    -> Example : DATEDIFF(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Months between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy'))</li>\n<li>\tNumber of Years between two Dates\t-> Example : MONTHS_BETWEEN(CURRENT_DATE, TO_DATE('12-DEC-21', 'dd-MMM-yy')) / 12</li>\n</ul>\n<h3>Regex Functions</h3>\n<br>\n<ul>\n<li>\tReplace using Regex\t\t-> Example : REGEXP_REPLACE(PRD_NAME, 'E', '#')</li>\n</ul>",
      "examples": "<h2>Expressions Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT<br>\n--------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0<br>\n<br>\n<h4>Expressions Node Configuration</h4>\n<br>\nExpressions node is configured to compute new columns as below:<br>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nNET_AMT                  |    LIST_PRICE + TAX_AMT - DISCOUNT<br>\nPRD_DETAILS              |    CONCAT(PRD_CD,':',PRD_NAME)<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutgoing Dataframe would be created as below with new columns added:<br>\n<br>\nPRD_CD    |    PRD_NAME          |    LIST_PRICE    |    TAX_AMT    |    DISCOUNT    |    NET_AMT    |    PRD_DETAILS<br>\n--------------------------------------------------------------------------------------------------------------------------------<br>\nP01       |    DRILL MACHINE     |    1000.0        |    100.0      |    50.0        |    1050.0     |    P01:DRILL MACHINE<br>\nP02       |    WEIGHING MACHINE  |    1500.0        |    200.0      |    150.0       |    1550.0     |    P02:WEIGHING MACHINE<br>\nP03       |    HAMMER            |    100.0         |    10.0       |    5.0         |    105.0      |    P03:HAMMER<br>\n<br>\n<h4>Computing Current Date value using Expression:</h4>\n<br>\nNEW COLUMNS NAME         |    EXPRESSIONS<br>\n-----------------------------------------------------------------<br>\nCURRENT_DATE_VAL         |    CURRENT_DATE<br>\nCURRENT_DATETIME_VAL     |    CURRENT_TIMESTAMP<br>\n<br>\nOutput would contain below value<br>\n<br>\nCURRENT_DATE_VAL         |    CURRENT_DATETIME_VAL<br>\n-----------------------------------------------------------------<br>\n2022-09-07               |    2022-09-07 10:05:12.432<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeExpressions",
      "x": "939px",
      "y": "447px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "Expressions",
          "value": "",
          "widget": "tab",
          "title": "Expressions",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCols",
          "value": "[\"subscription_duration\"]",
          "widget": "key_array",
          "type": "sparksql",
          "title": "Column Name",
          "description": "Output Column Name",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": true,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "expressions",
          "value": "[\"DATEDIFF(subscription_end_date, subscription_start_date)\"]",
          "widget": "value_array",
          "type": "sparksql",
          "title": "Expression",
          "description": "Expression to create new columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputSchema",
          "value": "",
          "widget": "tab",
          "title": "InferSchema",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColNames",
          "value": "[]",
          "widget": "schema_col_names",
          "title": "Output Column Name",
          "description": "Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColTypes",
          "value": "[]",
          "widget": "schema_col_types",
          "title": "Output Column Type",
          "description": "Data Type of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputColFormats",
          "value": "[]",
          "widget": "schema_col_formats",
          "title": "Output Column Format",
          "description": "Format of the Output Columns",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    },
    {
      "id": "21",
      "name": "Case When",
      "iconImage": "fa fa-tumblr-square",
      "description": "This node creates a new Dataframe with a new column appended to it containing value based on the condition met",
      "details": "<h2>Case When Node Details</h2>\n<br>\nThis node creates a new Dataframe with new output column added to the incoming dataframe. Value of the new column is set based on the Condition met and corresponding value fetched.<br>\n<br>\nIt evaluates a set of expressions and outputs value of the expression that evaluates to true. If none of the expressions evaluates to true then it outputs value assigned in the 'else' section.<br>\n<br>\n<h3>When conditions can be entered as followings:</h3>\n<br>\n<h4>Using Comparison Operators</h4>\n<ul>\n<li>\tComparing a value against a String column\t\t->\t\tExample:\tPRD_CATEGORY = 'MACHINE'</li>\n<li>\tChecking for not equal to condition against a String column\t\t->\t\tExample:\tPRD_CATEGORY != 'MACHINE'</li>\n<li>\tComparing a value against a Numeric column\t\t->\t\tExample:\tAGE >= 35</li>\n<li>\tUsing a Mathematical operator\t\t\t\t\t->\t\tExample:\t(AGE * 10) < 90</li>\n<li> Checking for multiple values using IN and NOT IN  ->  Example:    DEPT IN ('HR', 'SALES')</li>\n</ul>\n<h4>Using Logical Operators To Combine Multiple Expressions</h4>\n<ul>\n<li>\tChecking for two conditions in single expression\t->\t\tExample:\tDEPT = 'HR' AND AGE >= 25</li>\n<li>\tChecking for two conditions in single expression\t\t->\t\tExample:\tAGE >= 35 OR AGE <45</li>\n</ul>\n<h4>Checking For Null Value</h4>\n<ul>\n<li>\tChecking whether a column value is Null\t\t\t->\t\tExample:\tDEPT IS NULL</li>\n</ul>\n<h4>Checking For Blank Value</h4>\n<ul>\n<li>\tChecking whether value in a column is empty\t\t->\t\tExample:\tTRIM(DATE_OF_JOINING) = ''</li>\n</ul>\n<h4>Checking Against Boolean Value</h4>\n<ul>\n<li>\tChecking whether a Boolean column is True or False\t\t->\t\tExample:\tIS_DATEGREATER = TRUE</li>\n</ul>\n<h4>Checking Against Date-Time Value</h4>\n<ul>\n<li>\tComparing a Date column against a Date value\t->\t\tExample:\tCURR_DATE > TO_DATE('2021-12-12','yyyy-MM-dd')</li>\n<li>\tComparing a Date-Time column against a Date-Time value\t->\t\tExample:\tCURR_TIME > TO_TIMESTAMP('2021-12-12 12:12:12','yyyy-MM-dd HH:mm:ss')</li>\n</ul>\n<br>\n<h3>Values can entered as followings:</h3>\n<br>\n<h4>Assigning value from a column</h4>\n<ul>\n<li> \tAssigning value from a column[DEPT] to output (Value)\t\t->\t\tExample:\tDEPT</li>\n<li> \tApplying a operator before assigning value from a column\t\t->\t\tExample:\tSALARY * 10</li>\n</ul>\n<h4>Assigning a String or Number constant</h4>\n<ul>\n<li>\tAssigning a String constant\t\t->\t\tExample:\t'DEPT IS HR'</li>\n<li>\tAssigning a Number constant\t\t->\t\tExample:\t1000</li>\n</ul>\n<h4>Assigning Current Date and Current Timestamp</h4>\n<ul>\n<li>\tAssigning Current Date\t\t->\t\tExample:\tCURRENT_DATE</li>\n<li>\tAssigning Current Date-Time\t\t->\t\tExample:\tCURRENT_TIMESTAMP</li>\n</ul>",
      "examples": "<h2>Case When Node Examples</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY<br>\n------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999<br>\n<br>\n<h4>CaseWhen Node Configuration</h4>\n<br>\nCaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY < 12500                        |        'FIRST_GRADE'<br>\nSALARY>= 12500 AND SALARY < 30000     |        'SECOND_GRADE'<br>\nSALARY >- 30000 AND SALARY < 70000    |        'THIRD_GRADE'<br>\nELSE                                  |        'FOURTH_GRADE'<br>\n<br>\n[ELSE] is the default condition processed if no other condition is met<br>\n<br>\n<h4>Node Output</h4>\n<br>\nOutput Dataframe would be created as below where value of [SALARY] is compared against [WHEN CONDITION] and [VALUE] is fetched for the output column [SALARY_GRADE]:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE    |    DATE_OF_JOINING   |    PERFORMANCE     |    SALARY    |    SALARY_GRADE<br>\n---------------------------------------------------------------------------------------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25     |    2021-01-01        |    GOOD            |    12000     |    FIRST_GRADE<br>\nE02       |    JOHN        |    SALES      |    35     |    2019-05-04        |    VERY GOOD       |    11000     |    FIRST_GRADE<br>\nE03       |    MARTIN      |    MARKETING  |    40     |    2018-06-07        |    AVERAGE         |    34000     |    THIRD_GRADE<br>\nE04       |    TONY        |    MARKETING  |    45     |    2017-02-01        |    VERY VERY GOOD  |    12500     |    SECOND_GRADE<br>\nE05       |    MARK        |    HR         |    25     |    2020-12-21        |    BAD             |    78999     |    FOURTH_GRADE<br>\n<br>\n<h4> Values can also be assigned based on the value of another column</h4>\n<br>\nif CaseWhen node is configured as below to compute values for the output column:<br>\n<br>\nWHEN CONDITION                        |        VALUE<br>\n------------------------------------------------------------------<br>\nSALARY IS NULL                        |        AGE<br>\nELSE                                  |        SALARY<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.etl.NodeCaseWhen",
      "x": "1012px",
      "y": "628px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "outputCol",
          "value": "payment_frequency_category",
          "widget": "textfield",
          "title": "Output Column Name",
          "description": "output column name",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "whenConditions",
          "value": "[\"payment_frequency = 1\",\"payment_frequency = 3\"]",
          "widget": "key_array",
          "type": "sparksql",
          "title": "When",
          "description": "When Condition",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": true,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "values",
          "value": "[\"'Frequent'\",\"'Moderate'\"]",
          "widget": "value_array",
          "type": "sparksql",
          "title": "Then",
          "description": "Value when this condition is true",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": true,
          "header": "",
          "size": "100%",
          "toggle": ""
        },
        {
          "name": "finallyElse",
          "value": "'Infrequent'",
          "widget": "key_textfield",
          "title": "Else",
          "description": "else",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": true,
          "header": "",
          "size": "100%",
          "toggle": ""
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "3",
      "target": "9",
      "id": 1
    },
    {
      "source": "5",
      "target": "9",
      "id": 2
    },
    {
      "source": "9",
      "target": "8",
      "id": 3
    },
    {
      "source": "4",
      "target": "8",
      "id": 4
    },
    {
      "source": "8",
      "target": "10",
      "id": 5
    },
    {
      "source": "1",
      "target": "10",
      "id": 6
    },
    {
      "source": "2",
      "target": "11",
      "id": 7
    },
    {
      "source": "10",
      "target": "12",
      "id": 8
    },
    {
      "source": "11",
      "target": "12",
      "id": 9
    },
    {
      "source": "12",
      "target": "13",
      "id": 10
    },
    {
      "source": "13",
      "target": "16",
      "id": 11
    },
    {
      "source": "16",
      "target": "15",
      "id": 12
    },
    {
      "source": "18",
      "target": "19",
      "id": 13
    },
    {
      "source": "19",
      "target": "20",
      "id": 14
    },
    {
      "source": "20",
      "target": "21",
      "id": 15
    },
    {
      "source": "15",
      "target": "18",
      "id": 16
    },
    {
      "source": "21",
      "target": "14",
      "id": 17
    }
  ],
  "dataSetDetails": [
    {
      "id": 990,
      "uuid": "6c70424d-0fc1-46b7-a898-41ea932e0f42",
      "header": true,
      "path": "data/SALES/Subscription-Renewal-Prediction/Raw-Data/customer_category.csv",
      "delimiter": ",",
      "datasetType": "CSV",
      "datasetSchema": "{\"colNames\":[\"customer_id\",\"customer_category\",\"risk_score\"],\"colTypes\":[\"INTEGER\",\"STRING\",\"INTEGER\"],\"colFormats\":[\"\",\"\",\"\"],\"colMLTypes\":[\"NUMERIC\",\"TEXT\",\"NUMERIC\"]}"
    },
    {
      "id": 988,
      "uuid": "f9fd182e-c722-4c0e-bcee-7728060a8680",
      "header": true,
      "path": "data/SALES/Subscription-Renewal-Prediction/Raw-Data/customer_feedback.csv",
      "delimiter": ",",
      "datasetType": "CSV",
      "datasetSchema": "{\"colNames\":[\"subscription_id\",\"feedback_score\",\"feedback_date\"],\"colTypes\":[\"INTEGER\",\"INTEGER\",\"STRING\"],\"colFormats\":[\"\",\"\",\"\"],\"colMLTypes\":[\"NUMERIC\",\"NUMERIC\",\"TEXT\"]}"
    },
    {
      "id": 987,
      "uuid": "180a3e82-2623-46c5-976a-6e87f53354aa",
      "header": true,
      "path": "data/SALES/Subscription-Renewal-Prediction/Raw-Data/customer_payments.csv",
      "delimiter": ",",
      "datasetType": "CSV",
      "datasetSchema": "{\"colNames\":[\"customer_id\",\"subscription_id\",\"payment_terms\",\"invoice_amount\",\"payment_frequency\"],\"colTypes\":[\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"INTEGER\"],\"colFormats\":[\"\",\"\",\"\",\"\",\"\"],\"colMLTypes\":[\"NUMERIC\",\"NUMERIC\",\"TEXT\",\"NUMERIC\",\"NUMERIC\"]}"
    },
    {
      "id": 989,
      "uuid": "fc78d13a-cb8d-47f3-b31b-f376e1ef8fcb",
      "header": true,
      "path": "data/SALES/Subscription-Renewal-Prediction/Raw-Data/product_category.csv",
      "delimiter": ",",
      "datasetType": "CSV",
      "datasetSchema": "{\"colNames\":[\"product_id\",\"product_category\",\"product_subcategory\"],\"colTypes\":[\"INTEGER\",\"STRING\",\"STRING\"],\"colFormats\":[\"\",\"\",\"\"],\"colMLTypes\":[\"NUMERIC\",\"TEXT\",\"TEXT\"]}"
    },
    {
      "id": 992,
      "uuid": "75390274-1fae-45cc-8fc4-127610bfe70f",
      "header": true,
      "path": "data/SALES/Subscription-Renewal-Prediction/Raw-Data/subscription_history.csv",
      "delimiter": ",",
      "datasetType": "CSV",
      "datasetSchema": "{\"colNames\":[\"subscription_id\",\"customer_id\",\"subscription_start_date\",\"renewal_flag\",\"subscription_end_date\"],\"colTypes\":[\"INTEGER\",\"INTEGER\",\"STRING\",\"INTEGER\",\"STRING\"],\"colFormats\":[\"\",\"\",\"\",\"\",\"\"],\"colMLTypes\":[\"NUMERIC\",\"NUMERIC\",\"TEXT\",\"NUMERIC\",\"TEXT\"]}"
    }
  ],
  "engine": "scala"
}