{
  "name": "00-Data-Quality",
  "uuid": "b6bb832a-4ed6-4906-9b0d-713932452549",
  "category": "Data-Quality",
  "parameters": " --var runDataQualityRules=true --var selectH2OModel=h2OGradientBoostingMachine --var workflow_3_featurecolumns=MONTHLY_AVG_CLAIM_AMOUNT,STATUS_MONTHLY_AVG_CLAIM_AMOUNT,STATUS,CLAIM_TYPE,PREMIUM_AMOUNT,POLICY_STATUS,POLICY_START_CLAIM_DATE_DIFF,CLAIM_AMOUNT --var modelName=MODEL_1 --var h2omaxrows=10 --var h2oseed=-1 --var h2onumoffolds=0 --var h2onumoftrees=50 --var h2omaxdepth=5 --var run1=true --var destinationPath=data/COMMON/Customer/Etl-Warranty/Upload --var model=MODEL_1",
  "nodes": [
    {
      "id": "2",
      "name": "ExpectColumnValueLengthToBeInBetween",
      "description": "",
      "details": "<h2>Expect Column Value length To be in Between Details</h2>\n<br>\nExpect the column value lengths to be between a minimum value and a maximum value (inclusive).<br>\n<br>\n<h4>Keyword Args</h4>\n<br>\nColumn Name: The column name<br>\nMin (comparable type or None): The minimum value for a column entry.<br>\nMax (comparable type or None): The maximum value for a column entry.<br>\n<br>\n<h4>Notes</h4>\n`Min` and `Max` are both inclusive.<br>\nIf `Min` is None, then `Max` is treated as an upper bound, and there is no minimum value checked.<br>\nIf `Max` is None, then `Min` is treated as a lower bound, and there is no maximum value checked.<br>",
      "examples": "If the incoming DataFrame has the following values in column6:<br>\n<br>\ncolumn6<br>\napple<br>\norange<br>\npineapple<br>\nkiwi<br>\nbanana<br>\nSetting Min to 5 and Max to 7 will yield the following result:<br>\n<br>\nValid values: \"orange\" and \"banana\"<br>\nInvalid values: \"apple\" (too short), \"pineapple\" (too long), \"kiwi\" (too short)<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ge.NodeExpectColumnValueLengthToBeInBetween",
      "x": "157.659px",
      "y": "183.675px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "cols",
          "value": "[\"Policy_Number\"]",
          "widget": "variables_list_select",
          "title": "Column Name",
          "description": "The column name.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "min",
          "value": "[\"4\"]",
          "widget": "variables_list_textfield",
          "title": "Min",
          "description": "The minimum value for a column entry length.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "max",
          "value": "[\"5\"]",
          "widget": "variables_list_textfield",
          "title": "Max",
          "description": "The maximum value for a column entry length.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "3",
      "name": "ExpectColumnValuesToBeInSet",
      "description": "",
      "details": "<h2> Expect Column Values To Be In Set Details</h2>\n<br>\nThis feature allows users to validate that column values in a DataFrame are within a specified set of values. It helps ensure data quality by restricting column values to predefined acceptable options.<br>\n<br>\n<h4> Input</h4>\n<br>\nColumn Name: Select the column that needs to be validated. The column type should match the expected data type.<br>\nValues: Enter the set of values that are acceptable for the selected column.<br>\nMostly: Specifies the minimum percentage (0.0 - 1.0) of rows that must meet the condition for it to pass validation.<br>\n<h4> Output</h4>\n<br>\nA DataFrame with validation results, indicating whether each row's value in the specified column is within the acceptable set.<br>\nThe validation status can be used to filter or further process data based on quality checks.<br>",
      "examples": "Example: If a column named \"Status\" in the DataFrame is expected to contain only \"Approved,\" \"Pending,\" or \"Rejected,\" set the Values field to [\"Approved\", \"Pending\", \"Rejected\"]. This configuration ensures that any other value in the \"Status\" column will be flagged for review.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ge.NodeExpectColumnValuesToBeInSet",
      "x": "321.664px",
      "y": "41.672px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "cols",
          "value": "[\"Status\"]",
          "widget": "variables_list_select",
          "title": "Column Name",
          "description": "The column name.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "values",
          "value": "[\"Open;Closed;Pending\"]",
          "widget": "variables_list_textfield",
          "title": "values",
          "description": "A set of objects seperated by spaces used for comparison..",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mostly",
          "value": "[\"\"]",
          "widget": "variables_list_textfield",
          "title": "Mostly",
          "description": "Mostly value is between 0 and 1, and evaluates it as a percentage and as long as mostly percent of rows evaluate to True, the expectation returns “success”: True.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "4",
      "name": "ExpectColumnValuesToBeUnique",
      "description": "",
      "details": "<h2>Expect Column Values To Be Unique Details</h2>\n<br>\nExpect each column value to be unique.<br>\n<br>\nThis expectation detects duplicates. All duplicated values are counted as exceptions.<br>\n<br>\n<h4>Keyword Args</h4>\n<br>\nColumn Name: The column name<br>\nMostly (None or a float between 0 and 1): Return `success`: True if at least mostly fraction of values match the expectation.<br>",
      "examples": "<h2>Example</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    DEPT        |<br>\n--------------------------------------<br>\nE01       |    MARKETING   |<br>\nE02       |    MARKETING   |<br>\nE03       |    SALES       |<br>\nE04       |    ADMIN       |<br>\n<br>\n<h4>Configuration</h4>\n<br>\nColumn Name   | Mostly  |<br>\n-------------------------<br>\nEMP_CD        |         |<br>\nDEPT          | 0.75    |           <br>\n<br>\nThe above setup would result in a status of `success: true` as both conditions are satisfied.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ge.NodeExpectColumnValuesToBeUnique",
      "x": "415.672px",
      "y": "192.664px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "cols",
          "value": "[\"Claim_ID\"]",
          "widget": "variables_list_select",
          "title": "Column Name",
          "description": "The column name.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mostly",
          "value": "[\"\"]",
          "widget": "variables_list_textfield",
          "title": "Mostly",
          "description": "Mostly value is between 0 and 1, and evaluates it as a percentage and as long as mostly percent of rows evaluate to True, the expectation returns “success”: True.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "5",
      "name": "ExpectColumnValuesToNotBeNull",
      "description": "",
      "details": "<h2>Expect Column Values To Not Be Null Details</h2>\n<br>\nExpect the column values to not be null.<br>\n<br>\nTo be counted as an exception, values must be explicitly null or missing, such as an np.NaN in pandas. Empty strings don't count as null unless they have been coerced to a null type.<br>\n<br>\n<h4>Keyword Args</h4>\n<br>\nColumn Name: The column name<br>\nMostly (None or a float between 0 and 1): Return `success`: True if at least mostly fraction of values match the expectation.<br>",
      "examples": "<h2>Example</h2>\n<br>\n<h4>Incoming Dataframe</h4>\n<br>\nIn this example we have considered a Incoming Dataframe with following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |<br>\n--------------------------------------<br>\nE01       |    DAVID       |<br>\nE02       |                |<br>\nE03       |    MARK        |<br>\nE04       |    JACK        |<br>\n<br>\n<h4>Configuration</h4>\n<br>\nColumn Name   | Mostly  |<br>\n-------------------------<br>\nEMP_CD        |         |<br>\nEMP_NAME      | 0.8     |           <br>\n<br>\nThe above setup would result in a status of `success: false`, as even though the `EMP_CD` column value evaluates to be true it fails for the condition setup for the column `EMP_NAME`.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ge.NodeExpectColumnValuesToNotBeNull",
      "x": "624.664px",
      "y": "47.6693px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "cols",
          "value": "[\"Claim_ID\"]",
          "widget": "variables_list_select",
          "title": "Column Name",
          "description": "The column name.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mostly",
          "value": "[\"\"]",
          "widget": "variables_list_textfield",
          "title": "Mostly",
          "description": "Mostly value is between 0 and 1, and evaluates it as a percentage and as long as mostly percent of rows evaluate to True, the expectation returns “success”: True.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "6",
      "name": "ExpectColumnValueToMatchStrftimeFormat",
      "description": "",
      "details": "<h2>Expect Column Values Lengths to Equal</h2>\n<br>\nExpect the column entries to be strings with length equal to the provided value.<br>\n<br>\n<h4>Keyword Args</h4>\n<br>\nColumn Name: The column name<br>\nstrftime_format (str): A strftime format string to use for matching<br>\nMostly (None or a float between 0 and 1): Return `success`: True if at least mostly fraction of values match the expectation.<br>",
      "examples": "<h2>Example</h2>\n<br>\nLet's assume we have a column named date_of_birth with values like \"1990-12-25\", \"12/25/1990\", and \"25-Dec-1990\".<br>\n<br>\nConfigure the Node:<br>\n<br>\nColumn Name: date_of_birth<br>\nStrftime Format: %Y-%m-%d (for the first format)<br>\nMostly: False (all values must match)<br>\nNode Execution:<br>\n<br>\nThe node will flag records with values like \"12/25/1990\" and \"25-Dec-1990\" as they don't match the specified format.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ge.NodeExpectColumnValueToMatchStrftimeFormat",
      "x": "713.664px",
      "y": "175.677px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "cols",
          "value": "[\"Claim_Date\"]",
          "widget": "variables_list_select",
          "title": "Column Name",
          "description": "The column name.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "strftime_format",
          "value": "[\"%Y-%m-%d\"]",
          "widget": "variables_list_textfield",
          "title": "Strftime Format",
          "description": "A strftime format string to use for matching",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "mostly",
          "value": "[\"0.8\"]",
          "widget": "variables_list_textfield",
          "title": "Mostly",
          "description": "Mostly value is between 0 and 1, and evaluates it as a percentage and as long as mostly percent of rows evaluate to True, the expectation returns “success”: True.",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "16",
      "name": "Print N Rows",
      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",
      "details": "<h2>Print N Rows Node Details</h2>\n<br>\nThis node is used to print the first N rows from the incoming dataframe.<br>\n<br>\nThe Number of rows that needs to be printed can be configured in the node.<br>\n<br>\n<h4>Input Parameters</h4>\n<ul>\n<li> OUTPUT STORAGE LEVEL : Keep this as DEFAULT.</li>\n<li> TITLE : Enter a short description for the type of information being displayed.</li>\n<li> NUM ROWS TO PRINT : Set an integer value(N) which controls the number of rows to be displayed(Default N=10).</li>\n<li> DISPLAY DATA TYPE : Shows the output dataframe column datatypes by default.</li>\n</ul>\n<h4>Output</h4>\n<ul>\n<li> This node can be used to view, analyze and validate the output of the Dataframe.</li>\n</ul>",
      "examples": "when input 5 in no of rows,it will show first 5 rows of the table as follows<br>\n<br>\nPartID\tSupplierID\tPartName\t<br>\n<br>\nP9271\t  S798\t    Part_D\t<br>\nP523\t  S955\t    Part_K\t<br>\nP3201\t  S332\t    Part_M\t<br>\nP9634\t  S527\t    Part_G\t<br>\nP9345\t  S850\t    Part_M<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",
      "x": "963.667px",
      "y": "171.677px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "title",
          "value": "Great Expectations Rules Output",
          "widget": "textfield",
          "title": "Title",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "n",
          "value": "10",
          "widget": "textfield",
          "title": "Num Rows to Print",
          "description": "number of rows to be printed",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "displayDataType",
          "value": "false",
          "widget": "array",
          "title": "Display Data Type",
          "description": "If true display rows DataType",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "18",
      "name": "Sticky Note",
      "description": "Allows capturing Notes on the Workflow",
      "details": "",
      "examples": "",
      "type": "sticky",
      "nodeClass": "fire.nodes.doc.NodeStickyNote",
      "x": "132.844px",
      "y": "323px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "bgColor",
          "value": "blue",
          "widget": "textfield",
          "title": "Bg Color",
          "description": "Background of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "width",
          "value": "624.306878px",
          "widget": "textfield",
          "title": "Width",
          "description": "Width of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "height",
          "value": "231.306878px",
          "widget": "textfield",
          "title": "Height",
          "description": "Height of note",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "comment",
          "value": "<h2>Data Quality Workflow for Transactional Claims</h2><p><br></p><p><strong>Objective:</strong></p><p>Ensure transactional claims data adheres to specified data quality rules.</p><p><br></p><p><strong>Rules</strong>:</p><p>1. Policy Number:</p><p>&nbsp;&nbsp;- Length: 4-5 characters</p><p>2. Status:</p><p>&nbsp;&nbsp;- Valid Values: Open, Pending, Closed</p><p>3. Claim ID:</p><p>&nbsp;&nbsp;- Uniqueness: No duplicates</p><p>&nbsp;&nbsp;- Non-null: Mandatory field</p><p>4. Claims Date:</p><p>&nbsp;&nbsp;- Format: Fixed date format</p><p><br></p><p><strong>Process</strong>:</p><ul><li>- Validate each transaction against the above rules.</li></ul>",
          "widget": "textarea_rich",
          "title": "Comment",
          "description": "Comments for the Workflow",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    },
    {
      "id": "20",
      "name": "Create CSV from GE Results",
      "iconImage": "/images/icons/node-icon/csv.svg",
      "description": "",
      "details": "<h2> Create CSV from GE Results Node</h2>\n<br>\n<h4> Overview:</h4>\n<br>\nThis node writes the output of a GE pipeline to a CSV file. It offers flexibility in configuring the output file's path, save mode, and whether to include a header row.<br>\n<br>\n<h4> Input:</h4>\n<br>\nPath: The desired path for the output CSV file.<br>\nSave Mode: Determines how to handle existing files:<br>\nAppend: Appends new data to the end of an existing file.<br>\nOverwrite: Overwrites the file with the new data.<br>\nErrorIfExists: Throws an error if the file already exists.<br>\nHeader: Specifies whether to include a header row with column names.<br>\n<br>\n<h4> Output:</h4>\n<br>\nThe node writes the output DataFrame to the specified CSV file.<br>",
      "examples": "Example:<br>\n<br>\nLet's say you have a DataFrame containing customer data and want to save it as a CSV file.<br>\n<br>\nConfigure the Node:<br>\n<br>\nPath: /path/to/output.csv<br>\nSave Mode: Append<br>\nHeader: True<br>\nNode Execution:<br>\n<br>\nThe DataFrame will be written to the specified CSV file, appending new data if the file already exists. The output file will include a header row with column names.<br>",
      "type": "transform",
      "nodeClass": "fire.nodes.ge.NodeCreateCsvFromGeResults",
      "x": "828.844px",
      "y": "161.847px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "csvPath",
          "value": "data/COMMON/Customer/Etl-Warranty/Output/GE-Results/",
          "widget": "textfield",
          "title": "Path",
          "description": "Path to save consolidated Great Expectation results as a CSV",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "saveMode",
          "value": "Overwrite",
          "widget": "array",
          "title": "Save Mode",
          "description": "Whether to Append, Overwrite or Error if the path Exists",
          "optionsArray": [
            "Append",
            "Overwrite",
            "ErrorIfExists",
            "Ignore"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "header",
          "value": "true",
          "widget": "array",
          "title": "Header",
          "description": "Should a Header Row be saved with each File?",
          "optionsArray": [
            "true",
            "false"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "advanced",
          "value": "",
          "widget": "tab",
          "title": "Advanced",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "partitionColNames",
          "value": "[]",
          "widget": "variables",
          "title": "Partition Column Names",
          "description": "Partition Column Names",
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "pyspark"
    },
    {
      "id": "21",
      "name": "Dataset Structured",
      "iconImage": "fa fa-th-list",
      "description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset was defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",
      "details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",
      "examples": "<h2> Dataset Structured Node Example</h2>\n<br>\nScenario:<br>\n<br>\nLet's say you have multiple datasets available in your workflow and you want to select one of them as input for the next node. You can use the Dataset Structured node to choose the desired dataset.<br>\n<br>\nConfiguration:<br>\n<br>\n1. **Output Storage Level:** Select the desired storage level for the output DataFrame.<br>\n2. **Dataset:** Choose the dataset from the dropdown list.<br>\n<br>\nOutput:<br>\n<br>\nThe node will output the selected dataset as a DataFrame.<br>",
      "type": "dataset",
      "nodeClass": "fire.nodes.dataset.NodeDatasetStructured",
      "x": "44.8439px",
      "y": "74.8466px",
      "fields": [
        {
          "name": "storageLevel",
          "value": "DEFAULT",
          "widget": "array",
          "title": "Output Storage Level",
          "description": "Storage Level of the Output Datasets of this Node",
          "optionsArray": [
            "DEFAULT",
            "NONE",
            "DISK_ONLY",
            "DISK_ONLY_2",
            "MEMORY_ONLY",
            "MEMORY_ONLY_2",
            "MEMORY_ONLY_SER",
            "MEMORY_ONLY_SER_2",
            "MEMORY_AND_DISK",
            "MEMORY_AND_DISK_2",
            "MEMORY_AND_DISK_SER",
            "MEMORY_AND_DISK_SER_2",
            "OFF_HEAP"
          ],
          "required": false,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        },
        {
          "name": "dataset",
          "value": "eae1b9d3-4c70-4465-934e-10b49a6f2a3b",
          "widget": "dataset",
          "title": "Dataset",
          "description": "Selected Dataset",
          "required": true,
          "display": true,
          "editable": true,
          "disableRefresh": false,
          "expandable": false,
          "header": "",
          "size": "100%"
        }
      ],
      "engine": "all"
    }
  ],
  "edges": [
    {
      "source": "2",
      "target": "3",
      "id": 1
    },
    {
      "source": "3",
      "target": "4",
      "id": 2
    },
    {
      "source": "4",
      "target": "5",
      "id": 3
    },
    {
      "source": "5",
      "target": "6",
      "id": 4
    },
    {
      "source": "6",
      "target": "20",
      "id": 5
    },
    {
      "source": "20",
      "target": "16",
      "id": 6
    },
    {
      "source": "21",
      "target": "2",
      "id": 7
    }
  ],
  "dataSetDetails": [
    {
      "id": 2220,
      "uuid": "eae1b9d3-4c70-4465-934e-10b49a6f2a3b",
      "header": true,
      "path": "data/COMMON/Customer/Etl-Warranty/Raw-Data\n/Claims.json",
      "delimiter": ",",
      "datasetType": "JSON",
      "datasetSchema": "{\"colNames\":[\"Appliance_Model\",\"Claim_Amount\",\"Claim_Date\",\"Claim_ID\",\"Claim_Type\",\"Claimant_Name\",\"Description\",\"Policy_Number\",\"Status\"],\"colTypes\":[\"STRING\",\"DOUBLE\",\"STRING\",\"LONG\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"],\"colFormats\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\"colMLTypes\":[\"TEXT\",\"NUMERIC\",\"TEXT\",\"NUMERIC\",\"TEXT\",\"TEXT\",\"TEXT\",\"TEXT\",\"TEXT\"]}"
    }
  ],
  "engine": "pyspark"
}