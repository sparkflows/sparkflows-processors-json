{
  "id": "11",
  "name": "Read JDBC",
  "description": "This node writes data to databases using JDBC.",
  "type": "dataset",
  "engine": "pyspark",
  "nodeClass": "fire.nodes.save.NodeReadJDBC",
  "fields" : [
    {"name":"connection", "value":"", "widget": "object_array", "title": "Connection", "description": "The JDBC connection to connect" ,"required":"true"},

    {"name":"table", "value":"", "widget": "textarea_small", "title": "DB Table", "required":"true",
      "description": "The JDBC table that should be read. Note that anything that is valid in a FROM clause of a SQL query can be used. For example, instead of a full table, you could also use a subquery in parentheses"},

    {"name": "performance", "value":"", "widget": "tab", "title": "Performance"},
    {"name":"partitionColumn", "value":"", "widget": "textfield", "title": "Partition Column", "description": "PartitionColumn must be a numeric, date, or timestamp column from the table" },
    {"name":"lowerBound", "value":"", "widget": "textfield", "title": "Lower Bound", "description": " LowerBound and UpperBound are just used to decide the partition stride, not for filtering the rows in the table. All rows in the table will be partitioned and returned. This option applies only to reading" },
    {"name":"upperBound", "value":"", "widget": "textfield", "title": "Upper Bound", "description": " LowerBound and UpperBound are just used to decide the partition stride, not for filtering the rows in the table. All rows in the table will be partitioned and returned. This option applies only to reading" },
    {"name":"numPartitions", "value":"", "widget": "textfield", "title": "Num Partitions", "description": "The maximum number of partitions that can be used for parallelism in table reading" },
    {"name":"fetchsize", "value":"", "widget": "textfield", "title": "Fetch Size", "description": "The JDBC fetch size, which determines how many rows to fetch per round trip" },

    {"name": "schema", "value":"", "widget": "tab", "title": "Schema"},
    {"name":"outputColNames", "value":"[]", "widget": "schema_col_names", "title": "Column Names of the Table", "description": "Output Columns Names of the Table"},
    {"name":"outputColTypes", "value":"[]", "widget": "schema_col_types", "title": "Column Types of the Table", "description": "Output Column Types of the Table"},
    {"name":"outputColFormats", "value":"[]", "widget": "schema_col_formats", "title": "Column Formats", "description": "Output Column Formats"}
  ]
}
start-details:

h2: Read JDBC Node Details

This node reads data from Relational Databases using JDBC and creates a DataFrame from it.

h4: Parameters to be set:
General:
*OUTPUT STORAGE LEVEL: Keep this as DEFAULT.
*CONNECTION: Select the desired JDBC connection to be used.
*DB TABLE: Specify the table from which data is to be read.
Performance:
*PARTITION COLUMN: The column used to partition the table data for parallel reads.
*LOWER BOUND: The minimum value for the partition column to start data partitioning.
*UPPER BOUND: The maximum value for the partition column to end data partitioning.
*NUM PARTITIONS: Number of partitions for parallel data processing.
*FETCH SIZE: Number of rows to fetch per call; helps optimize data retrieval performance.
Schema:
*Schema Columns: Refresh the schema for loading column name,column type,column format. 

end-details:

start-examples:

h2: Read JDBC Node Examples

h4: Example of Connection Values
General:
*CONNECTION: MYSQL_DEV_ENV
*DB TABLE: employee_data
Performance:
*PARTITION COLUMN: employee_id
*LOWER BOUND: 1
*UPPER BOUND: 1000
*NUM PARTITIONS: 4
*FETCH SIZE: 500

end-examples
