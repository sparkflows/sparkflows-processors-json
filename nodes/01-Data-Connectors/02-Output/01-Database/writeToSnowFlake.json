{
  "id": "11",
  "name": "Write To Snowflake",

  "description": "",
  "input": "The Dataframe from the previous node",
  "output": "The incoming Dataframe is passed to the next node as it is",
  "engine": "all",
  "type": "transform",
  "nodeClass": "fire.nodes.snowflake.NodeWriteToSnowFlake",
  "fields" : [
   {"name":"authType", "value":"UserCredential", "widget": "array", "title": "Auth Type", "description": "Authentication Type. Possible value is OAUTH or USER_CREDENTIAL" ,"required":"true","optionsArray": ["UserCredential","OAuth"]},
    {"name":"connection", "value":"", "widget": "object_array", "title": "Connection", "description": "The Snowflake connection to connect" ,"required":"true"},
    {"name":"sfWarehouse", "value":"", "widget": "textfield", "title": "Snowflake Warehouse", "description": "Warehouse for connecting to the Snowflake" ,"required":"true"},

    {"name":"sfDatabase", "value":"", "widget": "textfield", "title": "Snowflake Database", "description": "Database for connecting to the Snowflake" ,"required":"true"},
    {"name":"sfSchema", "value":"", "widget": "textfield", "title": "Snowflake Schema", "description": "Schema for connecting to the Snowflake" ,"required":"true"},
    {"name":"dbtable", "value":"", "widget": "textfield", "title": "Snowflake Table", "required":"true", "description": "Snowflake Table from which to write the data"},
    {"name":"columnMapping", "value":"Order", "widget": "array","optionsArray": ["Order","Name"], "title": "Column Mapping", "description": "The connector must map columns from the Spark data frame to the Snowflake table"},
    {"name":"saveMode", "value":"Append", "widget": "array","optionsArray": ["Append","Overwrite", "ErrorIfExists", "Ignore"],
      "title": "Save Mode", "description":"Whether to Append, Overwrite or Error if the table Exists"},

    {"name": "extraOptions", "value": "", "widget": "tab", "title": "Extra Options"},
    {"name": "extraOptionsKeys", "value":"[]", "widget": "key_array", "title": "Extra Options Keys", "description": "Extra options available while writing to Snowflake. Examples:\ncolumn_mismatch_behavior --> 'error' (default) or 'ignore'. Determines the action when there is a mismatch between DataFrame columns and Snowflake table columns.\nautopushdown --> 'on' (default) or 'off'. Enables or disables automatic query pushdown to Snowflake for optimization.\nkeep_column_case --> 'on' or 'off' (default). Preserves the original case of column names when set to 'on'. Converts column names to uppercase otherwise.\ntime_output_format --> e.g., 'HH24:MI:SS'. Defines the output format for time columns.\ntimestamp_output_format --> e.g., 'YYYY-MM-DD HH24:MI:SS.FF3'. Defines the output format for timestamp columns.\npreactions --> Specifies SQL statements to execute in Snowflake before writing data.\npostactions --> Specifies SQL statements to execute in Snowflake after writing data.\ntruncate_table --> 'on' or 'off' (default). If set to 'on', truncates the target table before inserting data.\nusestagingtable --> 'on' (default) or 'off'. When set to 'on', uses a staging table for the write operation to ensure atomicity.\nusestagingtableondemand --> 'on' or 'off' (default). Uses a staging table only when necessary if set to 'on'."},
    {"name": "extraOptionsValues", "value":"[]", "widget": "value_array", "title": "Extra Options Values", "description": "Config Values for the Corresponding keys"}

  ]
}
start-details:

h2: Write To Snowflake Node Details

This node saves the rows of the incoming dataframe into the specified table in Snowflake.

h4: Parameters to be set:
* OUTPUT STORAGE LEVEL : Keep this as DEFAULT.
* CONNECTION : Select the desired snowflake connection to be used.
* SNOWFLAKE WAREHOUSE : Specify the virtual warehouse to use for the connection.
* SNOWFLAKE DATABASE : Specify the database to use once connected.
* SNOWFLAKE SCHEMA : Specify the schema to use for the specified database once connected.
* SNOWFLAKE TABLE : Specify the table from which data is to be read.
* SAVE MODE : Select the mode of operation on the table. 
Append: If data/table already exists, contents of the table are to be appended to existing data. 
Overwrite: If table already exists, existing data is overwritten by the new content. 
ErrorIfExists: If data already exists, an exception is thrown and operation stops.
Ignore: If table already exists, the save operation is ignored.

end-details:

start-examples:

h2: Write To Snowflake Node Examples

h4: The below example will save the input dataframe to the `CUST_BASIC_LA` table.

* CONNECTION : SNOWFLAKE_DEV_ENV_NCUS
* SNOWFLAKE WAREHOUSE : SNOWFLAKE_BI_VWH
* SNOWFLAKE DATABASE : CUSTOMER_SALES_NCUS
* SNOWFLAKE SCHEMA : INT_NA_CUSTSALES
* SNOWFLAKE TABLE : CUST_BASIC_LA
* SAVE MODE : Overwrite

end-examples:
