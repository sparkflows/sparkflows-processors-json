{
  "id": "7",
  "name": "ExpectColumnValuesToNotBeNull",
  "description": "",
  "type": "transform",
  "engine": "pyspark",
  "nodeClass": "fire.nodes.ge.NodeExpectColumnValuesToNotBeNull",
  "fields" : [

    {"name": "cols", "value":"[]", "widget": "variables_list_select",
      "title": "Column Name", "description": "The column name."},

    {"name": "mostly", "value":"[]", "widget": "variables_list_textfield",
      "title": "Mostly", "description": "Mostly value is between 0 and 1, and evaluates it as a percentage and as long as mostly percent of rows evaluate to True, the expectation returns “success”: True."}
  ]
}

start-details:

h2:Expect Column Values To Not Be Null Details

Expect the column values to not be null.

To be counted as an exception, values must be explicitly null or missing, such as an np.NaN in pandas. Empty strings don't count as null unless they have been coerced to a null type.

h4:Keyword Args

Column Name: The column name
Mostly (None or a float between 0 and 1): Return `success`: True if at least mostly fraction of values match the expectation.

end-details:

start-examples:

h2:Example

h4:Incoming Dataframe

In this example we have considered a Incoming Dataframe with following rows:

EMP_CD    |    EMP_NAME    |
--------------------------------------
E01       |    DAVID       |
E02       |                |
E03       |    MARK        |
E04       |    JACK        |

h4:Configuration

Column Name   | Mostly  |
-------------------------
EMP_CD        |         |
EMP_NAME      | 0.8     |           

The above setup would result in a status of `success: false`, as even though the `EMP_CD` column value evaluates to be true it fails for the condition setup for the column `EMP_NAME`.  

end-examples:
